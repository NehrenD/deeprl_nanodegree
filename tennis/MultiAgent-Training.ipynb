{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Code for the Multi Agent Project\n",
    "\n",
    "By: Daniel Nehren\n",
    "\n",
    "Date: 7/13/2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from unityagents import UnityEnvironment\n",
    "import numpy as np\n",
    "import random\n",
    "from collections import deque\n",
    "import copy\n",
    "import ptan\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from maddpg_model import Config,Actor,Critic,ReplayBuffer,MADDPGAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "Unity brain name: TennisBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 8\n",
      "        Number of stacked Vector Observation: 3\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 2\n",
      "        Vector Action descriptions: , \n"
     ]
    }
   ],
   "source": [
    "env = UnityEnvironment(file_name='Tennis_Linux/Tennis.x86_64',no_graphics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "n_agents = len(env_info.agents)\n",
    "state_size = env_info.vector_observations.shape[1]\n",
    "action_size = env_info.previous_vector_actions.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config()\n",
    "\n",
    "writer = SummaryWriter(comment=\"-tennis_maddpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.ACTOR_FC1_UNITS = 265\n",
    "config.ACTOR_FC2_UNITS = 128\n",
    "config.CRITIC_FC1_UNITS = 256\n",
    "config.CRITIC_FC2_UNITS = 128\n",
    "config.LR_ACTOR = 1e-4\n",
    "config.LR_CRITIC = 3e-4\n",
    "config.TAU = 1e-3\n",
    "\n",
    "#REPLAY BUFFER\n",
    "config.BUFFER_SIZE = int(1e5)\n",
    "config.BATCH_SIZE = 256\n",
    "config.GAMMA = 0.99\n",
    "config.WEIGHT_DECAY = 0\n",
    "config.DEVICE = 'cpu'\n",
    "\n",
    "config.WAIT_EPOCHS = 300\n",
    "config.NOISE_START=1.0\n",
    "config.NOISE_END=0.1\n",
    "config.NOISE_REDUCTION=0.999\n",
    "\n",
    "config.TRAINING_ITERATIONS_PER_STEP = 3\n",
    "\n",
    "seed = 14\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "_ = torch.manual_seed(seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "agents = [MADDPGAgent(state_size,action_size,n_agents,config) for _ in range(n_agents)]\n",
    "replay_buffer = ReplayBuffer(config.BUFFER_SIZE,config.BATCH_SIZE,config.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50\tAverage Score: 0.02\tCurrent Score: 0.0\n",
      "Noise Scaling: 1.0, Memory size: 862 and Num Steps: 14\n",
      "Epoch 100\tAverage Score: 0.02\tCurrent Score: 0.0\n",
      "Noise Scaling: 1.0, Memory size: 1808 and Num Steps: 15\n",
      "Epoch 150\tAverage Score: 0.02\tCurrent Score: 0.0\n",
      "Noise Scaling: 1.0, Memory size: 2772 and Num Steps: 14\n",
      "Epoch 200\tAverage Score: 0.02\tCurrent Score: 0.0\n",
      "Noise Scaling: 1.0, Memory size: 3651 and Num Steps: 14\n",
      "Epoch 250\tAverage Score: 0.02\tCurrent Score: 0.0\n",
      "Noise Scaling: 1.0, Memory size: 4589 and Num Steps: 14\n",
      "Epoch 300\tAverage Score: 0.01\tCurrent Score: 0.0\n",
      "Noise Scaling: 1.0, Memory size: 5485 and Num Steps: 17\n",
      "Epoch 350\tAverage Score: 0.01\tCurrent Score: 0.0\n",
      "Noise Scaling: 0.9512056281970314, Memory size: 6195 and Num Steps: 14\n",
      "Epoch 400\tAverage Score: 0.01\tCurrent Score: 0.0\n",
      "Noise Scaling: 0.9047921471137089, Memory size: 7058 and Num Steps: 15\n",
      "Epoch 450\tAverage Score: 0.01\tCurrent Score: 0.0\n",
      "Noise Scaling: 0.8606433826830363, Memory size: 7831 and Num Steps: 15\n",
      "Epoch 500\tAverage Score: 0.01\tCurrent Score: 0.10000000149011612\n",
      "Noise Scaling: 0.8186488294786356, Memory size: 8749 and Num Steps: 45\n",
      "Epoch 550\tAverage Score: 0.03\tCurrent Score: 0.10000000149011612\n",
      "Noise Scaling: 0.7787033741169899, Memory size: 9880 and Num Steps: 56\n",
      "Epoch 600\tAverage Score: 0.05\tCurrent Score: 0.10000000149011612\n",
      "Noise Scaling: 0.7407070321560992, Memory size: 11189 and Num Steps: 30\n",
      "Epoch 650\tAverage Score: 0.07\tCurrent Score: 0.10000000149011612\n",
      "Noise Scaling: 0.704564697832001, Memory size: 12571 and Num Steps: 31\n",
      "Epoch 700\tAverage Score: 0.08\tCurrent Score: 0.10000000149011612\n",
      "Noise Scaling: 0.6701859060067401, Memory size: 14170 and Num Steps: 39\n",
      "Epoch 750\tAverage Score: 0.09\tCurrent Score: 0.10000000149011612\n",
      "Noise Scaling: 0.6374846057319378, Memory size: 15963 and Num Steps: 48\n",
      "Epoch 800\tAverage Score: 0.08\tCurrent Score: 0.0\n",
      "Noise Scaling: 0.6063789448611847, Memory size: 17590 and Num Steps: 13\n",
      "Epoch 850\tAverage Score: 0.06\tCurrent Score: 0.10000000149011612\n",
      "Noise Scaling: 0.5767910651721362, Memory size: 18977 and Num Steps: 71\n",
      "Epoch 900\tAverage Score: 0.07\tCurrent Score: 0.0\n",
      "Noise Scaling: 0.5486469074854967, Memory size: 20787 and Num Steps: 14\n",
      "Epoch 950\tAverage Score: 0.09\tCurrent Score: 0.30000000447034836\n",
      "Noise Scaling: 0.5218760262931004, Memory size: 22943 and Num Steps: 110\n",
      "Epoch 1000\tAverage Score: 0.11\tCurrent Score: 0.0\n",
      "Noise Scaling: 0.49641141343109896, Memory size: 25394 and Num Steps: 13\n",
      "Epoch 1050\tAverage Score: 0.13\tCurrent Score: 0.10000000149011612\n",
      "Noise Scaling: 0.47218933035690475, Memory size: 28098 and Num Steps: 42\n",
      "Epoch 1100\tAverage Score: 0.13\tCurrent Score: 0.10000000149011612\n",
      "Noise Scaling: 0.4491491486100751, Memory size: 30679 and Num Steps: 31\n",
      "Epoch 1150\tAverage Score: 0.14\tCurrent Score: 0.09000000171363354\n",
      "Noise Scaling: 0.42723319805780824, Memory size: 33881 and Num Steps: 30\n",
      "Epoch 1200\tAverage Score: 0.15\tCurrent Score: 0.09000000171363354\n",
      "Noise Scaling: 0.4063866225452042, Memory size: 36901 and Num Steps: 31\n",
      "Epoch 1250\tAverage Score: 0.14\tCurrent Score: 0.09000000171363354\n",
      "Noise Scaling: 0.38655724258898083, Memory size: 40156 and Num Steps: 32\n",
      "Epoch 1300\tAverage Score: 0.21\tCurrent Score: 0.7000000104308128\n",
      "Noise Scaling: 0.36769542477096373, Memory size: 45693 and Num Steps: 300\n",
      "Epoch 1350\tAverage Score: 0.23\tCurrent Score: 0.30000000447034836\n",
      "Noise Scaling: 0.34975395750443883, Memory size: 49481 and Num Steps: 130\n",
      "Epoch 1400\tAverage Score: 0.20\tCurrent Score: 0.20000000298023224\n",
      "Noise Scaling: 0.3326879328624075, Memory size: 53914 and Num Steps: 70\n",
      "Epoch 1450\tAverage Score: 0.22\tCurrent Score: 0.30000000447034836\n",
      "Noise Scaling: 0.3164546341719581, Memory size: 58649 and Num Steps: 128\n",
      "Epoch 1500\tAverage Score: 0.22\tCurrent Score: 0.5000000074505806\n",
      "Noise Scaling: 0.3010134290933991, Memory size: 62854 and Num Steps: 206\n",
      "Epoch 1550\tAverage Score: 0.24\tCurrent Score: 0.10000000149011612\n",
      "Noise Scaling: 0.2863256679165293, Memory size: 68436 and Num Steps: 46\n",
      "Epoch 1600\tAverage Score: 0.29\tCurrent Score: 0.20000000298023224\n",
      "Noise Scaling: 0.2723545868194768, Memory size: 74241 and Num Steps: 57\n",
      "Epoch 1650\tAverage Score: 0.29\tCurrent Score: 0.0\n",
      "Noise Scaling: 0.2590652158479633, Memory size: 79892 and Num Steps: 14\n",
      "Epoch 1700\tAverage Score: 0.32\tCurrent Score: 0.10000000149011612\n",
      "Noise Scaling: 0.2464242913846615, Memory size: 86711 and Num Steps: 50\n",
      "Epoch 1750\tAverage Score: 0.32\tCurrent Score: 0.09000000171363354\n",
      "Noise Scaling: 0.2344001728895552, Memory size: 92288 and Num Steps: 31\n",
      "Epoch 1800\tAverage Score: 0.35\tCurrent Score: 0.20000000298023224\n",
      "Noise Scaling: 0.2229627637029021, Memory size: 100000 and Num Steps: 91\n",
      "Epoch 1850\tAverage Score: 0.35\tCurrent Score: 0.0\n",
      "Noise Scaling: 0.21208343571256524, Memory size: 100000 and Num Steps: 3\n",
      "Epoch 1900\tAverage Score: 0.31\tCurrent Score: 0.10000000149011612\n",
      "Noise Scaling: 0.20173495769715533, Memory size: 100000 and Num Steps: 46\n",
      "Epoch 1950\tAverage Score: 0.33\tCurrent Score: 0.20000000298023224\n",
      "Noise Scaling: 0.19189142716562418, Memory size: 100000 and Num Steps: 90\n",
      "Epoch 2000\tAverage Score: 0.36\tCurrent Score: 0.6000000089406967\n",
      "Noise Scaling: 0.18252820552270244, Memory size: 100000 and Num Steps: 222\n",
      "Epoch 2050\tAverage Score: 0.31\tCurrent Score: 0.0\n",
      "Noise Scaling: 0.173621856397899, Memory size: 100000 and Num Steps: 11\n",
      "Epoch 2100\tAverage Score: 0.31\tCurrent Score: 0.30000000447034836\n",
      "Noise Scaling: 0.16515008698369826, Memory size: 100000 and Num Steps: 129\n",
      "Epoch 2150\tAverage Score: 0.38\tCurrent Score: 0.800000011920929\n",
      "Noise Scaling: 0.15709169223612307, Memory size: 100000 and Num Steps: 300\n",
      "Epoch 2200\tAverage Score: 0.37\tCurrent Score: 0.10000000149011612\n",
      "Noise Scaling: 0.14942650179799616, Memory size: 100000 and Num Steps: 31\n",
      "Epoch 2250\tAverage Score: 0.38\tCurrent Score: 0.5000000074505806\n",
      "Noise Scaling: 0.14213532951204777, Memory size: 100000 and Num Steps: 190\n",
      "Epoch 2300\tAverage Score: 0.39\tCurrent Score: 0.800000011920929\n",
      "Noise Scaling: 0.13519992539749945, Memory size: 100000 and Num Steps: 300\n",
      "Epoch 2350\tAverage Score: 0.33\tCurrent Score: 0.10000000149011612\n",
      "Noise Scaling: 0.12860292996992023, Memory size: 100000 and Num Steps: 52\n",
      "Epoch 2400\tAverage Score: 0.36\tCurrent Score: 0.5000000074505806\n",
      "Noise Scaling: 0.12232783079001679, Memory size: 100000 and Num Steps: 206\n",
      "Epoch 2450\tAverage Score: 0.35\tCurrent Score: 0.10000000149011612\n",
      "Noise Scaling: 0.11635892113259806, Memory size: 100000 and Num Steps: 31\n",
      "Epoch 2500\tAverage Score: 0.27\tCurrent Score: 0.10000000149011612\n",
      "Noise Scaling: 0.11068126067226176, Memory size: 100000 and Num Steps: 50\n",
      "Epoch 2550\tAverage Score: 0.29\tCurrent Score: 0.20000000298023224\n",
      "Noise Scaling: 0.10528063808739813, Memory size: 100000 and Num Steps: 70\n",
      "Epoch 2600\tAverage Score: 0.30\tCurrent Score: 0.30000000447034836\n",
      "Noise Scaling: 0.10014353548890784, Memory size: 100000 and Num Steps: 122\n",
      "Epoch 2650\tAverage Score: 0.30\tCurrent Score: 0.0\n",
      "Noise Scaling: 0.09994334856146551, Memory size: 100000 and Num Steps: 11\n",
      "Epoch 2700\tAverage Score: 0.30\tCurrent Score: 0.0\n",
      "Noise Scaling: 0.09994334856146551, Memory size: 100000 and Num Steps: 17\n",
      "Epoch 2750\tAverage Score: 0.30\tCurrent Score: 0.6000000089406967\n",
      "Noise Scaling: 0.09994334856146551, Memory size: 100000 and Num Steps: 221\n",
      "Epoch 2800\tAverage Score: 0.34\tCurrent Score: 0.4000000059604645\n",
      "Noise Scaling: 0.09994334856146551, Memory size: 100000 and Num Steps: 178\n",
      "Epoch 2850\tAverage Score: 0.38\tCurrent Score: 0.10000000149011612\n",
      "Noise Scaling: 0.09994334856146551, Memory size: 100000 and Num Steps: 52\n",
      "Epoch 2900\tAverage Score: 0.36\tCurrent Score: 0.10000000149011612\n",
      "Noise Scaling: 0.09994334856146551, Memory size: 100000 and Num Steps: 30\n",
      "Epoch 2950\tAverage Score: 0.33\tCurrent Score: 0.20000000298023224\n",
      "Noise Scaling: 0.09994334856146551, Memory size: 100000 and Num Steps: 87\n",
      "Epoch 3000\tAverage Score: 0.33\tCurrent Score: 0.20000000298023224\n",
      "Noise Scaling: 0.09994334856146551, Memory size: 100000 and Num Steps: 69\n",
      "Epoch 3050\tAverage Score: 0.35\tCurrent Score: 0.800000011920929\n",
      "Noise Scaling: 0.09994334856146551, Memory size: 100000 and Num Steps: 300\n",
      "Epoch 3100\tAverage Score: 0.36\tCurrent Score: 0.0\n",
      "Noise Scaling: 0.09994334856146551, Memory size: 100000 and Num Steps: 15\n",
      "Epoch 3150\tAverage Score: 0.33\tCurrent Score: 0.30000000447034836\n",
      "Noise Scaling: 0.09994334856146551, Memory size: 100000 and Num Steps: 108\n",
      "Epoch 3200\tAverage Score: 0.35\tCurrent Score: 0.800000011920929\n",
      "Noise Scaling: 0.09994334856146551, Memory size: 100000 and Num Steps: 300\n",
      "Epoch 3250\tAverage Score: 0.43\tCurrent Score: 0.0\n",
      "Noise Scaling: 0.09994334856146551, Memory size: 100000 and Num Steps: 13\n",
      "Epoch 3300\tAverage Score: 0.40\tCurrent Score: 0.20000000298023224\n",
      "Noise Scaling: 0.09994334856146551, Memory size: 100000 and Num Steps: 69\n",
      "Epoch 3350\tAverage Score: 0.34\tCurrent Score: 0.0\n",
      "Noise Scaling: 0.09994334856146551, Memory size: 100000 and Num Steps: 14\n",
      "Epoch 3400\tAverage Score: 0.34\tCurrent Score: 0.30000000447034836\n",
      "Noise Scaling: 0.09994334856146551, Memory size: 100000 and Num Steps: 127\n",
      "Epoch 3450\tAverage Score: 0.33\tCurrent Score: 0.7000000104308128\n",
      "Noise Scaling: 0.09994334856146551, Memory size: 100000 and Num Steps: 282\n",
      "Epoch 3500\tAverage Score: 0.37\tCurrent Score: 0.800000011920929\n",
      "Noise Scaling: 0.09994334856146551, Memory size: 100000 and Num Steps: 300\n",
      "Epoch 3550\tAverage Score: 0.37\tCurrent Score: 0.800000011920929\n",
      "Noise Scaling: 0.09994334856146551, Memory size: 100000 and Num Steps: 300\n",
      "Epoch 3600\tAverage Score: 0.37\tCurrent Score: 0.30000000447034836\n",
      "Noise Scaling: 0.09994334856146551, Memory size: 100000 and Num Steps: 109\n",
      "Epoch 3650\tAverage Score: 0.40\tCurrent Score: 0.30000000447034836\n",
      "Noise Scaling: 0.09994334856146551, Memory size: 100000 and Num Steps: 124\n",
      "Epoch 3700\tAverage Score: 0.35\tCurrent Score: 0.5000000074505806\n",
      "Noise Scaling: 0.09994334856146551, Memory size: 100000 and Num Steps: 201\n",
      "Epoch 3750\tAverage Score: 0.36\tCurrent Score: 0.7000000104308128\n",
      "Noise Scaling: 0.09994334856146551, Memory size: 100000 and Num Steps: 280\n",
      "Epoch 3800\tAverage Score: 0.43\tCurrent Score: 0.10000000149011612\n",
      "Noise Scaling: 0.09994334856146551, Memory size: 100000 and Num Steps: 64\n",
      "Epoch 3850\tAverage Score: 0.37\tCurrent Score: 0.10000000149011612\n",
      "Noise Scaling: 0.09994334856146551, Memory size: 100000 and Num Steps: 53\n",
      "Epoch 3900\tAverage Score: 0.24\tCurrent Score: 0.20000000298023224\n",
      "Noise Scaling: 0.09994334856146551, Memory size: 100000 and Num Steps: 68\n",
      "Epoch 3950\tAverage Score: 0.23\tCurrent Score: 0.10000000149011612\n",
      "Noise Scaling: 0.09994334856146551, Memory size: 100000 and Num Steps: 52\n",
      "Epoch 4000\tAverage Score: 0.28\tCurrent Score: 0.30000000447034836\n",
      "Noise Scaling: 0.09994334856146551, Memory size: 100000 and Num Steps: 109\n",
      "Epoch 4050\tAverage Score: 0.35\tCurrent Score: 0.6000000089406967\n",
      "Noise Scaling: 0.09994334856146551, Memory size: 100000 and Num Steps: 242\n",
      "Epoch 4100\tAverage Score: 0.39\tCurrent Score: 0.800000011920929\n",
      "Noise Scaling: 0.09994334856146551, Memory size: 100000 and Num Steps: 300\n",
      "Epoch 4150\tAverage Score: 0.40\tCurrent Score: 0.800000011920929\n",
      "Noise Scaling: 0.09994334856146551, Memory size: 100000 and Num Steps: 300\n",
      "Epoch 4200\tAverage Score: 0.44\tCurrent Score: 0.10000000149011612\n",
      "Noise Scaling: 0.09994334856146551, Memory size: 100000 and Num Steps: 51\n",
      "Epoch 4250\tAverage Score: 0.33\tCurrent Score: 0.30000000447034836\n",
      "Noise Scaling: 0.09994334856146551, Memory size: 100000 and Num Steps: 100\n",
      "Epoch 4300\tAverage Score: 0.26\tCurrent Score: 0.30000000447034836\n",
      "Noise Scaling: 0.09994334856146551, Memory size: 100000 and Num Steps: 127\n",
      "Epoch 4350\tAverage Score: 0.36\tCurrent Score: 0.10000000149011612\n",
      "Noise Scaling: 0.09994334856146551, Memory size: 100000 and Num Steps: 31\n",
      "Epoch 4400\tAverage Score: 0.37\tCurrent Score: 0.10000000149011612\n",
      "Noise Scaling: 0.09994334856146551, Memory size: 100000 and Num Steps: 17\n",
      "Epoch 4450\tAverage Score: 0.37\tCurrent Score: 0.10000000149011612\n",
      "Noise Scaling: 0.09994334856146551, Memory size: 100000 and Num Steps: 52\n",
      "Epoch 4500\tAverage Score: 0.41\tCurrent Score: 0.20000000298023224\n",
      "Noise Scaling: 0.09994334856146551, Memory size: 100000 and Num Steps: 90\n",
      "Epoch 4550\tAverage Score: 0.39\tCurrent Score: 0.30000000447034836\n",
      "Noise Scaling: 0.09994334856146551, Memory size: 100000 and Num Steps: 129\n",
      "Epoch 4600\tAverage Score: 0.42\tCurrent Score: 0.4000000059604645\n",
      "Noise Scaling: 0.09994334856146551, Memory size: 100000 and Num Steps: 140\n",
      "Epoch 4650\tAverage Score: 0.39\tCurrent Score: 0.0\n",
      "Noise Scaling: 0.09994334856146551, Memory size: 100000 and Num Steps: 14\n",
      "Epoch 4700\tAverage Score: 0.27\tCurrent Score: 0.20000000298023224\n",
      "Noise Scaling: 0.09994334856146551, Memory size: 100000 and Num Steps: 71\n",
      "Epoch 4750\tAverage Score: 0.30\tCurrent Score: 0.10000000149011612\n",
      "Noise Scaling: 0.09994334856146551, Memory size: 100000 and Num Steps: 41\n",
      "Epoch 4800\tAverage Score: 0.46\tCurrent Score: 0.10000000149011612\n",
      "Noise Scaling: 0.09994334856146551, Memory size: 100000 and Num Steps: 17\n",
      "Solved!\n"
     ]
    }
   ],
   "source": [
    "NUM_EPOCHS=10000\n",
    "MAX_STEPS = 300\n",
    "\n",
    "with ptan.common.utils.TBMeanTracker(writer, batch_size=100) as tb_tracker:\n",
    "    scores_deque = deque(maxlen=100)\n",
    "    scores_list = []\n",
    "    scores_list_100_avg = []\n",
    "    \n",
    "    noise_scale = config.NOISE_START\n",
    "    \n",
    "    for epoch in range(1, NUM_EPOCHS+1):\n",
    "        \n",
    "        if epoch > config.WAIT_EPOCHS and noise_scale > config.NOISE_END:                \n",
    "            noise_scale = config.NOISE_REDUCTION**(epoch-config.WAIT_EPOCHS)\n",
    "           \n",
    "        env_info = env.reset(train_mode=True)[brain_name]                                \n",
    "        scores = np.zeros(n_agents)                  \n",
    "        \n",
    "        num_steps = 0\n",
    "        for _ in range(MAX_STEPS):\n",
    "            \n",
    "            states = env_info.vector_observations\n",
    "            \n",
    "            actions = np.asarray([agents[i].act(states[i],noise_scale=noise_scale) for i in range(len(agents))])\n",
    "            \n",
    "            env_info = env.step(actions)[brain_name]           \n",
    "            next_states = env_info.vector_observations\n",
    "            \n",
    "            rewards = env_info.rewards                         \n",
    "            dones = env_info.local_done                        \n",
    "            \n",
    "            full_states = np.reshape(states,(n_agents*state_size))\n",
    "            full_next_states = np.reshape(next_states,(n_agents*state_size))\n",
    "        \n",
    "            replay_buffer.add(full_states, states, actions, rewards, full_next_states, next_states, dones)            \n",
    "            scores += rewards                                  \n",
    "            \n",
    "            if len(replay_buffer) > config.BATCH_SIZE and epoch > config.WAIT_EPOCHS:\n",
    "            \n",
    "                for _ in range(config.TRAINING_ITERATIONS_PER_STEP): \n",
    "                \n",
    "                    #Run training step one per agent\n",
    "                    for agent_id in range(n_agents):\n",
    "\n",
    "                        rb_full_states, rb_states, rb_actions, rb_rewards, rb_full_next_states, rb_next_states, rb_dones = replay_buffer.sample()\n",
    "                        next_actions = [agents[i].actor_target.forward(rb_next_states[:,i,:]).detach().numpy() for i in range(n_agents)]\n",
    "                        full_next_actions = torch.from_numpy(np.concatenate(next_actions,axis=1)).to(config.device)\n",
    "\n",
    "                        agent = agents[agent_id]\n",
    "                        agent_state = rb_states[:,agent_id,:]\n",
    "                        agent_rewards = rb_rewards[:,agent_id].view(-1,1) \n",
    "                        agent_dones = rb_dones[:,agent_id].view(-1,1) \n",
    "\n",
    "                        actor_full_actions = rb_actions.clone()\n",
    "                        actor_full_actions[:,agent_id,:] = agent.actor_local.forward(agent_state)\n",
    "                        actor_full_actions = actor_full_actions.view(-1, n_agents*action_size)\n",
    "\n",
    "                        full_actions = rb_actions.view(-1,n_agents*action_size)\n",
    "\n",
    "                        experiences = (rb_full_states, actor_full_actions, full_actions, agent_rewards, agent_dones, rb_full_next_states, full_next_actions)\n",
    "                        agent_losses = agent.learning_step(experiences, config.GAMMA)\n",
    "\n",
    "                        agent.soft_update()\n",
    "\n",
    "                        tb_tracker.track(f\"loss_critic_{agent_id}\", agent_losses[0], epoch)\n",
    "                        tb_tracker.track(f\"loss_actor_{agent_id}\", agent_losses[1], epoch)                    \n",
    "            \n",
    "            num_steps += 1\n",
    "            if np.any(dones):                                  \n",
    "                break\n",
    "            \n",
    "        scores_deque.append(np.max(scores))\n",
    "        scores_list.append(np.max(scores))\n",
    "        scores_list_100_avg.append(np.mean(scores_deque))\n",
    "\n",
    "        tb_tracker.track(\"num_steps\", num_steps, epoch)\n",
    "        tb_tracker.track(\"reward\", np.max(scores), epoch)\n",
    "        tb_tracker.track(\"reward_100\", sum(scores_deque)/len(scores_deque), epoch)\n",
    "                    \n",
    "        if epoch % 50 == 0:\n",
    "            print('Epoch {}\\tAverage Score: {:.2f}\\tCurrent Score: {}'.format(epoch, np.mean(scores_deque), np.max(scores)))\n",
    "            print('Noise Scaling: {}, Memory size: {} and Num Steps: {}'.format(noise_scale, len(replay_buffer), num_steps))\n",
    "\n",
    "        if np.mean(scores_deque) > 0.5 and len(scores_deque) >= 100:\n",
    "            print(\"Solved!\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_state = {\n",
    "    'epoch': epoch,\n",
    "    'score_list': scores_list,    \n",
    "}\n",
    "\n",
    "for i,agent in enumerate(agents):\n",
    "    \n",
    "    learning_state[f'actor_{i}'] = agent.actor_local.state_dict()\n",
    "    learning_state[f'critic_{i}'] = agent.critic_local.state_dict()\n",
    "    learning_state[f'actor_opt_{i}'] = agent.actor_optimizer.state_dict()\n",
    "    learning_state[f'critic_opt_{i}'] = agent.critic_optimizer.state_dict()\n",
    "    \n",
    "torch.save(learning_state,'./solverd_state.ckp')\n",
    "np.save('./score_list',scores_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last 100 Epochs Avg Score = 0.501\n"
     ]
    }
   ],
   "source": [
    "score_list = np.load('./score_list.npy')\n",
    "\n",
    "print(f'Last 100 Epochs Avg Score = {score_list[-100:].mean():2.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtUAAAHwCAYAAABpOpNzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nOzdefxcVX3/8fcn32yQFUjYspAAYd+JQVZBUbEIuFQFtRarorVocaniT4qWttaltdaWaqkLViuIgJpKZBEE2ZSwL4FASAJZIAtk377b+f3xnflmZr6z3Jm7nXvv6/l4QL4zc+fOmXvPPfd9z5x7rznnBAAAAKBzw9IuAAAAAJB1hGoAAAAgJEI1AAAAEBKhGgAAAAiJUA0AAACERKgGAAAAQiJUAwCaMrMvm9lP0i4HAPiMUA0ACTOzU8zsPjPbYGavmtm9ZvaalMt0tZl1m9nmUpluM7NDOpjPUjM7M44yAoDPCNUAkCAzGy/p15L+XdLukqZI+jtJOyL+nK4O3vZ159xYSVMlrZZ0dZRlAoA8I1QDQLIOkiTn3DXOuT7n3Dbn3K3OucfLE5jZR8zsaTPbZGYLzOy40vOHmtmdZrbezJ4ys3Mr3nO1mX3HzOaZ2RZJZ5jZvmZ2g5mtMbMlZvbJIAV0zm2V9FNJR9R73czOLX3++lJ5Di09/2NJ0yX9X6nH+3MdLiMAyBxCNQAk61lJfWb2IzN7i5ntVvmimb1L0pclfUDSeEnnSnrFzEZI+j9Jt0raU9InJP2vmR1c8fb3SvpHSeMk3Vea/jEN9Ia/QdIlZvbmVgU0s7GS3ifpkTqvHSTpGkmXSJosaZ4GQvRI59yfSXpR0jnOubHOua8HWyQAkH2EagBIkHNuo6RTJDlJ/y1pjZnNNbO9SpN8WAPDMOa7AYuccy9Ieq2ksZK+6pzrds7doYFhJBdUzP5Xzrl7nXP9ko6UNNk5d0Vp+sWlzzu/SfE+a2brJS0qfdaFdaZ5j6SbnHO3Oed6JP2zpF0kndTJ8gCAvBiedgEAoGicc0+rFFhLJwP+RNK3NBCQp0l6vs7b9pW0rBSYy17QQC902bKKv/eTtG8pJJd1Sbq7SdH+2Tl3WYvi71v63PJ36TezZTXlAIDCIVQDQIqcc8+Y2dWSPlp6apmkA+pMulLSNDMbVhGsp2tgOMng7Cr+XiZpiXNuVsRFXqmBXnBJkpmZBg4EVtQpAwAUBsM/ACBBZnaImX3GzKaWHk/TQA/1H0qTfE8DwzCOtwEHmtl+kv4oaaukz5nZCDM7XdI5kq5t8FEPSNpkZp83s13MrMvMjojg0n3XSTrbzN5QGuf9GQ1cueS+0uurJO0f8jMAIHMI1QCQrE2STpD0x9JVOv4g6UkNhFM5536ugZMNf1qa9peSdnfOdWsgRL9F0lpJ/ynpA865Z+p9iHOuT9JbJR0jaUnpPd+TNCFM4Z1zCyW9XwOXBFxbKtM5pfJJ0j9Juqx0ZZDPhvksAMgSc45f6gAAAIAw6KkGAAAAQiJUAwAAACERqgEAAICQCNUAAABASIRqAAAAIKTM3fxl0qRJbsaMGWkXAwAAADn30EMPrXXOTQ4ybeZC9YwZM/Tggw+mXQwAAADknJm9EHRahn8AAAAAIRGqAQAAgJAI1QAAAEBIhGoAAAAgJEI1AAAAEBKhGgAAAAiJUA0AAACERKgGAAAAQiJUAwAAACERqgEAAICQCNUAAABASIRqAAAAICRCNQAAABASoRoAAAAIKdZQbWZnmdlCM1tkZpfWeX26mf3OzB4xs8fN7E/iLA8AAAAQh9hCtZl1SbpS0lskHSbpAjM7rGayyyRd55w7VtL5kv4zrvIAAAAAcYmzp3qOpEXOucXOuW5J10o6r2YaJ2l86e8JklbGWB4AEejrd+rvdw1f7+936u3rb/h6T5PXmk1X+9i5xp8T9DPqvc+5+t+tcp7dvf3a3tM3ZNp6n9vd26/u3v6m5erp61dfaZnu6O0bMm299zX7js45be/p63g5RCGqz+7p66/6r3b+tf+GUV72/f1ucH3UK095vXfymZXfZXvPwOf19bvBzw6qWf0PqreiDEGUp21U1r7Sth9kuTSaZkdv3+Cy7+kb2Hb6+12kddm51vPr6evX1u5eSQP1YUdv35B2r7bu7ejta1hPw6psF7p7G7dT0sB6LX/H8vsqv3NlmSrbifI0jdrByjobxfcq17++fqet3b1ybuDfrd292tHbN/hfb0X76LvhMc57iqRlFY+XSzqhZpovS7rVzD4haYykM2MsD5A5n/35Y7r+oeVa+tWzdc9za/X+7/9Rpx00Wb9/do0k6d8vOFbnHL1vw/e/9iu3a+8Jo/XLvzpZkvSxHz+kWxa8rCX/dLYk6Tt3Pq+v3fyMnvn7szR6RFfVe51zmvmFefrE6w/Uf/1+8WAwlKRTDpykexat1fmvmaa7n1urFeu31f38D50yU9+/Z8ng43ccO0U3PrKi6Xd+9PI36pgrbqv72vf/fLYuvfEJrdm0Q5I0dtRwPfl3b9YpX7tDy9cNlOHai16r86/6w5D3Ttx1hNZv7dE/vO0IXfbLJ4e8/uFTZup79yzRrD3H6rnVm3X9x07Un373fl140gzds2itFq3erP0nj9HiNVualv/fzj9Gf1zyqn76xxebThfG0VMn6LHlGwYf33zJqTrrW3e3fN8PL3yNzjhkz8HHv3xkhS752aO64rzDdfmvnhr8V5I+cOJ+uuaBF9XTt3Nn9tBlZ8rMdNzfV6+fH39ojk6dNVmSdOEPH9CdC9cMvjZp7Eit3dw9+PjzZx2ir938jG655DS9+Vu/H3z+0cvfqHd99371O6fRI7r01MqNDb/HV99xpC698Ymm3/XpK87SLiN31ukbH16uT1/32OBnVdax7//5bG3e0au/vvbRwef222NXHbbPeP3myZfrft5fnn6AvnPn81XPLf3qwHZ18GW/0UkH7KH3v3Y/fehHD+qCOdN1zQPB68OZh+6l3z69SpK057hRWr1ph/7zfcdp6m676Nz/uFc3fvwk/ei+pXpyxQbd/pnTJUn3Llqr933vj0PmdfEZB+qzbz5YknTkl27Rph29dT/zFx8/SW//z/u09/jRennj9sBlnf/FM3XtAy/qX257tur5ey99vaZM3EW9ff068Iu/kSS9/pA9tWDlxrbmX8+ksSP14GVvHPL8E8s36Jz/uEc3/OVJOn6/3SRJdy5crQt/OF93fOZ1ev2/3KV3HjdV40YP1/89tlIP/e3APG5+8iV97CcPS5KmTNylYXvWzFuP2ke/fvylltOV60it1Zu2a84/3q79J43R4rUDbcwHT56hH967tO70Zx+5j65833GSpOvmL9Pnbni84WdOHjdK5xy1r35w75KG01TWuXa87Zh99ctHB/pDZ+yxq5a+slWLv/InGjbMmr5vxqU3tfU5R0+doF9dfErb5UtanKE6iAskXe2c+xczO1HSj83sCOdc1SGQmV0k6SJJmj59egrFBNJx/UPLB/++6YmBBrscqMuvNwvVL2/cXrUDu/mpl6te/++7F0uStuzoHRKqyx0DV/5ukWo7Ce5ZtFaSdO38ZWqmMlBLahmoJenFV7c2fO2OZ1YPBmpJ2lwKCOVALUnznqi/Y1u/tUeS9OP7X6j7+vdKZX1u9WZJ0u3PrJYkXX3f0sFpWgVqSZr76MrB98alMlBL0h+efyXQ++Y+trIqVF87fyDoffU3z0iSvjLv6cHX/qfOcmq0buY98fJgqK4M1JKqArUk/fsdz0mS7nq2ehktX7dtcNm3Uluv6lm3tVu7jNxl8HFlqK2sL9JAPZ48blTVcy+8slUvvDLwfb/12+eGzL82UFfa0duv3y1co7GjRwz57CAqw83qUn2/4aHlOnraREnS755ZrV89Wv3DbqN6/x+/WzQYqhsFakn6XWm9tRt4l6zdou/eNXRZLH91q6ZM3EXdFT2ad0S0XdTWqbJynbrjmVWDoXruYwPL6eEX10uSbnh4+ZD3Xf/Qznapk0AtKVCgbmZRqe6XA7WkhoFaGtgfXFn6+99uH1o/K63ZtKNpoJbUUaCWNBioJWlpaXuJo0+5ts3zVZzDP1ZImlbxeGrpuUofknSdJDnn7pc0WtKk2hk5565yzs12zs2ePHlyTMUF4IMmv2oCAOCtOEP1fEmzzGymmY3UwImIc2umeVHSGyTJzA7VQKheIwCFRaZGXjT/ARxxaffA3FhRiEhsodo51yvpYkm3SHpaA1f5eMrMrjCzc0uTfUbSR8zsMUnXSLrQNRt9DwDomA/ZoUgtvA9hLa0ypLGarcMv68FqQk7EOqbaOTdP0rya5y6v+HuBpJPjLAOAbOG4Ot9cKW5ZwlEmT9XKp+9ixq9LUUh6e0A8uKMikGHszIZqFThczEstjXUS9jN9CmlJqNehGccyiDomxRq7ilYJKvjwi0KeFLljhFANAHXkcj9rtQ+T/5aNPtPnYNNp2TodjoBkZb2XmGrmD0I1AK806+Ng5xGtuHvtkZy01mSjTTLNzsqi1eoCdwx7h1ANoC4ff8ILUiSCYvuCHqxEsWSjWD+dHFxRKwDEjVANZERavbR5+wk77p96fV5aDYdelP5N8jgqTLWKYx3GUc19qAtplyELQyty1sQhRYRqICPS6jhOusfaww7ytqRyomLAD23USxy+zO3PIevrOWksruCoW0gLoRpAXT72UAcpUhZ6xnxRXlblEJLEKk8r8KRSKxL80IZjm5MrQmZ52NQhowjVADwT9yXvihszWh1wdH5A0v77wgSZONYhvZvxSGN7y2JIzmKZMRShGoBXCDfti2qH3CoA+bLf76SOpHKHvwiXWOWc2gmqSawz37bZtm9T7k3N7gyB3B+EaiAjaDiBAWG3hXZDlC+hsdn3Tu2Sei0WZZKBlTYSaSNUAxlRb8fu42Xv0pb28I401knQjyR0dIbl1r40t8O024Ck+bYb8Kw4iSJUA/CKLw1yEYNUmj+Dp/vZ4V5v+D4P6pCPJxzHpeM6VJxFhJgRqgHkim+9Nqjmw+pJqiczrqwWRx33Yb2E1el6JVMjKoRqAHUxtKQzPvcMtipZq1DiS43opEeyWX325XtlU4N1wUJFARGqgYwoyh0VyfLJK6/iJJa9D4ccSQ01iWvT8fi4LVWdrlcfDoTDlMCD4qOEUA1kRJyBJ085Nu3vksqJimHf38bNX0J/VsPn015z0YsyvOdv6SQkwILLeib1rSPCt/IkiVANoKmsDQPJ+g4ySYM91KXk0XkIzFYdQc5RHZESQjUAr4Jof8gQz0+hwdUu6iC9xXEt3qzfgKOeuOpiO5tI0CKEucKJL78y1F3eAb4YbQaiQqgGMoKGH3HJWqANffOXmvdn5dvHOfa301jcKuCn0W75EfFRRIRqAF6Je7RJxkazZEQeTmalYsSB7Q1FQqgG4JVmPyVnrUc1KYF/4g95S2lflr4vww1aibKX1pdlX8vHX9DaLZKHX6EtPq6DoiJUAxlRlB6fZsEuSJgqynKqFP6KHAVcaIkobtpJs0a1+9k+XFIvT4rcnhCqAdSV1WaxVbmD7j+L0CteuywSuflLg5m0k2s6uvlLh69JhK6syPJaoo7lA6EayIii3PwF8WkURsvPJ9HLP3j5vhD1Kp4qGf1Mfdh0fCiD71hEiAqhGoBXGFOdniQDWJbWZBau1R62iJ2+38f1mIX1hXwiVAPwC1f/SEway2KwVzzEPLj6h//K66jI42tRPIRqICPqBYmowkWedntph+Y0Pj5oz1wUPdFRfb/aMqe53lotlk6HqkTZi+sa/I0WgiwsH7vb25B2m1fLt/IkiVANoKms/ZTKGNLGaldlGrcpj6LnknXsDzPzJkRRL5A2QjWQEfV2GFHtRHzaF/WH3EH79F3yKKrlW9v7m+h47oQ+K0vfKeqyehNwg9ymPOOthjfLGoRqACgKdr7J8iGspVWGNHuv2/1sH7YLH8qA8AjVAHLFk1+igUzxZQhHGD4cxKDYCNVAhsW5I8zqTjar5fZB5+Odg4eZ8vpJOv6kcqUTMl6iy73T+stqQlQI1QCaKurNXzr92j6H+trvlOaq9alaebzKBrVaXD7XO8TLp22p6AjVALyS9evaZqn0Po17JRjkSxrbcVGHf3BA5Q9CNQCvNNtBZCF4Ze0ShFKyYcTHdRhXkTz8qpHz8Tu2uwX6WCeRTYRqAJmRwbzqmfTTQ5HWYVxDp9pahumv8sR0uriL2sON6BGqAXg1ZMGnshRFOzd/Cbt+Gr0/7rCd9XrlFG+PapjhGl4vW68LF40iHaj6jlANoKmkhzPE/Xlxf5ss7uDCl9m/L90sgNY7eMjiesuCLCxWH4Z/hCmCD+WvVORtiVANIDM/fgbZeaS9g8nSiZadLKuwi7fR+6Neb0NOhIx29oFk6o6KHS6htLe3ljLQZoSV9fLnCaEaQGYE6QEpci9JFrB64kG9B9IXa6g2s7PMbKGZLTKzS+u8/q9m9mjpv2fNbH2c5QEAOnUaS6LHqzy8J83etSz9mlBP1ssfNw4wkJbhcc3YzLokXSnpjZKWS5pvZnOdcwvK0zjnPlUx/SckHRtXeQC0J60dd9b3hz7v0GuD7ODdDa36cSPOZfenZo9XSy75vB3kDcvaH3H2VM+RtMg5t9g51y3pWknnNZn+AknXxFgeIHeSCL4+3VExWFHS3cOksYOL6jOzUp/CzqPe+OE4qnlcl2prZ75Bp8xT73f738WfNi4P8lSX2hVbT7WkKZKWVTxeLumEehOa2X6SZkq6I8byAJl1//Ov6GfzlzV8fcnaLbrjmdX60Ckz675+24JVGjl85zH0t377rGZOGqNXt3RLkr571/O68OSZmjJxl2gLnoBv3rqw6vE1DzReTpL03OrNgea7KOB0te5f/EpH70tDbZDc3tPf8j2PvDh0lN4tT63SP70j2GeWh38sWLmx6vl1W3qCzUDSi69saTnNd+96Xpt39OqkAyZp8rhRVa+9+Vu/r3p864JVTee1Yv22wGWr9OTKDR29r547nlmt+58fqFvfvev5weev+v3zOvuofXXNAy/WfV853nT3tl63nVi7eUds827m5idf1thRw3XKrEmBpv/szx8b8tzzazbrsz9/TFt39EVdvIa27OjVmFFDo9cP71uaWBmSctPjL2mPsSP12v33qHp+e09yyztpcYbqdpwv6XrnXN0lbWYXSbpIkqZPn55kuQAvXPDff2j6+rv/636t2bRDF8yZpl1HDt2sP/I/D1Y9/tZvn6t6/N93L9Hdz63VzZecFr6wYbXZyfHtOxbFUozfPPlyLPNNUxT9cVf8esGQ58oHZ+34+UPLqx7/7a+eDPzeLd2td8r/c/8LkqQbH14hSTp62sQ2SheNB5a8Gun8ttUJI1+Z94y+d/eSlu+9vmZ5R+Uvrn6w7vPlzTiuS2R+7CcPSZKWfvXsIa8F7cl/+5X3auP23kjL1cq/3vasLnvrYVXP9fT166bHX0q0HEn4q58+LGnoOrrq94vTKE4i4hz+sULStIrHU0vP1XO+mgz9cM5d5Zyb7ZybPXny5AiLCOTD5gh2DFsDBBX4KakROnF+Tuy9VzkeeLp5R+Ptv7zKunuLs30HHX6wqclyi8uOGHr1PRqhF8iOHNfFOEP1fEmzzGymmY3UQHCeWzuRmR0iaTdJ98dYFgAAkGM+nf/RjmyWGvXEFqqdc72SLpZ0i6SnJV3nnHvKzK4ws3MrJj1f0rUu6du2ATlQu9WwFRVT0PXeKHMkWW/Suk15nrHsmvBs2cRxEp9v69+38iQp1jHVzrl5kubVPHd5zeMvx1kGoAji7KDp60+4haTbJjaNdnYF3gdGyjnnXW/p4OUSW0z39EubYi9LUnwOdT/5w4v60jmHa0TXzj5N3+oMOscdFYEMy2Vb7PEOMa98qEax1+VcbiytBQ2YdzyzOt6CpMXD1Z7Hk6AxgFANoC6fe3vQmbC5MtN1ItOFb87n6wKnUTLfj58Y7ZpfhGogR8I01T7vmBGvJEMIeSJZvgfMOGStjoUN2UVcx74iVAM5UJQ2tSjfE8i6NHpjaR+QNkI1kGHl/VbGOmY6VpTv2a6gvzI0uilG1nr20D7WMZJS5KpGqAZyJExPTdC7kCE/irTOi7qjL9I6ZhgE0kaoBnKkqMEB2UcgilcRli+98UgboRrIgQLsLyUV53vGpTZYcXJqPvgYJstF8rFsQFwI1QAyg/1zfUn9xB9nbyfhC2HVrZ8FqFdsO/4gVAMZlsvGlO7otoXtcc5jNUK1XLYV8FKRr8NNqAZyJExjloWhAOTtaLXbw13gfWUgaS0fVku1oO2gL/XZk2IgAoRqIMPKP3dans5CYg+TOB9qT56qsE+KtFzrftUCfP8irWPfEaoBAACAkAjVQA4UeQwbgqNDq7hSayFomoaguc4vQjWQYVE2zkW6SUTehK0H7ONRRHkZNuFb213k9oRQDeRArsZU5+irwB/0DiYsxeVdtFWdhZPMi4JQDcAv7B9i0+jgy4fjGN962zKFbUZSzjoXkEmEagAAcspq/kX6it6znOdfjQjVQI6Eaau8aejZ+wOR82Tr9oov4c6XciA8QjWQA3HkUBp6JCnugzpvDhpj4ON3K5cp9bL5t2gKP9Qpz6N0CNVAhqW+w0IuUIuQJ3QIpKvIy59QDSAzOBEpWizOaBU4S3iB+pwNeQ7dhGogw3L5M2KTBpeb3ETLp8UZd13O5bbShsJuOx6udn5hzC9CNQBJhI4iY83nVxF/3SG0+i3PVZJQDQDIPYIWgLgRqoEMqw0KYX7hzULoKGKvWxBB11yjxef/mkczPo/sSKNsWfvVLQttb1ty9nXaQagG8iBb+5DmmnyXwo4LjQnHKPng41aR5qbqe0iNetlk7SAizwjVAPzi9/4QMSHgIyyqENJGqAaQGQz/CIceLRSB7z9o0YzlF6EayJMIdya+/4SKNMRXJ+IOQr4HLUSgXlotwHqnrfYHoRrIsHJQoOOj2AiMaCSttiGVOlnQDcG3r13kkE+oBnIgV00YRwix4WfnfGp2Am+u2oac8C0EIzqEaiBP8hCa2OHEhp15vLg6zVCJLpGCHjUW9Gt7iVANZNiQxjQH+/Qi/3TYqeR2qvF9EMGgc81O4E1rsXqzPn0pRxNhj8U4AdkfhGogB2hSEYQ3QQeR8rGHPN3rVAPpIFQDAIDMy8oxo4fHQIgIoRrIMBpnSBHUA+pRfpWSJm0FktKqruW5LhKqgRxhPDKayUpPHtrTdKunSfAOw7Dyi1AN5EAcdxrMc28CagSuPvFVirhzRp7rc5DvlnSQKxfJx/HeSFeeDyoI1QBQcDnexxVC05BSwJVLjkdaCNVADtAbhCAahS8fao8PZcgqNv8Bdeu3h8sm6vWVtWF/ea6vsYZqMzvLzBaa2SIzu7TBNO82swVm9pSZ/TTO8gB5k+O2CW0IvVOlIuVenoMM/FLkqjY8rhmbWZekKyW9UdJySfPNbK5zbkHFNLMkfUHSyc65dWa2Z1zlAfIsjjHVaWHnHx+WbbzSWrxmjddtflqGdlDRfZaj3dUQcfZUz5G0yDm32DnXLelaSefVTPMRSVc659ZJknNudYzlAVLz8obtscy3Xtu0YVuPtnb3xvJ5SXh5Y+NltWL9tgRLkh2rN+4INF13X7+2dvdqw9aeWMqxZUfn9S7u/eyClzbG/AkDtvf0JfI5lZodLJVfejqh719pa3evNm5PuS3yMMCt29qt7T19Wrdl4N+1m4Ntv42sCrj9J2VVTRu+etN2bevu06tbulMqUXJi66mWNEXSsorHyyWdUDPNQZJkZvdK6pL0ZefczTGWCUjc759dow/84AF99/3H66wj9g78vtVNwmUzR//drdp9zEg9/Ldv7Oj9afviL55s+NptC1YlWJLsuPq+pYGm+5/7X9BtC1bppQ3btfSrZ0dejsO/dEvk88ya8/7j3rSLMMR9z6/VjY+sSPxzT//GnVq9ya/A54N/uOlp3frUKj2w9FUdvu94PbWy8wOeexetVXdvf4SlC+8t/3Z3Vfsy5x9vH/x76VfPzvUvZmmfqDhc0ixJp0u6QNJ/m9nE2onM7CIze9DMHlyzZk3CRQTCeWLFBknSY8vXt/W+tZvbP6ovN1ZF6BFAZ14K9auJh91+nlm4alPaRahikhaECG1hJB2oLUP184Glr0pSqEAtSU+W9i/wQ5yheoWkaRWPp5aeq7Rc0lznXI9zbomkZzUQsqs4565yzs12zs2ePHlybAUGsqZ8wJ/nMWoAsocrEqGRPO+v4gzV8yXNMrOZZjZS0vmS5tZM80sN9FLLzCZpYDjI4hjLBCAgdokYiloB/5HnkZbYQrVzrlfSxZJukfS0pOucc0+Z2RVmdm5pslskvWJmCyT9TtLfOOdeiatMQJZk7dqjyLAc9xwVXZ6uDNRKgb5qpuX5oCfOExXlnJsnaV7Nc5dX/O0kfbr0H4CQwrRVeW7o4L8ihb8iSKM5KWIbVsCv7LW0T1QEAKTNgz0zY3ARC6qVd/J8/EyoBiAp3w0dgPyjDUPaCNVAltELgwgwfh95wo8efsvz+iFUAznCT+hAetj80kVHNdJGqAayzKr+ATriw00zOFExHoVfrEX//h7Kc50kVAMAACARef5Fh1ANeKqThifKS+oxlATIBzZlIBmEaiDLSjtLfjoH4BOCPBrJ8+6KUA3kAL3K6AQHY8ijIl3NhqbfL4RqAACQeRwjZkOeDwQI1UCOhGms2CEVV5F69oqmiJt1VTuY86pNu+0XQjWQA/yMj04wbAjxoW6hvjzvrgjVQIbRwwigGafitRN5Dm21OC72C6EaAAqKXziQRwRNv+V5/RCqgRwJ0yOV54YOSIKPPcImP+6YmYSifE/4i1ANZFh5J8KuBFlHHY6Pj2E/MVQs7+T5BzJCNZADcewyC7wbRgP8moEsoJoiLYRqACg4fjbPL8bNwzd5PjgnVAMZNuRn3Rw3VohPoYcH5FwRL5vIYQTSQqgGcoCdCACfpJnli3cYkS15/vGEUA1AUr4bOjQXdPgHdSR7CjX8o0BfFX4iVAOeKuCvtkgJwz/yrWhtSZFuU57FbTfP9ZFQDeRImLYqzw0dgPyjoxppI1QDGVYOwnB9GeMAACAASURBVEX6hRfR44Aqv0zptA9pVCmqcTbkeX9FqAaAgsrxvg0lThw0wS95ro+EaiAH4mik8tzwoTPUieZYPuniIBFpI1QDGVb7Mxo7dbSjXF28+DnWhzLkUOEXa+EXAJJEqAZywItQhMzijorIkyxeEaNI8ry/IlQDGUbPNKJACEEeFOqa3BmW5/0WoRrwVNJBh/1R8bDK84/tGkgOoRrIkTBBPM+9B0BROZfS5e1oT1BAhGogF+iOQue8CEA+lAH5k/N65cW226Y8/3pCqAYS0m47wslj8E2ed4Z5Vch1lsGgWSRZPBAIilANJKTddqSToRx5bqwAdKYo7UIRjx/gF0I1kGGx7isLsiNGcEUJZwiPK8okI4u/RGSxzEERqgGg4PK8kwMrN8840PULoRrwFI0lgPAcvcbwSp73bYRqIMNq+6By3FYByJA0T7SuagfpqEeCCNVADvDzPYD60mkc0ugdpx3MhjyvJ0I1kGH0TCMKef45FqxfICmxhmozO8vMFprZIjO7tM7rF5rZGjN7tPTfh+MsDwBgpzz3GKG4HEcRXsvz6hke14zNrEvSlZLeKGm5pPlmNtc5t6Bm0p855y6OqxxAkbAzAVCJAycgOXH2VM+RtMg5t9g51y3pWknnxfh5QGGx30QnfDoG86goiECadcsqjySoWN7J84FebD3VkqZIWlbxeLmkE+pM904zO03Ss5I+5ZxbVmcaIFPuenaNfvXICn3zPcfoG7cslBTvTqanr1+StGDlxsHnbn96VUfzum7+Mi15ZYtWbdweSdngp3/6zdODf/f2h6+cH/mfB0O9f8naLaHLkLZD/vbmtIswxJpNOwbboCRdO//FxD+zrPIXuxsfWZFaOeJ2wVV/0KH7jE+7GG2ZcelNaRchVnGG6iD+T9I1zrkdZvZRST+S9PraiczsIkkXSdL06dOTLSHQgT//wQOSpG++55jB5/r6+9uaR5CYU955rNvaI0n6/A2PD772N9c/Xvc9rXzuhs7eh2z5r7sW63UHTY5sfrct6OwgDvl076JXEv/MPPeA1nP/4lf00Avr0i4GKsQ5/GOFpGkVj6eWnhvknHvFObej9PB7ko6vNyPn3FXOudnOudmTJ0e3EwDypjKIr9/a3d57+Zm0cIoWQlAMRWrKuLGPX+IM1fMlzTKzmWY2UtL5kuZWTmBm+1Q8PFfS0wIAAGhTmjecSQudIX6JbfiHc67XzC6WdIukLkk/cM49ZWZXSHrQOTdX0ifN7FxJvZJelXRhXOUB0mZtdgt2snuggQVQVPTaIm2xjql2zs2TNK/mucsr/v6CpC/EWQbAF+1e7i7I1M2Ceru7F4YCAADQOe6oCAAAMq+Qwz/SLgCqEKqBDKvt/ebmLwBQHLT5fiFUAzlVvD4bAODcEqSHUA14KmwPBPsVAEVSxPNCaOf9QqgGIIneHbRGFQH8QrvtF0I1kCO0rwAApINQDcSocghH29epDjA9IRoAAD8QqoGEtH2d6k5+1yNlow0FHIKKAqAZRFoI1QAkFfMkn6Jr+wZBsZQCAPKBUA1kGCEHAAA/EKqBHOFnTwAA0kGoBjwVJCDXThPm2tZcmgkAgM4RqoEYpRlUCcloheFDyCNu3Y20EKoBTxF44BuiCgA0RqgGcoqreQAAkBxCNZCQdn+R7KRXkJ5EAEVHO4i0EKqBDKsN6gwlBAAgHYRqIKfaDdgMFwGQBzRlSAuhGohRmI7jTnqdCcYAio4f7JAWQjWQkCQa+jDDPxg6AgBA5wjVQIbV9ky7iuhOrzWiRpVCJtBBgJQQqoGEtBtIwoZiep4BAEgOoRpISLsZN0goJjgjSVQ3AGiMUA3kCCEb7TDGCCFHaP+QNkI1ECNHKw+PUT8BIDqEaiAhSeQXIhIAAOkgVAPeSjYiMxIAQB44uheQEkI1kGFR7joYCQAAQOcI1UBC2u8J7qDrmGCMNnCiIgBEh1ANAAAyj2EfSBuhGohRZRPf/vAKdhAAAGQFoRrIMH68B4BqnB+CtBCqgRhVNu5x/DRZO0d+/gQAIB2BQ7WZ7WJmB8dZGAAAACCLAoVqMztH0qOSbi49PsbM5sZZMKDo+AkTANpH24m0BO2p/rKkOZLWS5Jz7lFJM2MqE4AOsTMBUFS0f0hb0FDd45zbUPMc1RdooXKMs7V5WiGXEAaA9tF2Ii3DA073lJm9V1KXmc2S9ElJ98VXLAAAgPbRY420BO2p/oSkwyXtkPRTSRskXRJXoYC8CHP1j0A7hpqJ2JcAAJCOlj3VZtYl6Sbn3BmSvhh/kYB8SqL3xNFFA6DguLQo0tKyp9o51yep38wmJFAeACEYgwkBAEhF0OEfmyU9YWbfN7Nvl/9r9SYzO8vMFprZIjO7tMl07zQzZ2azgxYcwFD0VCNOVC/4jPqJtAU9UfHG0n+BlYaNXCnpjZKWS5pvZnOdcwtqphsn6a8l/bGd+QPQkNPc2acAAJCOQKHaOfcjMxsp6aDSUwudcz0t3jZH0iLn3GJJMrNrJZ0naUHNdH8v6WuS/iZwqYE2be3u1dMvbdLx++3WdLrNO3r17KpNOm569XTOOf3ikRU6YsrAKKgJu4zQXuNHS5IeXPqqDt93glZu2KbRI7o0ZeIudef97KpNg3/39Q/M75hpE7Rq4w6dfOAkbdjaoxde3aKJu4wMPiaw9kTFEKl6xfpt2rKjt/MZIPd+8ciKtIsAVFm+bqvGjRqhF17dMuS1exetTaFEkKR7nivmsg8Uqs3sdEk/krRUkkmaZmZ/7pz7fZO3TZG0rOLxckkn1Mz3OEnTnHM3mVnDUG1mF0m6SJKmT58epMhAlUuufVS3LlilBy87U5PGjmo43V/978O669k1evzLb9L40SMGn7/mgWX6f794omrapV89Wy9t2KY//e79eutR++jXj780+HxZZci97/lXBv/+7l3P6xu3LBx8fNWfHa9v3/GcnlyxcfC56z92YvtfNKRTvnZH4p+J9NzxzOq2pr/mgRdjKgnQmVO+9jsdvu94PbVyo/7lXUcPPn/bglX6yP88mGLJiu393y/m4IOgwz/+RdKbnHMLJcnMDpJ0jaTjO/1gMxsm6ZuSLmw1rXPuKklXSdLs2bP5hRtte2rlQFjd3tPXdLonVgzc46int7/q+Zc2bKs7fbln9+mXNtZ9vZEla6t7VV7euL0qUEvpDOVYt7XVD1AA4Jdy+17mnLRyff02G4hT0BMVR5QDtSQ5556VNKLJ9JK0QtK0isdTS8+VjZN0hKQ7zWyppNdKmsvJivBBbaAd0RV0UwEAAEUUtKf6QTP7nqSflB6/T1Kr31XmS5plZjM1EKbPl/Te8oul255PKj82szslfdY5x+81SE2jC9KNHF4/VHO2OQD4geYYaQva/faXGjjB8JOl/xaUnmvIOdcr6WJJt0h6WtJ1zrmnzOwKMzu38yIDyRs+rLPrPwc94bDTcM5OBACG4vKiSEPQnurhkv7NOfdNafByeY3P9ipxzs2TNK/mucsbTHt6wLIAiWs0/CPOe62wTwAAIDuC9lTfLqnyOmG7SPpt9MUB/NQoPLcKvkGDMTdCBIBo0B+BtAQN1aOdc5vLD0p/7xpPkYD01YbhVpk3jtuDE7QBoDMEa6QhaKjeUrqmtCSpdIUOrleD3CHIAgCATgQdU32JpJ+b2crS430kvSeeIgEeapG24zgpJsgsOQYAgAGcnIi0Ne2pNrPXmNnezrn5kg6R9DNJPZJulrQkgfIBmRZ3E88uBACGIl8jDa2Gf/yXpO7S3ydK+n+SrpS0TqU7HAJ5VHspvDTGVAMA2kegRlpaDf/ocs69Wvr7PZKucs7dIOkGM3s03qIBaYg2HPNzJAAkg9YWaWvVU91lZuXg/QZJd1S8FnQ8NuCNTjNuw0vqJVwOAEBrNLFIQ6tgfI2ku8xsrQau9nG3JJnZgZI2xFw2AACANhGpkY6modo5949mdrsGrvZxq9v5W/YwSZ+Iu3BA1KIe+tzp7KIqBz3eAFBCe4iUtRzC4Zz7Q53nno2nOIAnhtz8pX4KbtWG08YDQDJ2nmBunM+CVAS9+QtQCI16kFv1LMdx7Q92CgDQCdpOpINQDUSgURMeNBeTnwEgHNpRpI1QDWQYl8cGgGqEa6SFUA3UUdsmt7z5S8jP6zQcs/MAAMAPhGqgQqNsS48wAPiNPgakjVCNQun45i+d9kU3+Dx6mAEgWpXtKm0s0kCoBjzADgAAgGwjVKNQfBnG4Us5ACCPHINBkAJCNVDHkJ7jjkd/BGvY64VsdgkAEFy5vaXtRFoI1UCFdnuQ0x62QW8MAAB+IFSjUALfjKUmrLa8pF7GwjgA5A0nKiJthGogAGuRmhs14NxREQCSQTOKtBGqUShBe5Q7voRexOUAAADZQKgG6mh3rHLYkNzp++MO/wCQNc5xtgnSQahGobQaZtEopHYaXRt9XFTDPdh1AEAJ4+iQMkI14IF6+wL2DwAAZAehGoXiy1hmX8oBAHlR2Q9BpwTSQKgG6qhtkDsNwS5gy07IBoBwCNJIG6EaqNAo3BJ6ASAbyNZIC6EahRL85i/VGp3A2OmJgpGdqMjeAwCG4CRupIFQDcQoaLNOOAaAcIIOtwPiQqhGoQS/+UvQ6TobF8JwEgCIB9kaaSFUA3UMGf7RIARH9RMjIRsAwuHqH0gboRqF0vrmL51pOOa6wecFafAZEwgAwZXbVTopkBZCNVBHVsbmsfMAgGoZab6RQ4RqIACLKL02Cuud7gTYeQAA4AdCNQol6Z7d2iEc/DwJAPGgjwFpI1QDFaLqkW7/c1P5WADIHcI10kKoRqEEvvlL7W3KQ85vcPoO3wcAaK5yeF1WzotBvsQaqs3sLDNbaGaLzOzSOq9/zMyeMLNHzeweMzsszvIAiatp16MeUw0AAPwQW6g2sy5JV0p6i6TDJF1QJzT/1Dl3pHPuGElfl/TNuMoDSG3c/CXi6aJ6Xy3COAAAfoizp3qOpEXOucXOuW5J10o6r3IC59zGiodjxFAoeGLI8I+oQnBsEwMAyuhwQBqGxzjvKZKWVTxeLumE2onM7K8kfVrSSEmvj7E8yIgv3PiEnlixXr/+xKmRz7uyof3e3Yv1Dzc9LUnac9wo/fYzrxt87dSv/04L/+EsjRreJan1zV0Wrto0+NwxV9w6+Pecr9xeNf2sL/6m7ny+NPepIc99/54lTb7JgAUvbdSMS29qOR0A5F25Pf/9s2v0+2fXpFwaFFHqJyo65650zh0g6fOSLqs3jZldZGYPmtmDa9awoeTdNQ+8qCdXbGw9YUjlBliSVm/aoVc2d1e9vm5Lz+Df7fRUr9/a03qiAG5/ZnUk8wEAAPGLM1SvkDSt4vHU0nONXCvpbfVecM5d5Zyb7ZybPXny5AiLCDRWeY1pfkoEAADNxBmq50uaZWYzzWykpPMlza2cwMxmVTw8W9JzMZYH4HrQAAAgFrGNqXbO9ZrZxZJukdQl6QfOuafM7ApJDzrn5kq62MzOlNQjaZ2kP4+rPEAQjUI3YRwAADQT54mKcs7NkzSv5rnLK/7+6zg/H8VyyN/+Ruccta++8a6jG07TzjAOhnwAAICgUj9REYjK9p5+/fyh5ZHNj0wNAACCIlSjUBjGAQAA4kCoBgAAAEIiVKNQWo2TruzJdgEGVTPuGgAASIRqYFCQEA0AAFAPoRoAAAAIiVCNQuFERQAAEAdCNVDiJJlI3QAAoH2EahRKpzd/IWoDAIBmCNUAAABASIRqoKRZLzbXBQEAAM0QqlEonKgIAADiQKhGobRz8xcAAICgCNVACI6BIQAAQIRqoEJ1QK7s1eZmiwAAoBlCNQol6uEdXNcaAABIhGogFIZ/AAAAiVCNgml62TxXfZMXAjMAAAiKUA0AAACERKgGAqDXGgAANEOoBkpqYzNX/AAAAEERqoEKxt1fAABABwjVQAN0VAMAgKAI1UBJ7dU/gr4HAACAUA1UaJSRCc8AAKAZQjXQgAuQpBmCDQAAJEI1CqZVTmb4BwAA6AShGijhWtQAAKBThGqgAdfgbwAAgFqEagAAACAkQjUKpdkQD+fU/qBqAAAAEaqBhjgJEQAABEWoBgAAAEIiVAMlzXqmg1yzGgAAFBehGmiIIA0AAIIhVKNQor75CwAAgESoBgZx8xcAANApQjVQwWxnXzXDqAEAQFCEagAAACAkQjUKpZ3OZzqqAQBAULGGajM7y8wWmtkiM7u0zuufNrMFZva4md1uZvvFWR6gmdrhHgz/AAAAQcUWqs2sS9KVkt4i6TBJF5jZYTWTPSJptnPuKEnXS/p6XOUBAAAA4hJnT/UcSYucc4udc92SrpV0XuUEzrnfOee2lh7+QdLUGMsDtKXyaiCNeq3pzQYAAJI0PMZ5T5G0rOLxckknNJn+Q5J+E2N5Mue+RWs1dvRwHTV1oiRpw9YezXvyJV0wZ3oq5Vm7eYfueGa13j17miTp6Zc2atXG7Tr94D1DzffRZeu1YOVG7T5mpM46Yu/B53f09mnU8C79buFq7TNhtA7Ze7weeXGd1m/t0bJ1W3XA5LF6+IV1Wrx2i/75XUcPvu/FV7Zq3pMvqctMR06doJXrt1V93i8eWa6TDpg0pBxX/HqBFq3ePPj4wh/M1xfPPlQr12/TnQvX1C37fc+vDfXdAQBAPsQZqgMzs/dLmi3pdQ1ev0jSRZI0fXo6gTIN7/3eHyVJS796tiTps9c/ptsWrNKRUyboiCkTEi/Px3/ysB5Y+qpO3H8PTdt9V73l3+6uKl+n3nblvYN/V87rvudf0RkH76kP/nD+4Gtv/8/76s7j5AN3huTL5z45JASPGdklSdq4rUef+tljOmivsUPm8cCSV6sev7xxuz5xzSNNy/5Pv3mm6esAAKAY4hz+sULStIrHU0vPVTGzMyV9UdK5zrkd9WbknLvKOTfbOTd78uTJsRQ2C9ZsGlg8O3r7U/n81Zu2S5J6+pL5/O42vufW7t7Bv5es3TLk9f7SMI3e0h+rN9WtagAAAB2JM1TPlzTLzGaa2UhJ50uaWzmBmR0r6b80EKhXx1iWXLGU7qVtaX0wAACA52IL1c65XkkXS7pF0tOSrnPOPWVmV5jZuaXJviFprKSfm9mjZja3weyAULgFOQAAiFOsY6qdc/Mkzat57vKKv8+M8/PzxpdYGGU5nlq5IZL5fOfO5wf/rndFju095aEkvixFAACQJ9xRMYPSGoQRx+ee/e17IpnPSxu2RzIfAACAThCqAQBAok7cf4+0iwBEjlCdJZ7cacSTYjTE+GkA8BvnvSOPCNUZlNpVOGgEAQARIFQjjwjVKBTfe9kBAEA2EaqRO82CM5kaAADEgVCdIf4EQn9KAgAA4ANCdQbl6ZJ6ScvDdwAAAP4hVCN3GP4BAH4zujiQQ4TqDPHlJDtfytGJLJcdAAD4i1CdQaldUY9rIAEAANRFqEahOLqqAQBADAjVGeLLnQL9KAUAAIA/CNUZlNYJHnkY/MEBAQCkj9GEyCNCNXKn2RCPfoZ/AACAGBCqM8SXPOhLOQAAAHxBqM6g9K7+kc7nRooDAgAAEANCNXKnWW4mUwMAgDgQqjPEl2EXvlyFpBO+LEMAAJAvhGoElofbymb5gAAAAPiLUI3coTcaAAAkjVCdIb5kxThDa9x3PCRwA0D6LBdnvgPVCNUZlOerf8QdesnUAJA+IjXyiFCN3Gk2bjrunnAAAFBMhOoM8SUQxjr8I75ZJzJ/AEBrtMXII0I1cqdp6KclBwAAMSBUwyuxn6hIqgYAADEgVGdQ2teLjjOYxj78g0wNAKnjREXkEaEaudN09AehGgBSxxX1kEeEaniF0AsAALKIUJ0h5cCZ3nWqraoccYh7zDOZHQAAxIFQjdxpFvp9uSwhABQZoz+QR4RqeKUy88aRf4nUAJA+2mLkEaE6Q8pDI1Ib/pH4J0bf7NJRDSDLOMEP8BehOoPSvqSe/7j7C4B8ykvrn5fvAVQiVMMrsQ//IFMDAIAYEKozJO1AWP7ZMamrf8TxMWRqAEifMY4FOUSoziDaouaaX/0juXIAAIDiIFTDK3EP/wCALKOHF/AXoTpD0s6Yg8M/YiyJq/o7hqt/pL4UAaBzRGrAX4Rq5E7Ta3+QqQFkWF46qnPyNYAqsYZqMzvLzBaa2SIzu7TO66eZ2cNm1mtmfxpnWfIkz8Gw8o6H3PwFAKpxSVXAX7GFajPrknSlpLdIOkzSBWZ2WM1kL0q6UNJP4yoHopOHxpzblAMAgDgMj3HecyQtcs4tliQzu1bSeZIWlCdwzi0tvdYfYzki4ZxTd1+/Rg3v0uYdvRo+zDR6RNfg8929/Ro+bJiGDZOGDxumfufU3duv0SO6NMyktZu7NWnsSG3c1qsRw029/U67jOhSv3MaZqZ+5zSya+AYZ1tPn0YN7xr87L5+p37n1Nc/EAh7+/vV29ev4V2Nj4m6e/vVNczU29+vkV3DBstefq3fOY0e0dXw/ZV29PbJZOrp27maeiv+3rS9R7uM6NKW7j5t3Naj3ceMVE9fv9Zu3qHddh2pzTt6tfuYkdre069N23s0zExdw0zDu4aG9Bde2Tr49+pNO7R+a/fg45c2bAtU3le3dDd8beX67ZKk9Vt7As2rmcVrNoeeBwAAyAeLq+euNJzjLOfch0uP/0zSCc65i+tMe7WkXzvnrm8139mzZ7sHH3ww6uK29LP5L+rzNzyhuz93hv7k23dr/0lj9KuLT9F37nxeX7v5mYbvm7jrCJ18wCTd9MRL+uybDtI/3/psw2m/fM5hennjDn33ruc1c9IYLVm7peG040YN1xN/9+aGr8+49CbN2nOsnlu9WUdOmaAnVmzQPZ8/Q1N321UzLr1JkrTgijdr15HNj6seX75e5/7HvVXPfes9x+iSnz3a9H0A4LNdR3Zpa3df1XNTJu6iFeuDHbyn5cA9x2rR6uwf0L/+kD11xzOr0y4GMmTpV89O5XPN7CHn3Owg02biREUzu8jMHjSzB9esWZNKGeY98bIkadGazdq0vVePLd8gSfrVoyuavm/91h7d9MRLkqRrHljWdNr/e/wlXTv/RUlqGqgladOO3pZlfq7U8D6xYkPdeW7e3noeDyx5teU0RTN21HB97qyDQ89n/8ljqh6fOmuS3n7slI7n949vPyJskRI3ZmSwX0viMnHXEXWf/5s3H6y/f1v18vzZRa9tOb/vfSBQu9vSh0+ZqQtPmtF0mr3Hj2742lfefmTbn/nJN8xq+z1RmTNjd73psL3aft+/X3Bs1ePTD54c6H3/+p6jdf+lb6h67pvvPlo3X3KqrvvoiXr8y2/Sh0+Z2XQe7zhuir71nmOqnvvGnx6lH37wNYOPm9WHP3vtflWPb/z4SYHK/idH7K0ffvA1+sTrD2w63d++9TDd8Jcn6beffl3Leb7r+KmBPjtK/QE79P7mzeHa2ivOO1zHTp+oT515UNPp9p88Rpedfaiu++iJQ16bNHZUqDJI0v9++ATN++Sp+sCJ++mCOdMGnz9g8hi9e/ZU3fqp06qm33fCaH30tP31H+89tnZWdbVqL+L0ruOn6ts122K9un/Vnx2vd9Ts46btvkugz/jGnx7VeQETFGeoXiFpWsXjqaXn2uacu8o5N9s5N3vy5GCNZlJGNBmCUSuL43l7+oaWubvP+9E6sSjvsL99wTFDdoid+N8Pn1D1+McfOkH/+p5jdOSUCU3fd9TU+q+/74TwZZKkc47eN/C0Zx7afhCqNHlc+J1VGLvvOnLIcycdsIf+6owDh6zjmZPH6II505vO78wOgmE9l731MH3x7EObTnPWEXs3fO29J+wsZ9BA8MaQ6zKM6z52oj52+gFtv++co/fVHmN2rsOrPzin7nRn1ITttx87VRN2HaGzj9pn8Ll3HDdV40aP0JyZu2v86BG67K2HaZ8J9Q9cDpg8Rt989zF6W01AeNfsaTrj4D0HHzerD7UHbcdN363udB84sWa7NtMZB++pz7ypedj80Ckzdfx+u+nAPcdWPT9p7EiddlD18jjvmIHvcfKBezSdZ5SCnqFzQE3nQ7s+cOIM/eLjJ+uvz2x+0Dh991314VP315yZu0dahmGlL3r8frvpsH3H64rzjtA/vWNnQPz7tx2hr//p0Tpor3E66YCdy//ycw7TF/7kUL31qGDt8XnHBJuuk4PXWqOGV+ee3ceO1MkHVNedenX/TYfvrQ+eXH2w+oZDWpfnpAP20LtmT2s5nQ/iDNXzJc0ys5lmNlLS+ZLmxvh5qag3LriR7EXq6rHTZT0FDdXlYyKTtXUwFTWfThfNy+W9gvNnK87bsu+0zyHI2zpdaxnsB2nJl5vHBF+0fpS3U62Wd9IXAIhj/20yb+pV2mI7UdE512tmF0u6RVKXpB84554ysyskPeicm2tmr5H0C0m7STrHzP7OOXd4XGWKQuWQiZXrt0UartZtbXyCXT1bdvSqq3TCZKX+/mDN1cbtvZq4a79Glo46N23v0fNrtmjsqC6NHtGl4cOGadWm7UPe9+zLm9oqZx6NjGC95+FqKmG/AQ2xP/K8KrIcjmtXS+htLuT7k+ZDvfShDFGp9+tzmoIs2ywt/ziv/iHn3DxJ82qeu7zi7/kaGBaSGZ+45pHBv0/66h3at8HPg/W0atgXr2k+jrrW4V+6RTMnjdHvPnt61fM9/cGORM/85l06ddYk/fhDA8MQjvzyrYHe96P7X2irnHk0bFhnW/ne40fr5Y1DD1Qqhbnr4/6Txmjx2i06ZO9xeublTTpm2kQ9umx9W/M4csp4/d9jKwNNm6XGLqhjp09s+FqWwxnal9c7sNZutnn9nu1Ia9uOqg1t1EHxmhm7af7SdYOPj5o6QfcsWhvNh1Z+fsDp8l7XMnGios/Wbg7euxxHZap3QmM7jcPdz0W/cZW1Goc2e7/6YwjTdMdnXqeff2zoiSpnHrrXzrVXaj3u/OzpmvfJU3XFecF+/4U83wAAHlxJREFUXLn1U6fppk+eUve1ey99fdP3/uELb9Dtn3md/vCFNzStRb+8+GTd/bkz9POPnai7P3eGfvLhE6pOILnlktM09+KTm37Wh0/Zv+7zUybuots+dZo+WXGCVCe97TdfcmrF+8N73UHRnWfxhbccok+/sf5YVZN5FaqjLkuQ+e01vv747C+fU3sLguQEOVel0+BSnvXVH3yNPt7BmO9WHvjiG1pPFLFhARdGo3M3ktastPvtsWtkn+PRpl0STdq++oNzBsd1f/f9x+nTb2x+wmZZ7Tk/zYQ5MMjDL7aVCNWIzTvrnFF++sGT1VXawv+ixdn1aZg5aYzGjhr6A0693ssZk8bosH3H170sYb0TnA7aa1zVtcXLDdHkcaM0ZWLzM6D3njBaB0weq71b/DIyfvQITdt9V40r/Tt21PDBE0jGjOzSwXuP0yF7j286j0a98IfsPU6z9hqnw1ucSNlK1edH0J6G2vnXfP5Be48brJ++8OnXgIm7DD2xU5Km7hZduIlD2EVYu+1GZc9xwX/pbHSlmnbVq0/1gk3tCY5paTZErNGJpJGXIcPBb8yo4Zqxx0AH16w26vHJB04K/Bmm4O1U7TFwoOEfGVr+hOoEJdXL5UtvWqsNwdfNJO0QE/X6i3PcctrLKmlp/HQZtj4UbR3V0/GJipGWIho+lqkTUVTLLIStViVM8hv4kA08KEKsCNUJSqoy+TJmqVWHn48nqZlZ3YbabOfPzEFOHGrUePnwlTv+Kbz8b8V3C/t9PFgcVVqVJ8mdUtLLJsy6jGaxdDaXOFfJ4BV/UqyoUbeT9XoV6+4z/NiNNN0OhkWYYNK65G1U67fpXGKuv2adH+D4tg8Ii1AdVt5qRIRatRU+BMwotNMUW4O/sypsT1EUO5SklmNS9dXn7cLnsjUT/ooZWegTDabZNufjt2xW55Iqbxr1PkvbWjvrofbgJW9X/yBUJ4jhH7Wv+ymKDTjMrwWRD/+IaD47G8PKruqIZp4RnmxaaFOIrTHi+XUu6XY97o+LYv5ZCluNJPsdaMHiRqgOq606mkyF9mWzadVYBD0LPWn1SlV5gFDb09POt4iiZzatg6Z6H+vFNXMjrEc+DEmKugRJ1Jc07xabxEeb+RPgwl8bvvFrlZ0BQW8jHjdflnsS4vqu5dlGtUrrlrPDsvvQ5kaJUJ1DvtwOvVVozsu21M738OEr+1CGsrTrQJDx8UkbctDmQ6FK8rYDDPptTH4OjejEwPjXmufqnUeSTHFCyVJ9DFLUuHbdcS+ndmbvRzqJD6E6rHYqU95rU42sjqlut1z11muYdR11NYl6OVefqOjpSgyo3WWdxW0446soVq1WZxbXdyfSOLndt2qZ2s1f0vnYUOotq04vqZc3hOoEJXf1Dz9ksbEYUP/qH41fbWPOESwUn0KSR0WJXZG+a7t8P7jqtHS1N3wKOz8fmKzh+vKxN75ZmaIsbbMDC8+rd+pC7RMjK4UfCNVh+ZJgK/hyJNjqVt4+NuCdKEqDW65XUVavrNUBXy5XKfkzzEuKpiydziKJ5ZC1ehoFb2pXzhd9kvuP2NaptXX9j5r3RlyWlBGqw2pr+EdSl/9I5mNaabloPN2YGjVy7ay+RpMGaXpa1ZN2q1FUgaDedap9EGU1armDS+KkuPg/omM+l62Zjm/+UlHZ0z54jmr/kaef6dNeJ9Fo9KtB9J/gwzr1oQxxIlSHFUHQyq2MtnjlUjca8hHma/mwSHz6qd6jonhjyI05PGo4ira+you+3sl9aQlbHaI+ByRuzZZ7pMM/PF4GQaR6g6JQ7/Vly4oGoTqHfPmJuuUdFZMpRuyKFjSKyswS3bJ8OvhpJYrlEuetxKO+9KMfLWznslOz/NgOwgS/rJ6w365O11Nevn8ZoTosD6/+4csRd+tL6vm5NZXLNXRHGnzB+jTeNao9aPk7+XLQVhbql4Mhj5vPLIvjdxMdHpMz1Ve6Sa8cleK4TnW95/zayuuLch/SbNPu9GO8qTOlcvjQdndSAl+zQj2E6gQldTH9Zp+SZNhrtRn4upnsHP6xs4TVQ0GqS97OIs1Q2xBI2O8TzW3Ko1uoXqwfH8qQAh+/drm9zNJOPW+SWvLNAmcafSRR1rm4h1iEGR6Vty2LUJ2k9A8SE1WU/VBRvmdZlDuYrC06nzZhr8oSQWE6nkWAN4Ytng/1NOn17cuvbXlvX5P8erHdXKada3/UXvwjZ+uXUJ2gxK5T3WTLSbKdbHWk7fvGVDsmvNGyq9egtDNtu9r9Ca92OXd8zV4/9rGxannxjxxf/SPI9pi3k4paqVzdafVWR/2x9WZX9+TFaD82FkmtkThXfVT1qun1vBNYULEuo/hmHTlCdYK8GP6RSAkGtB7+kZ1NpbKsQ67O0MZSTfNWtT7K0s1wslNb4+P7gXAjHRe7tC1m9Xs30uj7+Pg9kwqLPvTiVr8vO9q6TXnNgs5SDgiCUB1SO9WhSGFJan2ioq8yWuzERHrzF5Z1x/xqT1K8+UvoT24tzR1/kuvZrzqVD606XRrVrHZXRZDOnajWb71fP4NuI3mvYoTqBCV15m2zDSfRExUzeikhN9g7FeyExLrDPxrMO42vHNVnluuvL2MtY9FiYSUS4Gp3WB5tJx4VJXE+rYcw6g03yO53y07BfeiR9eHqH3lHqA6pnXzRn9gNFZuMqU6mCJICXFIvoXJEodGNYGpfaz2f1hO37tkIt+Si3IFmaR1mRdD1G/1Y2zAz9LsmhL4Gdopfb3A9RzoUJUCHgSf5K6nA78nX9UKSB1nZPaCrj1CdpMTOVGzyUqInKraaIJFitK3djTzpjtu0ehviOJnJh96boMz86qWPuijh6lV6yyXIOonj2s55VPk9fenVzMuib7Q8G45vb3P+Sbal9a7gEXQbGfLeaIrkDUJ1gnxppJKS1Wu7ljf6IVf/aGP9NTopNZXhHxGtB4/yZJUol2mzHZNz6Qz/8Gq5Z3Sb7lRlYPflADCa+pDc+Ns4RXqicwzfN8hY46jqVbNlUd4HBF2nftT0nbLU7BCqQ2rvLnsxFqTyc5q+5tPNXzK0pVQKUey8Xf3Dhx7ASIezeFAlreZfn/hYpjiVN0WTB3Uj7c9PS7OwGOHs89zp1Xavd5uVvZ3phyzn1DesaBGqQ2onACV3nerOXotaVk9U9LVcvijqzV/c4P/84FMIiOTmLx3OJJlfDzyoqQl8UR8P6DPb+RKQD1UrUQz/QDPttEHJXafaj5ax9c9efgt+iaB2rlOd/rf2oQy+KMKyCPoV8x5eOuFDyIx6vQSdW9ybRhTbXmLXqE+hnUizaWr5K3OdCbj5ywBCdUAF2PdGLqoTMHzRaAcb/QljnZUjboOX1IvyoC2SHWuCJ+h4csCK9nRaR8rrO6ttVruqTlT0pKonFe59+b5Z1NbNX0K8NwsI1QFF8/Nm+HmE/RwfbiQwOE4xQ1tTZVmD9BzlsYGO4zv5VgOalcc5l8xtyj3eLhoVLYrF0vFl7wK8MexVW8xq6kYK23eUHxlsmUX4gXXnH+wDmm0NWfp1Jc19Qnm7DXyiYpKX1MvQOgyCUB1SUkM62uHLiYqteJwd2lL3UnMe1gu05kOgTb8EjflctjhUbsYeVA1JEZQj6KXPPNpXxCnIxT86XeQ25Gis3jQdzrytcrQ5fYtC19u9xRmOfWiXgyJUB5Shddo00PlwomKGFmWVdhZdmEbA10BeLlV10Ai3NrO0XUn5/AXCFz5WhZ1X/0i/dHG2C3Xv/eJJXY87UMU5+zDrLEttYzvbR71rXOcJoTogXxqYPKi8TFVWVJZ1yHWE60zvazCOQqGv/pGEDm+iEPpjA3xuo4ATyfC4jt8X/5oZ6HDMUm1tLi+tUxSBLPamusX8G9WrOMoVeFspFalhx5gNfRz45i+5qX31EapD8jE7NR1TnVwxWvL9CDXMxu/Tcs67vF6nevCxB2XKuiz9fNxIVN+h3lzqPleQq3/sHG8cfatddS5OqlfzyH79zwpCdUA5aJMl+dGDanX+yoSGV/+Idpmmv4Ya8LZgyRi4o2LyC8GHE5xbyUv7OESjZZLi9w1bH4K+3YNdhaQEwn1pZcbeYd3mB8TxvdstQzt3YAxaXG5TDkn+NDB5kJVFWXl0X9nABWoEsvIl27DzknrR8a0HsenVP5Ts1T9aLZo0qlijIqV5daTErv7hV1UNJcjy8KUJy/zVPzw6UTHoOm23SFxSbydCdQ4x/CMaQXslfVqmQKeCjamOvxw+8WH8Z9TL3DS0zUr/W3YosZu/+D/vOIbBtTPPODtIstTsEKoDytLOpNmOwIced6v5NysS28F6sI7qKdedyl6uhK7u1WIeydUkT1cNYlKu6kPqWBrXqY6w8Q6yxXhzneq4N+82r+GMekM4Ol9Jvv1aGRahOqAsbXBNy+rB9/CgCIFUDf+ofD7A5T+y8h07Ee3wjwhnFoGm5XHJtAO+LZNKDa9UkGKNT+KTB4Z/+LFiIrniRYRTxc+P5R6XRttUu0G1Wds0eC3uwDfciW+Z+3BeV5wI1UiNLzupRoIP/xg6XazXlM13m9S2MNVo6FvTr5NRlyAT405j1vltyvPHzAKeLBb39aEjuPpHFOUo/RvLzV86fF/k2lzWrSav93qc39XzqFCFUB1QllaqL3dUbLTIMjv8o41FF+rmLx2/M15xlCt7gc/XtYM4lA+Ofailcda8+vP2o67Hf2m/+Obt5EfdiRsnKu4Ua6g2s7PMbKGZLTKzS+u8PsrMflZ6/Y9mNiPO8oSRpd5BX+6o2OijBm/+kqGNqd3rjebxJ67B7xTp+I8I5xUzp6SGfwRbKGnc/KXR+orm5i+dXv4j/Ge3Ypbe4V8cnxtkkfnShDW9+kcEO5G0v2dU+8FAV8EJOK9OOr4Cf48Ix2P7KLZQbWZdkq6U9BZJh0m6wMwOq5nsQ5LWOecOlPSvkr4WV3mKxPMh1blTrzFjOScnyibZhwM9D4rQkM9li0PlduxD3YhCTr6GpIiGf+wccNxkms4+KcRxaqQrqv1L5PlWS3wrT2Nx9lTPkbTIObfYOdct6VpJ59VMc56kH5X+vl7SG8y/tSkpPw1qkloN/8iaVj3vkX1O2l0nDbjBfyvKF3JlRrpTjNnAzV9QJDuv/lE8vtT1uCNBUjd/iVuQX3ri2rWYWfBf2GrKmbdsNTzGeU+RtKzi8XJJJzSaxjnXa2YbJO0haW2M5Wrbwpc36c6Fa9IuRkMf+MEDVY+3dffWne5rNz+jcaNGtHx/nIYPy+Yw/rZv/hLC2NFxbpZ+GTncr/rQat2OSqC8Pu9kfC5bnMyKGax90Hz4RwTzT3nFJnnzl8DTtzv/NqeP6r0+ysTe28wuknSRJE2fPj3xz+/t79eMPXbV0le2ShrYse7o7ZckHbL3OD3z8qZA8wky7e5jRurVLd1tlW/jtp5A03UNG6ZtPX01z1ng99dz6qxJuvu5+sdApx40WXuPH62XN24ffO5jr9tfH3vd/rrh4eU6bJ/xg89PHjdKazbtkCR9/Z1Hadgw02d//ljV/MaNHq5N2+sfMDTyjmOn6MZHVkiSZk4aoyVrt1S9fsNfnqR3fuc+SdJ+e+wqSZq62656x7FT9BenzNQ3blmohS9v0tuPnaKTD5ykb972rI6eNrFqHuceva++cOMTkqSfXfRa/fDepfrcWQfrn29dqH0n7KK7n1ur956ws97+xckzdcYhkzVp7Ci987ip+vOT9qua35fOOVx/+ZOHtHZzt846fG/NnrFb1evfOv8Yvelffy9JeudxUzV6xDCde/S+DZfBmJFdes/saXr3a6YNPvf+107XUVMm6nM3PK6Zk8booL3G6rSDJmtDqS4cPXWCHlu+QXNm7K7e/n6NGTVcXzpnYPTWW4/aV5+/YeD7/s2bD9ae40Zr9n67afm6rXpk2Xqt29qj51Zt0raePh0/fTet39ajh15YpzcdtpeOmT6w7D562v6atvuuOmivcXXrz1uP2kdHTJmg3ceM1JK1W3Tc9N20Yt1W/fbp1Vq7eYeckxau2qRRw4fpvSfsp6/Me0aSdMSU8dp7/C76yKkz9aP7l+qjpx2g8668V//wtiP05IoNunb+Mn3tnUdqr/Gjdfdza/Wu2VP1nTuf14uvbtXqjTt0xJQJVeX49gXH6pPXPCJJ2nPcKH3i9bPU3duvj59xoP7794s1f+mreqW0vX7i9QdKkn544Wv0wavn68A9x2rR6s36zvuO0//7xRM6etpEjRk1XPcuWquPnLq/7nt+rY6cMlEnzNxd1z+8XFt39GpbT5++8JZDBz//vSdM19uOmaIrfv2UnlyxUXuMGam3HztFw4aZPnzKTN3//NrBdqm83D5w4gxJO+v2Dz/4Gt317Br98pEV2t7TVzX9OUfvqwMmj9GBe47VgZPH6rxj9tXazTv0tmOm6LYFq3TElAnaa/woTd99jOY98ZL+4pSZ+udbFupPjtxHT63coA3bevS/f3xRZx66l7757qP1/9u78yCryjOP499fWjYXGgRsgQYbhp5CEEHogICkMmQmuM2okQQcKi5FYpIyaKpmBpfU6IzjGGepqGSMNSZqSCaiuEKphRKwIllGaVZZDHQUZZNFaJQgqPDMH+ft9gaGIHVobnff36fq1j3nueeefk8/Z3nuue85d/OuvTzyyttsrP/gkJye0v4Evj6mL9+fu4arR1Wxqf4Dxg+r5De/fxeAmjNObVyn1m3/A48v2sBPrvksVz+8kNH9uvC1MX15+NfriAguGdKTZevrAZhx7Qiu/ekiJqT1+8bz+1PRsR0AKza+x/qde7jrS4P4x1kr6FHegd5pOwe45cIzeW75Zv71srMOaS/A498cyVOLs/3H5cMq+VXddvZ+dIBbLvwkR7dePIDHFq7nyoLt+IGvDmNpat/1Y/sxbX4dgyvL+cpne/Hdp1fwoytrGqe949Kz+Hj/gcZl79mpA1ve28tTizcyeUwfxvY/jbd27OHWiwdw+7OruHpUVeN7f3DFOUyZsSTbfqu7cXp5e+54bjVfOqfnHy3H2ZXlLN+wC8jW6U4ntmHk9+YD8MjXRjCsqjMXDjqdqeP68+q6HUx9Yjl3XT6IO59bzXnV3fjxgjd4/Z33+c5fVrOp/gMWrN3O5l3Zfv3OywaxdP1OZtZu4LRT2rH1/X387YjevLt7H+3blNHt5HZ8uP8AnU9sy73z1ja26T+/PJgpMxazcN1ORvQ5lS4nteW51zbzw0nDWLB2G+Ud2jCwR0cG9ujYuD8COLFtGfsPRGOue3TqwMpN7/Hymm0M6lnOm9v/wO592XGi8H8FcO/EIazfsYcvnFnBBfcuAGDWdaOZNr+O69P2C58cq++fNJRZSzfx3YvOpKJjO4adcSp///gy7p4wmH0fHWDt1t08+Ks3Gdq7E4vfrm98/5ndO9K320lcM6oKSTxeu/6QD+Tf+Fxf/vvlN+jT9eTG2J2XDWLKjCVUdGzHqD/r0hj/+pg+/HLNNtZs2c2Eml48Vruesf1Po02ZWPx2PVVdTmw8no7s24Xundrz5xWnsCUde/9j/GDu+cUazq4sb1w/f123nU279jKmuiu3zlrJpUN68MzSTQBMnzwcgJnfGMmTizeyctMudu75kKnj+jNlxhLm3PA57nx+NS+u2gLA+JpKINtfLX5rJ7f99UAgO5ZPfXI55/XryiVDsmPU6H5dueCs0xncqxN7PtzPxOG9uWvO61w0qDt7P9rPL1ZvbVzu+ycNZfayTX+0vTV3aqqvmiWNBP4pIsal8ZsBIuJ7BdO8kKb5raQTgHeAbvEnGlVTUxO1tbVN0mYzMzMzswaSFkVEzZGnbNo+1QuBakl9JLUFJgKzD5pmNnBVGh4PzP9TBbWZmZmZWXPUZN0/Uh/pbwMvAGXAQxGxUtLtQG1EzAYeBH4mqQ7YQVZ4m5mZmZm1KE3apzoingeePyh2a8HwXuDLTdkGMzMzM7Om1rwuvTczMzMza4FcVJuZmZmZ5eSi2szMzMwsJxfVZmZmZmY5uag2MzMzM8vJRbWZmZmZWU4uqs3MzMzMcnJRbWZmZmaWk4tqMzMzM7OcXFSbmZmZmeXkotrMzMzMLCcX1WZmZmZmObmoNjMzMzPLyUW1mZmZmVlOLqrNzMzMzHJSRBS7DUdF0jbgrSL9+a7A9iL9bSse5700Oe+lyXkvXc59aTpS3s+IiG6fZkYtrqguJkm1EVFT7HbY8eW8lybnvTQ576XLuS9NxzLv7v5hZmZmZpaTi2ozMzMzs5xcVB+dB4rdACsK5700Oe+lyXkvXc59aTpmeXefajMzMzOznHym2szMzMwsJxfVn4Kk8yX9TlKdpJuK3R7LR9JDkrZKWlEQO1XSXElr03PnFJekaSn3yyUNLXjPVWn6tZKuKsay2KcnqZeklyStkrRS0g0p7ty3cpLaS3pV0rKU+39O8T6SXkk5fkxS2xRvl8br0utVBfO6OcV/J2lccZbIjoakMklLJD2bxp33Vk7SOkmvSVoqqTbFmnxf76L6CCSVAfcBFwADgCskDShuqyynnwDnHxS7CZgXEdXAvDQOWd6r0+Na4H7INk7gNmAEMBy4rWEDtWbrY+DvImIAcC5wXdqWnfvWbx8wNiIGA0OA8yWdC/wbcHdE9AN2ApPT9JOBnSl+d5qOtL5MBAaS7UN+mI4R1rzdAKwuGHfeS8NfRMSQgtvlNfm+3kX1kQ0H6iLijYj4EHgUuKTIbbIcIuJlYMdB4UuA6Wl4OnBpQfynkflfoJOk7sA4YG5E7IiIncBcDi3UrRmJiM0RsTgNv092kO2Jc9/qpRzuTqNt0iOAscATKX5w7hvWiSeAL0hSij8aEfsi4k2gjuwYYc2UpErgIuDHaVw476Wqyff1LqqPrCewvmB8Q4pZ61IREZvT8DtARRo+XP69XrRg6Wvdc4BXcO5LQuoCsBTYSnZw/D1QHxEfp0kK89iY4/T6LqALzn1LdA8wFTiQxrvgvJeCAF6UtEjStSnW5Pv6E/K22qy1iYiQ5NvitFKSTgaeBL4TEe9lJ6Iyzn3rFRH7gSGSOgFPA/2L3CRrYpIuBrZGxCJJny92e+y4Oi8iNko6DZgr6fXCF5tqX+8z1Ue2EehVMF6ZYta6bElf95Cet6b44fLv9aIFktSGrKD+eUQ8lcLOfQmJiHrgJWAk2de8DSeXCvPYmOP0ejnwLs59SzMa+BtJ68i6bo4F7sV5b/UiYmN63kr2IXo4x2Ff76L6yBYC1elq4bZkFyvMLnKb7NibDTRc2XsVMKsgfmW6OvhcYFf6+ugF4IuSOqcLF76YYtZMpb6RDwKrI+L7BS85962cpG7pDDWSOgB/Rdan/iVgfJrs4Nw3rBPjgfmR/ajDbGBiuktEH7ILm149PkthRysibo6IyoioIjt2z4+ISTjvrZqkkySd0jBMto9ewXHY17v7xxFExMeSvk32jywDHoqIlUVuluUgaQbweaCrpA1kV/feBcyUNBl4C/hKmvx54EKyC1P2ANcARMQOSf9C9qEL4PaIOPjiR2teRgNfBV5LfWsBbsG5LwXdgenpjg2fAWZGxLOSVgGPSroDWEL2oYv0/DNJdWQXNU8EiIiVkmYCq8juJnNd6lZiLcuNOO+tWQXwdOradwLwSETMkbSQJt7X+xcVzczMzMxycvcPMzMzM7OcXFSbmZmZmeXkotrMzMzMLCcX1WZmZmZmObmoNjMzMzPLyUW1mVkzJ2m/pKUFj5uO4byrJK04VvMzMytVvk+1mVnz90FEDCl2I8zM7PB8ptrMrIWStE7Sv0t6TdKrkvqleJWk+ZKWS5onqXeKV0h6WtKy9BiVZlUm6UeSVkp6Mf3qIJKul7QqzefRIi2mmVmL4KLazKz563BQ948JBa/tiohBwH8B96TYD4DpEXE28HNgWopPA34ZEYOBoUDDr8NWA/dFxECgHrg8xW8Czknz+WZTLZyZWWvgX1Q0M2vmJO2OiJP/n/g6YGxEvCGpDfBORHSRtB3oHhEfpfjmiOgqaRtQGRH7CuZRBcyNiOo0fiPQJiLukDQH2A08AzwTEbubeFHNzFosn6k2M2vZ4jDDR2NfwfB+Prne5iLgPrKz2gsl+TocM7PDcFFtZtayTSh4/m0a/g0wMQ1PAhak4XnAtwAklUkqP9xMJX0G6BURLwE3AuXAIWfLzcws47MOZmbNXwdJSwvG50REw231OktaTna2+YoUmwI8LOkfgG3ANSl+A/CApMlkZ6S/BWw+zN8sA/4nFd4CpkVE/TFbIjOzVsZ9qs3MWqjUp7omIrYXuy1mZqXO3T/MzMzMzHLymWozMzMzs5x8ptrMzMzMLCcX1WZmZmZmObmoNjMzMzPLyUW1mZmZmVlOLqrNzMzMzHJyUW1mZmZmltP/AVV3x9AWQ003AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize = (12,8))\n",
    "_ = plt.plot(score_list)\n",
    "_ = plt.xlabel(\"Epochs\")\n",
    "_ = plt.ylabel(\"Score\")\n",
    "_ = plt.title(\"Score Plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'epoch': 4820,\n",
       " 'score_list': [0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.10000000149011612,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.09000000171363354,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.09000000171363354,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.09000000171363354,\n",
       "  0.09000000171363354,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.10000000149011612,\n",
       "  0.09000000171363354,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.09000000171363354,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.10000000149011612,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.10000000149011612,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.09000000171363354,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.10000000149011612,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.10000000149011612,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.10000000149011612,\n",
       "  0.09000000171363354,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.09000000171363354,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.09000000357627869,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.10000000149011612,\n",
       "  0.0,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.10000000149011612,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.10000000149011612,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.10000000149011612,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.10000000149011612,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.10000000149011612,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.09000000171363354,\n",
       "  0.0,\n",
       "  0.10000000149011612,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.10000000149011612,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.09000000171363354,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.10000000149011612,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.09000000171363354,\n",
       "  0.0,\n",
       "  0.10000000149011612,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.09000000171363354,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.20000000298023224,\n",
       "  0.10000000149011612,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.10000000149011612,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.10000000149011612,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.10000000149011612,\n",
       "  0.0,\n",
       "  0.09000000171363354,\n",
       "  0.20000000298023224,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.10000000149011612,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.09000000171363354,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.09000000171363354,\n",
       "  0.10000000149011612,\n",
       "  0.09000000171363354,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.09000000171363354,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.09000000171363354,\n",
       "  0.09000000171363354,\n",
       "  0.0,\n",
       "  0.10000000149011612,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.09000000171363354,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.10000000149011612,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.09000000171363354,\n",
       "  0.10000000149011612,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.10000000149011612,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.09000000171363354,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.09000000171363354,\n",
       "  0.0,\n",
       "  0.09000000171363354,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.09000000171363354,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.09000000171363354,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.09000000171363354,\n",
       "  0.09000000171363354,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.09000000171363354,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.09000000171363354,\n",
       "  0.0,\n",
       "  0.09000000171363354,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.09000000171363354,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.09000000171363354,\n",
       "  0.10000000149011612,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.09000000171363354,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.10000000149011612,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.09000000171363354,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.10000000149011612,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.20000000298023224,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.09000000171363354,\n",
       "  0.09000000171363354,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.09000000171363354,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.09000000171363354,\n",
       "  0.09000000171363354,\n",
       "  0.0,\n",
       "  0.09000000171363354,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.10000000149011612,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.10000000149011612,\n",
       "  0.0,\n",
       "  0.09000000171363354,\n",
       "  0.0,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.20000000298023224,\n",
       "  0.09000000171363354,\n",
       "  0.10000000149011612,\n",
       "  0.09000000171363354,\n",
       "  0.09000000171363354,\n",
       "  0.10000000149011612,\n",
       "  0.09000000171363354,\n",
       "  0.0,\n",
       "  0.10000000149011612,\n",
       "  0.09000000171363354,\n",
       "  0.10000000149011612,\n",
       "  0.09000000171363354,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.09000000171363354,\n",
       "  0.09000000171363354,\n",
       "  0.09000000171363354,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.09000000171363354,\n",
       "  0.09000000171363354,\n",
       "  0.0,\n",
       "  0.10000000149011612,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.10000000149011612,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.10000000149011612,\n",
       "  0.09000000171363354,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.10000000149011612,\n",
       "  0.09000000171363354,\n",
       "  0.09000000171363354,\n",
       "  0.09000000171363354,\n",
       "  0.09000000171363354,\n",
       "  0.0,\n",
       "  0.09000000171363354,\n",
       "  0.10000000149011612,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.09000000171363354,\n",
       "  0.09000000171363354,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.09000000171363354,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.09000000171363354,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.09000000171363354,\n",
       "  0.09000000171363354,\n",
       "  0.09000000171363354,\n",
       "  0.0,\n",
       "  0.09000000171363354,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.0,\n",
       "  0.10000000149011612,\n",
       "  0.09000000171363354,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.09000000171363354,\n",
       "  0.09000000171363354,\n",
       "  0.09000000171363354,\n",
       "  0.10000000149011612,\n",
       "  0.0,\n",
       "  0.10000000149011612,\n",
       "  0.0,\n",
       "  0.09000000171363354,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.10000000149011612,\n",
       "  0.09000000171363354,\n",
       "  0.09000000171363354,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.09000000171363354,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.09000000171363354,\n",
       "  0.09000000171363354,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.09000000171363354,\n",
       "  0.10000000149011612,\n",
       "  0.0,\n",
       "  0.10000000149011612,\n",
       "  0.09000000171363354,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.09000000171363354,\n",
       "  0.09000000171363354,\n",
       "  0.10000000149011612,\n",
       "  0.09000000171363354,\n",
       "  0.09000000171363354,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.09000000171363354,\n",
       "  0.10000000149011612,\n",
       "  0.09000000171363354,\n",
       "  0.0,\n",
       "  0.10000000149011612,\n",
       "  0.09000000171363354,\n",
       "  0.0,\n",
       "  0.19000000320374966,\n",
       "  0.09000000171363354,\n",
       "  0.10000000149011612,\n",
       "  0.09000000171363354,\n",
       "  0.0,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.20000000298023224,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.0,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.20000000298023224,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.0,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.0,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.30000000447034836,\n",
       "  0.10000000149011612,\n",
       "  0.20000000298023224,\n",
       "  0.20000000298023224,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.0,\n",
       "  0.10000000149011612,\n",
       "  0.09000000171363354,\n",
       "  0.10000000149011612,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.09000000171363354,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.10000000149011612,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.09000000171363354,\n",
       "  0.10000000149011612,\n",
       "  0.0,\n",
       "  0.20000000298023224,\n",
       "  0.10000000149011612,\n",
       "  0.0,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.0,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.0,\n",
       "  0.10000000149011612,\n",
       "  0.20000000298023224,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.0,\n",
       "  0.10000000149011612,\n",
       "  0.20000000298023224,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.10000000149011612,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.10000000149011612,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.10000000149011612,\n",
       "  0.20000000298023224,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.10000000149011612,\n",
       "  0.0,\n",
       "  0.10000000149011612,\n",
       "  0.0,\n",
       "  0.20000000298023224,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.20000000298023224,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.0,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.0,\n",
       "  0.19000000320374966,\n",
       "  0.10000000149011612,\n",
       "  0.0,\n",
       "  0.10000000149011612,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.10000000149011612,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.2900000046938658,\n",
       "  0.0,\n",
       "  0.10000000149011612,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.0,\n",
       "  0.10000000149011612,\n",
       "  0.0,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.0,\n",
       "  0.10000000149011612,\n",
       "  0.0,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.20000000298023224,\n",
       "  0.20000000298023224,\n",
       "  0.0,\n",
       "  0.10000000149011612,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.20000000298023224,\n",
       "  0.20000000298023224,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.09000000171363354,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.09000000171363354,\n",
       "  0.0,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.20000000298023224,\n",
       "  0.09000000171363354,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.19000000320374966,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.10000000149011612,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.09000000171363354,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.4000000059604645,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.10000000149011612,\n",
       "  0.0,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.10000000149011612,\n",
       "  0.0,\n",
       "  0.10000000149011612,\n",
       "  0.20000000298023224,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.0,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.0,\n",
       "  0.10000000149011612,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.09000000171363354,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.30000000447034836,\n",
       "  0.10000000149011612,\n",
       "  0.20000000298023224,\n",
       "  0.20000000298023224,\n",
       "  0.09000000357627869,\n",
       "  0.10000000149011612,\n",
       "  0.20000000298023224,\n",
       "  0.30000000447034836,\n",
       "  0.20000000298023224,\n",
       "  0.0,\n",
       "  0.09000000171363354,\n",
       "  0.10000000149011612,\n",
       "  0.0,\n",
       "  0.09000000171363354,\n",
       "  0.10000000149011612,\n",
       "  0.09000000171363354,\n",
       "  0.30000000447034836,\n",
       "  0.30000000447034836,\n",
       "  0.09000000171363354,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.0,\n",
       "  0.20000000298023224,\n",
       "  0.0,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.09000000171363354,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.20000000298023224,\n",
       "  0.09000000357627869,\n",
       "  0.20000000298023224,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.20000000298023224,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.20000000298023224,\n",
       "  0.10000000149011612,\n",
       "  0.4000000059604645,\n",
       "  0.20000000298023224,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.09000000171363354,\n",
       "  0.30000000447034836,\n",
       "  0.20000000298023224,\n",
       "  0.10000000149011612,\n",
       "  0.0,\n",
       "  0.10000000149011612,\n",
       "  0.20000000298023224,\n",
       "  0.10000000149011612,\n",
       "  0.20000000298023224,\n",
       "  0.10000000149011612,\n",
       "  0.09000000171363354,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.20000000298023224,\n",
       "  0.10000000149011612,\n",
       "  0.09000000171363354,\n",
       "  0.10000000149011612,\n",
       "  0.10000000149011612,\n",
       "  0.0,\n",
       "  ...],\n",
       " 'actor_0': OrderedDict([('fc1.weight',\n",
       "               tensor([[-0.1778, -0.0308,  0.0524,  ..., -0.8894, -0.0450,  0.2117],\n",
       "                       [ 0.0318, -0.3526, -0.0209,  ...,  0.4465, -0.0457,  0.1583],\n",
       "                       [-0.1471,  0.6039,  0.0250,  ..., -1.2676, -0.0817, -0.0693],\n",
       "                       ...,\n",
       "                       [ 0.2088,  0.3138,  0.0217,  ..., -0.6853, -0.0122, -0.3210],\n",
       "                       [ 0.0586, -0.1044, -0.0092,  ..., -0.5985, -0.0140, -0.1683],\n",
       "                       [ 0.1317,  0.4086, -0.0158,  ..., -0.1492, -0.0342, -0.7783]])),\n",
       "              ('fc1.bias',\n",
       "               tensor([ 0.4117, -0.2173,  0.3813, -0.1913,  0.0660,  0.1041,  0.3194,  0.0580,\n",
       "                       -0.5779,  0.1830,  0.1093, -0.4232, -0.0834, -0.0060,  0.0801,  0.4300,\n",
       "                        0.2929,  0.1520,  0.0093, -0.0745,  0.3685,  0.2698,  0.0353,  0.2462,\n",
       "                       -0.3293,  0.2901,  0.2061,  0.2539, -0.1644,  0.0382, -0.3359, -0.1385,\n",
       "                       -0.0221, -0.4057,  0.4529, -0.3609,  0.1502, -0.0424, -0.0453, -0.1581,\n",
       "                       -0.4883, -0.1847, -0.3324, -0.1873,  0.1242, -0.2872,  0.0367,  0.0051,\n",
       "                       -0.2760, -0.0330, -0.2817,  0.2125, -0.5171,  0.0603,  0.0993,  0.2326,\n",
       "                       -0.1293, -0.3202,  0.1212, -0.1240, -0.2113, -0.0439, -0.0422,  0.0449,\n",
       "                       -0.4515, -0.1245,  0.1526, -0.7304, -0.2749, -0.2672, -0.1238, -0.3840,\n",
       "                        0.4480, -0.4022, -0.4943,  0.0111, -0.0530, -0.0359,  0.4554, -0.0558,\n",
       "                       -0.2086, -0.0024, -0.2099,  0.3516,  0.0432, -0.1258, -0.4415, -0.0357,\n",
       "                       -0.2081, -0.4158, -0.2961, -0.1211, -0.3191,  0.3534, -0.4457, -0.0718,\n",
       "                        0.5969,  0.1416, -0.8033, -0.3555, -0.0060, -0.1185, -0.0589,  0.0749,\n",
       "                       -0.1730,  0.0448,  0.0676,  0.2578, -0.4678, -0.2960,  0.0967,  0.2874,\n",
       "                       -0.0663, -0.1714, -0.3234, -0.5314,  0.3826,  0.0546, -0.2429, -0.6536,\n",
       "                       -0.4630, -0.1914, -0.3750,  0.1052,  0.0062, -0.3277, -0.3609, -0.4941,\n",
       "                       -0.1393, -0.0284, -0.1120, -0.0221,  0.0193, -0.0392, -0.1003, -0.0122,\n",
       "                        0.1546, -0.1350,  0.1298, -0.4521,  0.0113,  0.4384,  0.2314, -0.2212,\n",
       "                       -0.1399,  0.1732,  0.3018, -0.4248,  0.0810,  0.1929,  0.0287,  0.2856,\n",
       "                        0.1302, -0.2711, -0.2985,  0.1650,  0.1712, -0.0751,  0.3964, -0.3838,\n",
       "                       -0.0932,  0.2961,  0.2544, -0.4626, -0.3840, -0.4510, -0.0992, -0.2460,\n",
       "                        0.0654, -0.0552,  0.2685, -0.2271, -0.1701,  0.3958,  0.3232, -0.4470,\n",
       "                        0.3345, -0.6485, -0.0952,  0.0634,  0.0226, -0.2646, -0.1234,  0.0821,\n",
       "                        0.4452, -0.3624, -0.2335, -0.6720,  0.1215, -0.2596, -0.5212,  0.3278,\n",
       "                       -0.7474, -0.6218, -0.4099, -0.3703,  0.0791,  0.3983,  0.3009,  0.1660,\n",
       "                       -0.3797,  0.0222,  0.1748, -0.2489,  0.2016,  0.0751,  0.0844, -0.0804,\n",
       "                        0.4440,  0.2494, -0.3851,  0.1310, -0.3172, -0.2943,  0.0769, -0.2558,\n",
       "                        0.0221, -0.7974,  0.3849, -0.4284, -0.4047,  0.7915, -0.3451,  0.1056,\n",
       "                       -0.3641,  0.1564, -0.1179, -0.1381,  0.2365, -0.0367,  0.0170, -0.0795,\n",
       "                        0.2299,  0.2540,  0.5300, -0.2995, -0.3613,  0.3283, -0.0847, -0.0380,\n",
       "                       -0.4824,  0.0959, -0.2159, -0.0292,  0.5498, -0.1010,  0.2463, -0.4242,\n",
       "                       -0.0933, -0.0708, -0.0968,  0.1568, -0.5455,  0.2310,  0.3382,  0.0837,\n",
       "                       -0.7368, -0.1164, -0.2604, -0.1941,  0.0919, -0.1531, -0.2037,  0.4775,\n",
       "                       -0.4237])),\n",
       "              ('fc2.weight',\n",
       "               tensor([[-0.0900, -0.0018, -0.3955,  ...,  0.2107, -0.1015,  0.1113],\n",
       "                       [-0.0210,  0.0164, -0.0985,  ...,  0.1499, -0.2738, -0.1406],\n",
       "                       [ 0.1556, -0.1123,  0.0425,  ..., -0.2485,  0.1017,  0.0603],\n",
       "                       ...,\n",
       "                       [ 0.0680, -0.0218,  0.3346,  ..., -0.1545, -0.1256, -0.2493],\n",
       "                       [ 0.1377, -0.2303,  0.3776,  ..., -0.2030, -0.1247, -0.2417],\n",
       "                       [-0.1520,  0.0476, -0.3423,  ...,  0.2741, -0.0375,  0.1098]])),\n",
       "              ('fc2.bias',\n",
       "               tensor([-8.4137e-02,  5.6495e-02, -1.4708e-01, -8.9343e-03,  3.8280e-02,\n",
       "                       -4.5515e-01,  1.6230e-01, -1.3020e-01,  1.4284e-02, -4.0344e-02,\n",
       "                       -6.9483e-02,  1.9883e-02, -5.2902e-02, -3.1101e-01, -1.0692e-02,\n",
       "                        5.6259e-02, -3.0390e-01, -3.1431e-02, -1.3882e-01, -8.0746e-02,\n",
       "                       -5.5967e-02, -9.2034e-02, -2.8020e-02,  3.4990e-02, -2.5220e-01,\n",
       "                       -8.4830e-02, -1.9833e-01,  9.4030e-02, -8.7598e-02, -1.7426e-01,\n",
       "                       -1.7378e-01, -2.0273e-01, -2.2356e-01,  7.7947e-02, -3.6121e-02,\n",
       "                        1.5889e-01, -1.1482e-02, -1.6726e-01, -1.5431e-01,  2.7186e-02,\n",
       "                       -1.2082e-01,  7.5687e-03, -3.1793e-01, -8.4085e-02, -3.0322e-05,\n",
       "                        7.0390e-02, -1.4069e-01, -1.1440e-01, -1.5733e-01, -2.3536e-01,\n",
       "                       -2.2606e-03, -3.4633e-02, -1.8723e-01, -1.0247e-02,  3.4099e-02,\n",
       "                       -1.9185e-01,  5.8817e-02,  9.7726e-02, -1.6393e-01,  9.8620e-02,\n",
       "                       -1.7612e-01,  2.1526e-01,  1.7756e-02,  3.3408e-02, -1.1474e-01,\n",
       "                       -2.1820e-01,  1.9902e-01,  8.8209e-02,  2.0369e-02, -1.9574e-02,\n",
       "                       -1.8237e-01, -2.5294e-03, -7.0230e-02, -2.1166e-01, -4.4201e-01,\n",
       "                       -1.8226e-02,  1.4134e-02,  1.5330e-01, -6.7717e-03,  2.2756e-01,\n",
       "                       -8.7509e-02, -2.7084e-02, -5.5933e-01, -5.9374e-02,  1.5270e-01,\n",
       "                       -5.1768e-02, -1.5147e-01, -2.3323e-02, -2.8554e-01, -2.9645e-02,\n",
       "                       -1.0388e-01, -1.5564e-02, -1.1543e-01, -1.2580e-01,  2.4192e-03,\n",
       "                       -1.8552e-01, -6.3419e-02, -2.4323e-02, -7.7182e-02, -2.0706e-01,\n",
       "                        5.3128e-02,  1.2012e-01,  1.8511e-01,  1.5558e-01, -2.6448e-01,\n",
       "                       -4.2591e-02,  7.6252e-03,  4.8171e-02, -1.2574e-01, -9.0912e-02,\n",
       "                       -2.7554e-01,  4.6446e-02, -3.2536e-02,  6.8953e-02,  3.3805e-03,\n",
       "                        2.0859e-02, -7.1180e-02,  7.2146e-02, -1.1231e-01, -2.1757e-01,\n",
       "                       -1.2446e-01, -3.9411e-01,  1.1901e-01,  4.8892e-02,  1.4267e-01,\n",
       "                        7.9877e-03,  1.3831e-01, -1.8843e-02])),\n",
       "              ('fc3.weight',\n",
       "               tensor([[ 0.3178,  0.0595, -0.0237,  0.2844,  0.0696, -0.5583,  0.2262,  0.5989,\n",
       "                        -0.1355, -0.2389, -0.1706, -0.0923, -0.0383, -0.1957,  0.0695,  0.0453,\n",
       "                        -0.5309,  0.3903,  0.0336, -0.2392,  0.2536, -0.0468,  0.0015, -0.0213,\n",
       "                         0.7278, -0.4514, -0.2644,  0.1131, -0.4685,  0.6567, -0.1160, -0.2168,\n",
       "                         0.0502,  0.2493,  0.0783,  0.7476,  0.0969, -0.2563, -0.3447,  0.2868,\n",
       "                        -0.0473, -0.7396, -0.5899, -1.1061,  0.1440, -0.0031, -0.2289, -0.5948,\n",
       "                        -0.2991, -0.3428, -0.0632, -0.1106, -0.3855,  0.0301,  0.3239, -0.2134,\n",
       "                         0.3896,  0.1185,  0.0466,  0.3837,  0.0051,  0.1278, -0.0546,  0.3658,\n",
       "                         0.3908,  0.3629,  0.2965,  0.3089,  0.2453, -0.0887, -0.4345,  0.2125,\n",
       "                        -0.1279, -0.2186, -0.3460,  0.1435,  0.3621,  0.1164,  0.4309, -0.0509,\n",
       "                        -0.6613, -0.0675, -0.3400,  0.2873,  0.0675,  0.3558, -0.1864, -0.0770,\n",
       "                        -0.1005,  0.2090, -0.1564, -0.0913, -0.3299, -0.2067,  0.4196, -0.2654,\n",
       "                        -0.0956,  0.3017, -0.0870, -0.2973,  0.2481,  0.1697, -0.0252,  0.1290,\n",
       "                        -0.5116, -0.1785, -0.0984,  0.2328,  0.9163, -0.4127, -0.5482, -0.2145,\n",
       "                        -0.0333,  0.0920,  0.0103,  0.3172, -0.1268,  0.0474, -0.3379, -0.5863,\n",
       "                         0.2597, -0.1284,  0.3688,  0.0891, -0.0795,  0.3619, -0.0605, -0.0769],\n",
       "                       [-0.5792,  0.2799,  0.1765, -0.3009,  0.1013,  0.0657,  0.1185, -0.0204,\n",
       "                         0.1460,  0.0044,  0.3816, -0.5649, -0.1449, -0.3391,  0.2100,  0.5735,\n",
       "                        -0.0754,  0.2612, -0.8986, -0.0690,  0.3859, -0.8009, -0.4457, -0.3713,\n",
       "                        -0.5745,  0.4745, -1.0180, -0.0559,  0.3296, -0.0494,  0.3090,  0.1764,\n",
       "                         0.3858, -0.2905,  0.1427, -0.8575, -0.4589, -0.7629,  0.7093, -0.1809,\n",
       "                         0.3067,  0.8304,  0.2872, -0.2107, -0.6871,  0.7916, -0.0182,  0.2059,\n",
       "                         0.3236,  0.1571,  0.3356, -0.2033,  0.2544, -1.1063,  0.2856, -0.1859,\n",
       "                        -0.1445,  0.0103,  0.0937, -0.0328, -0.5788,  0.0688, -0.6532,  0.6055,\n",
       "                        -0.5000, -0.1083,  0.2886,  0.2546,  0.1829,  0.5287,  0.1654,  0.1674,\n",
       "                         0.3899, -0.0447,  0.5344,  0.3748,  1.3468, -0.0883,  0.1103, -0.9476,\n",
       "                        -0.1965,  0.2234,  0.0524,  0.2541,  0.1528, -0.5518, -0.6243, -0.2020,\n",
       "                         0.5585,  0.5819, -0.2379, -0.1250, -0.0844,  0.1567,  0.1521,  0.0536,\n",
       "                         0.1824,  0.8829,  0.1749,  0.2776, -0.0080, -1.5289,  0.6283,  0.4913,\n",
       "                        -0.6121,  0.6703, -0.5828,  0.5287,  0.2708,  0.0730,  0.6779, -0.6122,\n",
       "                        -0.8397, -0.2236, -0.3255,  0.0082,  0.3564,  0.6102, -0.0896,  0.3931,\n",
       "                        -0.5742, -0.4400,  0.2425,  0.4597, -0.5491, -0.1029, -0.7083,  0.3800]])),\n",
       "              ('fc3.bias', tensor([ 0.0485, -0.0146]))]),\n",
       " 'critic_0': OrderedDict([('fcs1.weight',\n",
       "               tensor([[ 0.0544, -0.6635,  0.2576,  ..., -2.0473, -0.2280,  1.3463],\n",
       "                       [-0.0383, -0.2606,  0.1098,  ..., -1.5590, -0.1994, -0.0354],\n",
       "                       [ 0.0423, -0.2300, -0.0305,  ..., -4.1454,  0.2438,  0.3320],\n",
       "                       ...,\n",
       "                       [ 0.2424, -0.0335, -0.0681,  ..., -1.2340, -0.2011,  0.2847],\n",
       "                       [ 0.0727, -0.3927, -0.0331,  ..., -3.5586,  0.0133,  0.3538],\n",
       "                       [-0.0494, -0.4705, -0.0434,  ...,  0.2839, -0.0247,  0.0234]])),\n",
       "              ('fcs1.bias',\n",
       "               tensor([ 0.3422, -0.0867,  0.2814, -2.5719, -0.2815, -0.3917, -0.2685,  0.7194,\n",
       "                        0.5226, -0.1733,  0.7896, -1.6524, -1.3297, -0.5528,  0.7585, -4.6685,\n",
       "                       -0.6265,  0.8050, -0.4980, -0.9817, -0.6505,  0.8268,  0.4077,  0.0094,\n",
       "                       -0.0633, -1.0154, -0.1807, -0.9939,  0.6509,  0.1994, -0.3773, -0.2079,\n",
       "                        0.6172, -0.0396, -0.0120, -1.1796, -1.2007, -1.5773, -0.5553, -0.3153,\n",
       "                       -0.4875,  0.7055, -1.3073,  0.4032, -0.1968,  1.2800, -0.5996, -0.9471,\n",
       "                        0.4882, -0.1877,  0.5144,  0.1352, -0.0993, -1.0498,  0.0808, -0.7357,\n",
       "                        0.3850, -0.0953, -0.1100, -1.4657, -0.4402, -0.1422, -0.4949,  0.8557,\n",
       "                        0.0195, -1.4496, -0.6433, -0.6199, -1.1716, -0.2266, -1.0055, -0.2985,\n",
       "                        0.1876,  0.2791, -0.3788, -1.3237,  0.0092, -0.2018, -0.6033,  1.1432,\n",
       "                        1.2580,  0.0146, -0.2990, -0.9979, -0.2192,  0.0927, -0.6896, -2.9025,\n",
       "                       -0.5416,  0.2263, -0.1152, -2.3794, -3.6554, -0.9989,  0.2403, -0.1448,\n",
       "                       -0.5519, -0.5990, -0.1911, -2.8849, -0.4490,  0.6665, -0.6664,  0.5615,\n",
       "                       -2.0944,  0.1901, -0.2610, -0.3491, -0.8543, -0.2127, -1.4100, -0.8880,\n",
       "                        0.7177,  0.8822, -0.8764, -1.0408,  0.8454,  0.3301,  0.6914, -1.4341,\n",
       "                       -0.2533, -1.5673, -0.3167, -0.2620,  0.2446, -0.9297, -0.9445,  0.0401,\n",
       "                        1.6710, -0.9204, -1.3959,  0.1057, -0.2580,  1.9114, -0.8454,  0.2277,\n",
       "                       -0.1582,  0.7554, -0.4036,  0.3099,  1.2856, -0.3282, -0.1557, -0.4595,\n",
       "                        0.1304,  0.1040, -0.3344, -0.2219, -0.8510, -0.5934, -0.1101,  0.2452,\n",
       "                       -0.0861, -0.2076,  1.4689,  0.1914, -0.3842, -0.1199, -0.0957,  1.4153,\n",
       "                        2.0092, -0.6007,  1.8463, -0.3261, -0.4042,  0.3611, -0.1912,  0.7761,\n",
       "                        0.3652,  0.4612,  1.4710, -0.4839, -0.8124,  0.7316, -0.8922, -1.5559,\n",
       "                       -0.3816,  0.1738,  0.0303, -3.5232, -0.3582, -0.6502, -0.2292, -0.5688,\n",
       "                       -1.8166, -0.2254, -0.1586, -0.7467,  0.9883, -0.2620, -0.1486, -0.9531,\n",
       "                       -0.4593, -0.3275,  1.6725,  0.5382, -0.4697,  0.0852,  0.2282,  0.0338,\n",
       "                       -0.4100,  0.4655,  0.2798, -0.1876, -0.1509, -1.3099, -0.4639, -0.4115,\n",
       "                       -0.3514,  0.5659, -1.2720, -0.7680,  0.6575, -0.8321, -0.0622,  0.9106,\n",
       "                       -1.0596, -0.2752,  0.4053, -0.5453, -0.5473,  0.3785, -0.3986, -0.4101,\n",
       "                       -0.1424, -0.4841,  0.1735,  0.0760, -2.1520,  1.6227,  0.2832,  0.7651,\n",
       "                       -0.7015, -2.7127, -0.8375, -0.7189,  2.0546, -1.2384, -0.7003,  0.1219,\n",
       "                       -0.2501, -0.7218, -0.8305, -0.1747, -0.5146,  0.7212, -0.5509, -0.7117,\n",
       "                       -0.4103, -0.3293,  0.1077,  1.2905, -0.3416, -0.5695,  0.0964, -1.7064])),\n",
       "              ('fc2.weight',\n",
       "               tensor([[ 0.2460,  0.1698,  0.3391,  ...,  0.9807, -0.4143, -0.1698],\n",
       "                       [-0.5074,  0.0681, -0.0998,  ...,  0.0122, -4.4327,  0.1046],\n",
       "                       [-0.1125, -0.0121, -0.1246,  ..., -0.6473, -0.8915, -1.2889],\n",
       "                       ...,\n",
       "                       [-0.2159, -0.6142, -0.3799,  ..., -0.2831,  0.1975, -0.1846],\n",
       "                       [-0.4333,  0.2048, -0.2925,  ...,  1.9958,  1.3160,  0.8624],\n",
       "                       [-0.0048, -0.6844, -0.2930,  ..., -1.4416, -0.2203,  0.2546]])),\n",
       "              ('fc2.bias',\n",
       "               tensor([-0.5499, -0.1824, -0.2874, -0.6356,  0.2872, -0.7623, -0.9606, -0.2543,\n",
       "                       -0.5710, -0.2540, -0.3837, -0.2807, -0.5210, -0.5147, -1.0149, -0.3059,\n",
       "                       -0.3978, -1.2130, -0.4384, -1.2663, -0.6862, -0.3627, -0.4319,  0.0548,\n",
       "                       -0.2346, -0.4498, -1.0792, -0.2802, -0.4747, -1.9594, -0.5761, -0.9440,\n",
       "                       -0.2818, -0.8184, -1.2880, -0.5399, -0.0196, -0.5006, -0.5378, -0.4099,\n",
       "                       -0.2855,  0.4166, -0.1422, -0.2345, -0.1647, -0.9147, -0.4557, -0.4347,\n",
       "                       -0.5095, -0.2461, -0.4013, -0.9078, -0.3399, -0.0550, -1.6352, -0.4548,\n",
       "                       -0.2715, -0.3631, -0.5758, -0.3175, -0.6406,  0.1992, -1.7084, -0.6118,\n",
       "                       -0.3807, -0.4077, -0.3847, -0.7262, -0.5274, -0.7524, -0.2729, -0.2567,\n",
       "                       -0.5118, -0.2552, -0.4288, -0.6085, -0.6891, -0.5434, -0.9563,  0.0214,\n",
       "                       -0.0621, -0.3782, -0.0745, -1.3166, -0.6001,  0.0634, -1.9732, -0.2355,\n",
       "                        0.0044, -0.5451, -1.6888, -1.3310, -0.6043,  1.0022, -0.3782, -0.8078,\n",
       "                       -0.5464,  0.4310, -0.7824, -0.1084, -0.4120, -0.4345, -0.3553,  0.9943,\n",
       "                       -1.7341, -0.2691, -0.5343, -0.3772, -0.6032, -0.0850, -0.5258, -0.5383,\n",
       "                       -0.4923, -0.2524, -0.0600, -0.2544, -1.0461, -0.4472, -0.4985, -0.3362,\n",
       "                       -0.3393, -0.4990, -0.5661, -0.3549, -0.5415, -0.1468, -0.6944, -0.0608])),\n",
       "              ('fc3.weight',\n",
       "               tensor([[-0.0076, -0.0177,  0.0105, -0.0113, -0.0190, -0.0124, -0.0269,  0.0074,\n",
       "                         0.0077, -0.0138,  0.0095,  0.0099, -0.0177,  0.0054, -0.0076,  0.0083,\n",
       "                        -0.0087,  0.0073, -0.0175, -0.0091, -0.0114,  0.0171, -0.0267,  0.0136,\n",
       "                        -0.0172,  0.0105, -0.0104,  0.0096, -0.0124, -0.0175,  0.0095,  0.0177,\n",
       "                         0.0050, -0.0065, -0.0092, -0.0142,  0.0081, -0.0219, -0.0161,  0.0086,\n",
       "                         0.0095, -0.0112,  0.0082,  0.0082,  0.0147, -0.0194, -0.0156, -0.0146,\n",
       "                         0.0123,  0.0164,  0.0071, -0.0137, -0.0264,  0.0206, -0.0095, -0.0172,\n",
       "                         0.0118, -0.0225, -0.0255, -0.0184,  0.0179,  0.0039, -0.0133, -0.0375,\n",
       "                        -0.0217,  0.0187,  0.0068, -0.0228, -0.0154, -0.0074,  0.0077,  0.0050,\n",
       "                         0.0071, -0.0106, -0.0274,  0.0089, -0.0144,  0.0089,  0.0036,  0.0128,\n",
       "                        -0.0186,  0.0034,  0.0070,  0.1381, -0.0218, -0.0205,  0.0076, -0.0322,\n",
       "                        -0.0173,  0.0119, -0.0146,  0.0144, -0.0283, -0.0102, -0.0271, -0.0086,\n",
       "                        -0.0094, -0.0163, -0.0096,  0.0050,  0.0107,  0.0157,  0.0069, -0.0088,\n",
       "                        -0.0124,  0.0096,  0.0076, -0.0165,  0.0052,  0.0078, -0.0340,  0.0056,\n",
       "                        -0.0167,  0.0038, -0.0139, -0.0209, -0.0093, -0.0173, -0.0165, -0.0241,\n",
       "                        -0.0098, -0.0315,  0.0101,  0.0050, -0.0117,  0.0132, -0.0139,  0.0069]])),\n",
       "              ('fc3.bias', tensor([-0.2913]))]),\n",
       " 'actor_opt_0': {'state': {140493485120880: {'step': 1528596,\n",
       "    'exp_avg': tensor([[ 1.7063e-05, -7.2197e-07,  1.2843e-05,  ..., -1.6502e-06,\n",
       "             -2.8067e-05,  2.2941e-08],\n",
       "            [-3.6607e-05, -6.4025e-06,  9.1088e-06,  ...,  5.6422e-06,\n",
       "             -8.7257e-06,  1.7763e-05],\n",
       "            [-3.3430e-05,  1.5032e-06, -7.7384e-05,  ...,  8.0049e-06,\n",
       "              4.8667e-05,  1.5904e-05],\n",
       "            ...,\n",
       "            [-4.5067e-06,  6.9398e-08,  1.3886e-05,  ...,  2.5442e-06,\n",
       "              1.7335e-05, -2.3693e-07],\n",
       "            [-2.4214e-06,  2.3986e-06, -3.4519e-05,  ..., -1.1919e-06,\n",
       "              1.5631e-05, -5.8980e-06],\n",
       "            [ 1.9239e-05, -1.2744e-06, -1.6695e-05,  ..., -3.4131e-06,\n",
       "             -4.5588e-05,  1.2868e-05]]),\n",
       "    'exp_avg_sq': tensor([[5.1930e-08, 5.9278e-10, 1.3697e-08,  ..., 1.7542e-09, 1.1458e-07,\n",
       "             5.3098e-09],\n",
       "            [2.1592e-08, 2.8628e-10, 1.9638e-08,  ..., 1.3551e-09, 6.3835e-08,\n",
       "             1.7822e-09],\n",
       "            [1.2443e-07, 7.1449e-10, 5.5189e-08,  ..., 4.0467e-09, 5.3219e-08,\n",
       "             1.0336e-08],\n",
       "            ...,\n",
       "            [3.4492e-09, 3.6267e-11, 1.2810e-08,  ..., 2.4401e-10, 3.0617e-08,\n",
       "             3.5110e-10],\n",
       "            [1.2302e-08, 1.7393e-10, 2.6414e-08,  ..., 1.0037e-09, 4.3503e-08,\n",
       "             1.0049e-09],\n",
       "            [1.2888e-08, 7.4360e-11, 1.0364e-07,  ..., 6.6557e-10, 1.2487e-07,\n",
       "             3.1742e-09]])},\n",
       "   140493485120000: {'step': 1528596,\n",
       "    'exp_avg': tensor([-1.2329e-06,  3.5752e-06,  3.0236e-06,  5.3119e-06,  5.2754e-07,\n",
       "            -7.5493e-07, -1.8018e-06,  2.9429e-07, -2.6943e-06, -2.0769e-06,\n",
       "            -8.1791e-07,  7.1092e-07,  1.4806e-06,  8.4263e-07,  3.5026e-07,\n",
       "            -2.0271e-06,  1.0041e-08, -4.3535e-07,  7.0135e-07,  1.7864e-07,\n",
       "             5.4778e-07,  4.0902e-07,  1.8265e-07, -1.9323e-07,  6.0620e-06,\n",
       "             2.6484e-06,  1.9400e-06,  5.9018e-06,  3.4585e-06,  4.7964e-07,\n",
       "             1.0128e-06, -6.3278e-07, -3.2162e-06, -1.2473e-06, -1.6338e-06,\n",
       "             5.0045e-06,  5.4972e-07, -1.4685e-06, -3.4680e-07, -8.6490e-07,\n",
       "             4.9350e-06, -1.2674e-06, -1.3201e-06, -1.3409e-06, -9.4179e-07,\n",
       "            -6.9576e-07,  1.9902e-06, -1.7507e-06, -1.2593e-06,  9.0008e-07,\n",
       "             1.5556e-06,  1.8878e-07, -1.7695e-06, -8.4219e-07, -1.6728e-08,\n",
       "            -8.1962e-07,  8.7827e-07,  7.1512e-07, -6.3547e-07, -5.1296e-07,\n",
       "            -2.6509e-06, -1.7409e-06,  2.6305e-06, -1.7292e-06, -3.0335e-06,\n",
       "             3.2606e-06, -1.7443e-06, -1.3855e-06,  4.8211e-07, -3.5577e-07,\n",
       "             3.3967e-07,  1.3019e-06,  7.6239e-07,  7.7262e-06,  3.6231e-07,\n",
       "             3.2568e-07,  8.3086e-07, -1.7122e-06, -6.9540e-07, -2.8625e-07,\n",
       "            -1.0862e-06,  1.0804e-05, -2.0665e-06, -1.7175e-07,  3.2833e-07,\n",
       "             1.9708e-06, -1.4008e-06, -2.5310e-06,  1.0159e-05,  7.5967e-06,\n",
       "             8.7961e-07, -1.6761e-06,  2.0394e-06,  3.0373e-07,  7.2174e-07,\n",
       "             9.7139e-07, -5.6453e-06,  3.1597e-06, -1.5169e-06, -8.5866e-07,\n",
       "            -4.6415e-07,  4.8383e-06,  5.7199e-06, -1.7557e-06,  4.5366e-07,\n",
       "             9.6537e-06, -4.8402e-07, -1.1539e-06, -1.0713e-06, -1.1193e-07,\n",
       "             1.4981e-06,  4.1368e-06,  4.4125e-06,  3.0191e-06,  2.0861e-06,\n",
       "             1.0230e-06,  4.7794e-06, -4.2488e-07, -5.2825e-07,  2.3344e-07,\n",
       "            -3.2178e-07, -1.6782e-06,  6.3284e-07, -4.3661e-07,  8.5528e-07,\n",
       "             5.5478e-07, -4.1755e-07,  1.2902e-06,  4.3997e-07,  3.1782e-07,\n",
       "             7.6195e-07,  1.4702e-06, -1.6296e-07,  2.1978e-06,  3.8999e-07,\n",
       "             8.5283e-07,  1.7554e-07, -2.1469e-07, -3.6332e-08, -3.6056e-07,\n",
       "            -8.7334e-07, -4.4438e-06,  2.2706e-07,  3.3260e-06,  1.1101e-07,\n",
       "             3.8645e-06,  1.7323e-06,  1.0308e-05,  4.5123e-08, -2.7054e-06,\n",
       "            -3.8192e-07,  1.7907e-07, -6.9580e-07, -7.3963e-08,  1.0214e-07,\n",
       "             4.2134e-07,  7.9132e-07, -8.7816e-07,  1.0673e-06, -8.4481e-08,\n",
       "            -2.1430e-07, -4.7449e-06,  1.9734e-07,  1.3520e-06,  1.2273e-06,\n",
       "             1.9471e-06,  4.0401e-06,  4.7042e-07,  8.5900e-07,  1.8023e-07,\n",
       "            -1.0529e-06,  7.3484e-07,  1.6853e-06, -1.0572e-07,  4.0399e-06,\n",
       "             2.1545e-07,  3.8638e-06, -1.6346e-06, -2.5908e-06,  6.0499e-07,\n",
       "             4.4005e-07, -1.8805e-08,  2.1806e-07,  3.1016e-06, -1.4471e-06,\n",
       "             1.1270e-06,  5.7744e-07, -1.6804e-06, -4.8999e-07,  4.0974e-07,\n",
       "             1.0920e-06, -3.7486e-07,  1.8792e-06,  5.5425e-07,  3.3110e-07,\n",
       "             5.6839e-07, -2.0798e-07, -6.9617e-07,  5.8042e-06, -2.3603e-06,\n",
       "            -1.9596e-06,  8.8088e-07, -1.8319e-06,  4.6326e-07, -2.1898e-06,\n",
       "             1.5792e-07,  7.4539e-07,  1.7870e-06, -3.2362e-06,  4.0714e-06,\n",
       "             3.9233e-06, -9.1275e-09, -3.3982e-06,  1.0139e-06, -3.0695e-07,\n",
       "            -2.8127e-08, -2.3918e-07,  6.2819e-07,  9.2479e-10,  2.6973e-06,\n",
       "             5.1425e-07,  5.7378e-06,  1.5260e-06, -6.0197e-07, -6.2116e-07,\n",
       "             4.4189e-08, -2.4984e-06,  1.7484e-06,  4.5477e-07,  2.3823e-07,\n",
       "             2.1439e-07, -3.5183e-07, -2.2793e-07,  2.6483e-07, -2.8255e-06,\n",
       "             2.8719e-08,  1.4665e-06, -1.2758e-06, -3.1612e-07,  4.4188e-07,\n",
       "            -2.6571e-06,  4.6086e-07,  4.0933e-07, -6.0677e-09,  2.0463e-08,\n",
       "            -3.0494e-07, -2.7466e-06,  3.8388e-08, -8.1768e-07,  1.2587e-06,\n",
       "             5.2600e-07,  2.0376e-07,  1.8814e-06,  5.9092e-08, -2.1148e-06,\n",
       "            -1.0186e-06, -1.4755e-06, -4.8194e-07, -1.2227e-06, -3.6943e-08,\n",
       "            -1.2401e-07,  3.5554e-07,  9.3341e-07, -4.1195e-07, -2.5191e-06]),\n",
       "    'exp_avg_sq': tensor([4.5086e-10, 2.0669e-10, 1.0947e-09, 3.3183e-09, 1.2584e-10, 2.0107e-10,\n",
       "            1.2293e-10, 1.9290e-10, 2.2464e-10, 1.7720e-10, 5.8238e-10, 6.5181e-12,\n",
       "            1.4620e-10, 1.4643e-10, 1.5477e-11, 3.5474e-11, 1.1871e-10, 3.0313e-11,\n",
       "            2.1950e-11, 4.6168e-11, 9.2851e-11, 9.6521e-11, 1.7743e-11, 2.9527e-11,\n",
       "            3.1959e-09, 1.2504e-10, 2.4450e-10, 5.0626e-10, 1.4499e-10, 1.3884e-10,\n",
       "            5.0489e-11, 7.4296e-11, 3.8946e-10, 4.6530e-11, 1.1494e-10, 2.2147e-10,\n",
       "            1.7841e-10, 2.0294e-10, 5.0726e-11, 3.8011e-10, 2.9651e-10, 1.4858e-10,\n",
       "            2.8742e-11, 2.1867e-10, 1.6741e-11, 5.0992e-11, 7.2185e-11, 1.5198e-10,\n",
       "            2.7106e-10, 2.0345e-11, 4.8892e-11, 6.7265e-11, 1.0963e-10, 1.9987e-10,\n",
       "            1.3840e-11, 3.8199e-11, 1.1862e-10, 8.3769e-11, 8.0280e-11, 5.9664e-11,\n",
       "            4.0861e-10, 9.8318e-11, 4.0812e-11, 4.7872e-11, 2.3900e-10, 3.3526e-10,\n",
       "            4.1939e-10, 1.3506e-10, 2.2233e-11, 4.5621e-12, 7.6749e-12, 1.7074e-11,\n",
       "            7.6640e-11, 7.7442e-10, 1.2036e-09, 4.9302e-12, 5.6811e-11, 3.6469e-11,\n",
       "            4.3981e-10, 3.8857e-12, 7.8861e-11, 1.4709e-09, 3.0223e-11, 9.9770e-11,\n",
       "            7.6760e-10, 4.1858e-10, 5.4242e-10, 1.2596e-10, 1.2061e-09, 6.5618e-10,\n",
       "            9.2498e-11, 8.4479e-11, 1.5732e-11, 2.1167e-10, 9.7300e-11, 1.8668e-10,\n",
       "            4.9858e-10, 5.7952e-11, 2.0070e-10, 9.0304e-10, 1.0172e-10, 1.5708e-10,\n",
       "            6.5268e-10, 1.6047e-10, 1.6968e-10, 1.1944e-09, 1.7631e-10, 3.7006e-11,\n",
       "            1.0741e-10, 5.1287e-10, 1.4534e-11, 2.8526e-10, 1.4904e-10, 1.4373e-10,\n",
       "            2.5295e-10, 7.4390e-11, 9.5686e-11, 4.1468e-11, 4.8750e-11, 2.0013e-10,\n",
       "            1.5426e-10, 1.5611e-10, 6.6822e-11, 1.7496e-10, 6.9326e-11, 3.2891e-11,\n",
       "            1.3268e-10, 1.3993e-11, 2.5730e-11, 3.7973e-11, 3.0280e-11, 3.4019e-10,\n",
       "            5.9484e-11, 2.1425e-10, 2.9656e-11, 2.3085e-11, 8.0530e-11, 3.9318e-11,\n",
       "            4.3189e-11, 2.0939e-11, 1.0493e-10, 2.5567e-10, 6.7702e-11, 1.3502e-10,\n",
       "            5.7171e-11, 3.4804e-10, 1.4710e-10, 2.0443e-09, 2.7316e-12, 3.1864e-10,\n",
       "            1.7721e-10, 1.8831e-10, 1.9442e-11, 5.1573e-11, 3.4713e-11, 2.2355e-10,\n",
       "            3.6461e-10, 3.9785e-11, 5.3907e-10, 1.1344e-11, 3.9343e-10, 1.9786e-10,\n",
       "            3.3633e-11, 6.5501e-11, 4.7620e-11, 1.2282e-10, 2.2436e-10, 1.9521e-11,\n",
       "            1.6476e-11, 4.6972e-11, 2.9886e-11, 8.1072e-11, 8.2647e-11, 2.0736e-10,\n",
       "            6.0833e-10, 9.9509e-12, 2.5693e-10, 1.5934e-10, 1.8620e-10, 5.5796e-11,\n",
       "            7.0755e-12, 6.7665e-11, 1.6325e-11, 9.3720e-11, 2.0353e-10, 9.8965e-11,\n",
       "            8.7720e-11, 6.3347e-11, 2.6192e-11, 2.2237e-10, 3.0387e-10, 5.5279e-11,\n",
       "            7.5089e-11, 1.1399e-10, 2.5712e-11, 3.0689e-11, 6.5128e-12, 2.7983e-10,\n",
       "            1.4522e-09, 7.7819e-11, 1.4912e-09, 8.6916e-11, 1.3473e-10, 6.9563e-11,\n",
       "            6.5390e-11, 9.5461e-12, 3.8413e-10, 1.8020e-10, 1.1456e-10, 7.0391e-10,\n",
       "            6.2598e-10, 5.8135e-11, 1.4436e-10, 2.3394e-10, 2.6236e-10, 2.4114e-10,\n",
       "            1.8652e-10, 4.4955e-11, 6.0884e-11, 1.5171e-10, 1.0837e-10, 7.0055e-10,\n",
       "            2.6770e-10, 7.4606e-11, 5.9436e-11, 7.4469e-11, 1.0147e-10, 3.5264e-10,\n",
       "            4.9492e-11, 4.5392e-11, 2.0072e-11, 7.1864e-11, 7.6485e-12, 6.3132e-11,\n",
       "            9.2581e-10, 3.0027e-10, 3.0673e-10, 1.1062e-10, 4.6551e-11, 6.9515e-11,\n",
       "            2.9232e-10, 6.0181e-11, 4.5060e-11, 5.1088e-11, 9.4448e-11, 3.0550e-11,\n",
       "            2.9565e-10, 1.4955e-11, 2.2516e-11, 4.8574e-11, 7.2356e-12, 2.5666e-10,\n",
       "            1.1536e-10, 8.5957e-12, 4.6956e-10, 2.8317e-10, 5.0979e-11, 4.8336e-12,\n",
       "            3.5953e-11, 2.2430e-10, 2.8144e-11, 3.8329e-11, 4.3585e-11, 1.3099e-10,\n",
       "            2.2398e-10])},\n",
       "   140493485120960: {'step': 1528596,\n",
       "    'exp_avg': tensor([[ 6.5484e-08, -1.3773e-06, -1.0324e-06,  ...,  3.7759e-06,\n",
       "              3.5709e-06,  5.1315e-07],\n",
       "            [ 1.6756e-06,  2.2771e-07,  1.1082e-06,  ...,  6.5666e-07,\n",
       "             -9.4588e-07,  7.3592e-07],\n",
       "            [-1.8459e-07,  1.6142e-06, -2.8534e-07,  ..., -7.5728e-07,\n",
       "              3.8656e-07, -1.2443e-07],\n",
       "            ...,\n",
       "            [-4.1673e-06,  5.5829e-06, -2.1867e-06,  ..., -5.9159e-07,\n",
       "             -5.1520e-07, -5.4399e-07],\n",
       "            [-3.3346e-06, -8.7801e-07, -6.6490e-06,  ...,  2.1760e-07,\n",
       "             -7.0660e-07,  6.9429e-07],\n",
       "            [ 3.2389e-06,  5.5659e-06,  1.3761e-06,  ..., -3.8021e-06,\n",
       "             -2.2513e-06, -2.7073e-06]]),\n",
       "    'exp_avg_sq': tensor([[2.5772e-10, 5.5349e-10, 1.3344e-10,  ..., 7.9615e-10, 2.2881e-10,\n",
       "             1.1932e-10],\n",
       "            [1.0917e-10, 2.1231e-10, 6.7479e-11,  ..., 1.1262e-10, 1.3748e-10,\n",
       "             3.7088e-11],\n",
       "            [9.7857e-11, 5.9142e-11, 3.1420e-11,  ..., 3.7628e-11, 7.6654e-11,\n",
       "             9.2722e-12],\n",
       "            ...,\n",
       "            [2.9182e-09, 1.1253e-09, 1.8193e-09,  ..., 1.5936e-09, 1.3701e-09,\n",
       "             4.0311e-10],\n",
       "            [5.8978e-10, 3.9285e-11, 8.8307e-10,  ..., 1.5196e-10, 1.0813e-10,\n",
       "             1.1706e-10],\n",
       "            [5.7556e-10, 6.2190e-10, 3.7302e-10,  ..., 2.9954e-10, 2.8895e-10,\n",
       "             1.1295e-10]])},\n",
       "   140493485121040: {'step': 1528596,\n",
       "    'exp_avg': tensor([-3.4907e-07, -5.8185e-07,  7.0687e-08,  9.1602e-08, -7.6171e-07,\n",
       "             3.2128e-06,  2.6993e-06, -1.7753e-06,  9.8897e-07,  1.9295e-06,\n",
       "            -4.1456e-07, -6.2239e-07,  7.6975e-08, -7.0892e-07, -3.4610e-07,\n",
       "             9.5179e-08, -1.4135e-06, -6.6752e-08, -1.7876e-06, -9.6414e-08,\n",
       "             1.6873e-06, -3.5645e-07,  1.1708e-06, -9.5552e-07,  1.4187e-06,\n",
       "             1.9242e-06,  1.0888e-06, -5.7872e-07, -1.3801e-06, -1.8826e-06,\n",
       "             7.6763e-07,  1.4233e-06,  4.1648e-08,  1.6648e-06, -9.4180e-08,\n",
       "            -8.3846e-08, -4.3124e-07,  1.9389e-06,  5.3242e-06, -2.8057e-06,\n",
       "            -7.5779e-08,  2.1214e-06,  5.7897e-07,  6.1188e-06,  1.8411e-07,\n",
       "             1.6761e-06,  1.7392e-06,  3.0008e-06,  5.7747e-07, -4.8762e-07,\n",
       "            -4.0282e-07,  9.1463e-07, -3.2161e-07,  5.8646e-07, -2.5929e-06,\n",
       "             5.3234e-09, -3.9804e-06, -1.3056e-06, -8.5422e-08, -1.1987e-06,\n",
       "             5.8663e-07,  1.1521e-06, -3.1161e-06,  2.0668e-06, -8.3804e-07,\n",
       "            -2.9943e-07, -2.7337e-06, -1.0022e-06, -1.6629e-06,  2.4677e-06,\n",
       "            -3.9253e-07, -2.8065e-06, -4.2274e-07, -1.3546e-06, -1.2322e-06,\n",
       "            -2.9551e-06, -2.6841e-06, -8.9549e-07, -1.0850e-06, -3.0384e-06,\n",
       "            -1.4983e-06,  3.7352e-07,  1.8872e-06,  4.8941e-07, -4.3638e-07,\n",
       "             1.0464e-06,  1.9243e-06, -1.1578e-06,  4.4756e-07, -5.7999e-07,\n",
       "            -1.0439e-07,  1.0730e-06,  1.2124e-07,  1.8998e-06,  9.3401e-07,\n",
       "            -5.4296e-07,  1.2439e-06,  5.4598e-07, -9.7316e-08, -6.9737e-07,\n",
       "            -1.5210e-07, -1.3265e-06, -8.6874e-08, -2.4949e-06, -1.1127e-06,\n",
       "             4.0442e-07,  2.4842e-06, -9.5957e-07, -2.3774e-07,  2.8183e-07,\n",
       "            -6.6536e-07, -1.7643e-06, -1.6946e-06, -1.7089e-06, -1.3026e-06,\n",
       "            -1.5464e-06, -1.8467e-07, -1.6864e-07,  1.3507e-06, -2.1057e-06,\n",
       "            -3.0231e-06,  1.2002e-06,  2.6058e-06, -3.9368e-06,  2.7150e-06,\n",
       "             1.4235e-06, -2.1004e-07,  2.6769e-06]),\n",
       "    'exp_avg_sq': tensor([1.1762e-10, 3.4839e-11, 9.1478e-12, 1.8423e-11, 3.5726e-11, 1.4462e-10,\n",
       "            3.1979e-10, 5.6733e-11, 1.6242e-10, 3.2011e-11, 3.6493e-11, 2.0483e-10,\n",
       "            2.5723e-11, 1.1528e-11, 6.9253e-11, 7.8499e-11, 8.0864e-11, 3.7666e-10,\n",
       "            3.6959e-10, 3.8584e-11, 8.8109e-11, 3.1985e-11, 5.0530e-11, 9.7386e-11,\n",
       "            2.5297e-10, 9.3450e-11, 3.7316e-10, 1.0303e-11, 5.4425e-11, 5.0591e-10,\n",
       "            1.2525e-10, 2.3311e-10, 2.8222e-11, 4.3528e-11, 4.7973e-11, 3.1910e-10,\n",
       "            8.8571e-11, 1.0102e-10, 2.5001e-10, 1.3001e-10, 4.1646e-11, 1.2667e-10,\n",
       "            8.8920e-11, 2.8746e-10, 1.3003e-10, 1.7699e-10, 6.4910e-11, 1.0570e-09,\n",
       "            3.6569e-10, 8.2544e-11, 3.2634e-11, 6.3788e-11, 4.2164e-11, 1.9127e-11,\n",
       "            2.7820e-10, 4.1081e-10, 5.1317e-11, 4.3786e-11, 1.3818e-11, 1.6584e-10,\n",
       "            3.0579e-11, 5.7679e-11, 1.3318e-10, 1.0675e-11, 1.1719e-10, 1.3117e-11,\n",
       "            2.6224e-10, 1.3717e-10, 1.5379e-10, 2.2020e-10, 9.6049e-11, 9.9901e-11,\n",
       "            5.2222e-11, 8.5060e-11, 6.2839e-11, 1.1029e-10, 3.4725e-11, 1.1586e-10,\n",
       "            5.7305e-11, 3.4808e-11, 1.8553e-10, 2.5618e-11, 1.4084e-10, 7.2642e-11,\n",
       "            5.6344e-11, 1.6181e-11, 7.2355e-11, 6.7376e-11, 2.8608e-11, 4.3388e-11,\n",
       "            1.4900e-10, 8.0364e-11, 3.2683e-11, 8.0868e-11, 1.2698e-11, 1.9276e-10,\n",
       "            7.3972e-11, 1.3998e-09, 1.1069e-11, 2.9433e-11, 2.2272e-11, 7.9332e-11,\n",
       "            4.4325e-11, 4.7199e-11, 1.9576e-10, 1.4636e-10, 1.7086e-10, 5.4723e-11,\n",
       "            6.3898e-11, 1.3104e-11, 1.9073e-11, 2.7425e-10, 1.4819e-10, 8.7133e-11,\n",
       "            4.7350e-11, 1.2291e-10, 9.6225e-11, 1.2576e-11, 5.5819e-10, 2.2455e-11,\n",
       "            1.7242e-10, 5.3734e-11, 6.0776e-10, 1.2555e-10, 1.8382e-10, 3.2119e-10,\n",
       "            1.1602e-10, 1.0915e-10])},\n",
       "   140493485120640: {'step': 1528596,\n",
       "    'exp_avg': tensor([[-1.4360e-05,  2.0348e-06,  1.1630e-05, -7.4359e-06, -1.0966e-04,\n",
       "             -3.7578e-05,  5.5139e-05, -9.1374e-06, -3.4843e-05, -1.7487e-05,\n",
       "              1.7376e-05,  3.3968e-05,  2.9646e-05,  1.5026e-05, -1.1577e-04,\n",
       "             -6.4769e-05,  4.2333e-05, -7.2196e-07,  1.0978e-05,  1.4952e-05,\n",
       "              9.6853e-05,  2.9811e-05, -2.4312e-05,  1.2802e-04,  7.2564e-06,\n",
       "             -2.5170e-05, -6.8582e-05, -6.0715e-06,  1.3728e-05, -1.4909e-05,\n",
       "             -1.7504e-04, -9.9739e-06,  4.3905e-05,  2.9813e-05, -3.1901e-05,\n",
       "             -1.2789e-05,  5.4640e-05,  4.8095e-06, -6.5947e-05, -4.5059e-05,\n",
       "              3.0807e-05, -7.4011e-07, -5.6758e-06, -7.2943e-06, -2.8783e-05,\n",
       "              6.9236e-05,  3.2011e-05, -5.2147e-06,  4.9526e-05,  1.1341e-05,\n",
       "              1.2580e-05, -1.5418e-04,  1.3740e-05,  5.4596e-06, -3.9390e-05,\n",
       "              6.7810e-05, -1.9582e-05, -1.5278e-04, -6.4060e-05, -8.3049e-05,\n",
       "             -2.7903e-05,  1.0585e-04, -6.3447e-08,  2.7311e-05, -2.8336e-05,\n",
       "              1.0566e-06, -1.0435e-04, -3.2792e-05, -3.8061e-05,  2.5685e-05,\n",
       "             -1.1924e-05, -3.2670e-05,  1.6423e-05,  8.8292e-05,  2.9575e-05,\n",
       "             -5.1487e-05,  4.6295e-06, -1.1224e-04, -4.2367e-06,  1.4547e-05,\n",
       "              1.8796e-05, -4.1071e-05, -4.0278e-05,  6.0010e-06, -1.3592e-04,\n",
       "              3.1152e-05, -2.4635e-05,  1.4033e-04, -2.0924e-05,  1.6387e-05,\n",
       "             -8.8085e-07, -2.0516e-04, -1.0443e-06, -8.7250e-05,  7.5802e-05,\n",
       "              1.4631e-04, -9.4014e-05,  2.1440e-05,  4.2911e-05,  5.0549e-06,\n",
       "              5.4947e-05, -1.0697e-05, -2.3316e-05, -3.2731e-06, -1.7623e-06,\n",
       "             -8.4976e-05, -9.6337e-05,  2.9679e-05,  1.2440e-06,  4.8719e-06,\n",
       "              1.9876e-05, -4.5413e-05, -5.5953e-07, -7.7696e-05,  7.4451e-05,\n",
       "              5.4236e-06, -5.8768e-05,  2.9590e-05, -7.5930e-05,  4.3021e-05,\n",
       "             -3.3622e-05,  7.2029e-06,  5.9751e-05, -1.1508e-04, -1.8584e-04,\n",
       "              7.1397e-05, -1.0176e-04,  3.2477e-05],\n",
       "            [-2.1842e-06,  1.5942e-06, -4.9102e-06, -2.7220e-05, -1.1151e-05,\n",
       "             -3.6310e-05,  7.1723e-06, -1.1069e-05,  4.5803e-05, -1.3647e-05,\n",
       "             -6.0963e-06, -3.1357e-06,  2.9248e-05,  1.1207e-05, -4.8072e-05,\n",
       "             -1.9134e-06,  1.2264e-05,  3.9164e-06, -2.5655e-06, -3.1152e-06,\n",
       "              6.8082e-06, -6.9229e-06, -7.6489e-05,  5.8161e-05, -8.9736e-06,\n",
       "             -1.1661e-06, -6.6228e-06, -3.0132e-06, -2.7863e-05, -7.3766e-06,\n",
       "             -1.0455e-04,  1.7632e-06, -9.6559e-06, -3.7055e-05, -4.5278e-05,\n",
       "             -3.1996e-06,  7.7101e-07, -2.5119e-05,  3.6134e-05, -4.5331e-05,\n",
       "             -3.3508e-05, -1.2370e-06, -5.9576e-05, -6.9810e-06, -2.0843e-05,\n",
       "              2.1043e-05,  1.2978e-05, -6.8399e-06,  7.6258e-06,  1.5521e-07,\n",
       "             -3.4187e-06,  8.1914e-05, -2.3846e-06, -4.2624e-06, -2.2806e-06,\n",
       "              4.7690e-05, -6.3447e-06, -7.1591e-05, -1.9265e-06, -2.9730e-05,\n",
       "             -9.6846e-06,  5.4071e-05,  3.1058e-05,  4.2764e-06, -9.4657e-06,\n",
       "              6.7564e-06, -2.3376e-05,  7.8829e-06, -1.6362e-05,  3.8383e-05,\n",
       "             -7.0390e-05, -3.8655e-05, -1.5638e-05,  2.5457e-05, -5.3432e-05,\n",
       "             -4.3249e-05, -9.6171e-06, -1.9827e-05, -3.7758e-05,  1.8120e-05,\n",
       "              3.6632e-06, -1.2141e-05, -4.4453e-05, -4.3913e-06, -6.7449e-05,\n",
       "             -5.7467e-06, -6.0947e-05,  9.9194e-05, -8.0706e-06, -3.6561e-05,\n",
       "              4.3099e-05,  2.8151e-06, -9.3466e-06, -8.6108e-06,  9.9193e-06,\n",
       "              4.9658e-05, -1.0659e-05,  7.7328e-05, -1.6759e-05, -5.5394e-05,\n",
       "              3.8552e-05, -4.9672e-07, -2.8884e-05, -6.8463e-05, -1.3048e-05,\n",
       "             -5.5691e-06, -7.2196e-05, -9.3486e-06,  3.6726e-06, -5.4436e-06,\n",
       "             -2.3460e-06,  3.3754e-05, -7.8787e-06,  1.4086e-05,  1.8490e-05,\n",
       "              4.1080e-06,  3.4347e-06,  2.4067e-06,  3.7715e-05, -1.7910e-06,\n",
       "              1.6957e-05, -6.4862e-05, -7.2308e-06, -4.4050e-05, -1.1310e-04,\n",
       "             -1.7789e-06,  2.1039e-05,  7.0357e-05]]),\n",
       "    'exp_avg_sq': tensor([[2.3947e-08, 1.7783e-07, 1.0273e-07, 2.2264e-08, 4.6953e-07, 5.9373e-08,\n",
       "             1.1257e-07, 1.1683e-08, 1.1247e-06, 3.6430e-08, 5.1650e-08, 7.7501e-07,\n",
       "             6.2262e-07, 6.4210e-08, 5.0694e-07, 3.9926e-08, 3.6449e-08, 2.4352e-08,\n",
       "             4.2074e-07, 4.7677e-08, 9.1870e-08, 7.4814e-08, 2.2505e-07, 2.6963e-06,\n",
       "             2.3745e-08, 1.3239e-08, 7.7940e-08, 7.3488e-08, 1.9661e-08, 5.4350e-08,\n",
       "             3.8163e-07, 4.9945e-07, 8.7299e-08, 8.3973e-08, 1.9058e-07, 2.5206e-08,\n",
       "             9.8401e-08, 3.6451e-08, 3.0477e-08, 7.9146e-08, 1.9435e-07, 1.1529e-08,\n",
       "             3.8337e-08, 9.7348e-09, 1.5379e-07, 3.1805e-07, 8.2774e-08, 2.9603e-08,\n",
       "             1.7594e-07, 1.8492e-08, 1.0362e-07, 3.1851e-07, 1.8439e-08, 1.0641e-08,\n",
       "             5.7271e-08, 1.1344e-06, 1.4209e-08, 3.5709e-07, 5.5025e-08, 5.6479e-08,\n",
       "             2.4095e-08, 4.0510e-07, 1.3794e-07, 1.4440e-08, 3.3760e-08, 1.6884e-08,\n",
       "             1.8386e-07, 5.1209e-08, 2.1563e-07, 7.6912e-07, 9.4935e-08, 1.2818e-07,\n",
       "             4.1812e-08, 1.8293e-07, 4.2289e-08, 1.1040e-07, 1.4970e-08, 1.3515e-06,\n",
       "             4.4105e-08, 1.7757e-08, 1.7511e-08, 9.0110e-08, 5.0078e-08, 1.3493e-08,\n",
       "             6.4021e-07, 4.1421e-08, 8.2142e-08, 1.7174e-06, 1.0998e-08, 3.8471e-08,\n",
       "             3.2279e-07, 1.1781e-06, 5.3747e-08, 4.3125e-08, 5.5626e-08, 2.6146e-07,\n",
       "             3.8506e-07, 2.0013e-06, 6.2041e-08, 4.3518e-08, 1.9558e-07, 2.0415e-08,\n",
       "             6.6844e-08, 7.3902e-08, 1.6012e-08, 5.8928e-08, 2.2223e-07, 5.6794e-08,\n",
       "             1.2717e-08, 1.2308e-08, 2.2531e-08, 9.5366e-08, 1.5722e-07, 5.8413e-07,\n",
       "             1.2777e-06, 2.2200e-07, 1.1308e-07, 3.8760e-08, 2.0362e-07, 1.9865e-08,\n",
       "             8.2693e-08, 4.9236e-08, 5.1730e-08, 1.7742e-07, 5.1311e-07, 2.1801e-07,\n",
       "             1.0685e-07, 9.1272e-07],\n",
       "            [1.7169e-08, 5.2625e-08, 1.5742e-08, 7.7613e-09, 6.6207e-08, 7.4262e-08,\n",
       "             1.4237e-08, 1.1287e-09, 4.5533e-08, 1.6663e-08, 7.7857e-09, 3.5151e-08,\n",
       "             3.5186e-08, 2.2639e-09, 1.3252e-07, 6.4121e-09, 1.7165e-08, 5.5316e-09,\n",
       "             4.7976e-08, 7.7414e-09, 9.9987e-09, 6.2860e-09, 6.5140e-08, 2.3115e-07,\n",
       "             4.6467e-09, 1.1239e-09, 1.1100e-08, 6.0534e-09, 3.2513e-09, 1.6369e-08,\n",
       "             1.8518e-07, 1.1197e-07, 1.2664e-08, 4.9653e-08, 3.4184e-08, 4.3623e-09,\n",
       "             1.0512e-08, 1.9192e-08, 7.3553e-09, 6.2309e-08, 2.2172e-08, 1.0040e-09,\n",
       "             4.6501e-08, 6.5476e-09, 1.0792e-08, 3.1087e-08, 3.6381e-09, 1.9293e-09,\n",
       "             2.0728e-08, 1.2986e-09, 6.7439e-09, 4.8431e-08, 1.4944e-09, 1.1876e-09,\n",
       "             1.3298e-08, 8.9233e-08, 1.1324e-09, 1.0650e-07, 3.7078e-08, 1.5774e-08,\n",
       "             3.3868e-09, 3.4579e-08, 1.1164e-08, 8.7488e-10, 2.9462e-08, 4.0653e-09,\n",
       "             1.5721e-08, 1.3111e-08, 4.1028e-08, 7.4739e-08, 9.8823e-08, 6.0789e-08,\n",
       "             3.6786e-09, 1.4441e-08, 4.5261e-08, 2.9705e-08, 1.7010e-09, 1.3729e-07,\n",
       "             2.5971e-08, 1.9141e-09, 1.8622e-09, 5.3978e-08, 4.4056e-08, 3.3566e-09,\n",
       "             1.4231e-07, 2.0351e-09, 3.7590e-08, 9.8041e-08, 3.8883e-09, 3.5730e-08,\n",
       "             5.3193e-08, 8.3698e-08, 2.0017e-09, 8.5462e-09, 1.7901e-09, 2.8040e-08,\n",
       "             5.3760e-08, 1.2968e-07, 7.7583e-09, 3.1041e-08, 8.5038e-09, 9.7464e-10,\n",
       "             9.4770e-09, 3.1513e-08, 4.8450e-09, 4.7486e-09, 1.4724e-07, 3.2340e-09,\n",
       "             2.1703e-09, 1.9592e-09, 1.0021e-09, 1.0856e-08, 8.6250e-09, 5.9537e-08,\n",
       "             7.7114e-08, 1.8436e-08, 1.5905e-08, 2.5918e-09, 1.1721e-08, 1.0556e-09,\n",
       "             6.3554e-09, 3.5281e-08, 1.2740e-08, 3.8296e-08, 1.9572e-07, 3.2908e-08,\n",
       "             1.9920e-08, 1.0504e-07]])},\n",
       "   140493485120400: {'step': 1528596,\n",
       "    'exp_avg': tensor([-6.0428e-06,  1.6645e-06]),\n",
       "    'exp_avg_sq': tensor([9.4207e-09, 7.6660e-10])}},\n",
       "  'param_groups': [{'lr': 0.0001,\n",
       "    'betas': (0.9, 0.999),\n",
       "    'eps': 1e-08,\n",
       "    'weight_decay': 0,\n",
       "    'amsgrad': False,\n",
       "    'params': [140493485120880,\n",
       "     140493485120000,\n",
       "     140493485120960,\n",
       "     140493485121040,\n",
       "     140493485120640,\n",
       "     140493485120400]}]},\n",
       " 'critic_opt_0': {'state': {140493485556192: {'step': 1528596,\n",
       "    'exp_avg': tensor([[-8.3627e-07, -5.6970e-08, -2.3307e-07,  ..., -1.9741e-07,\n",
       "              3.9143e-06,  2.2845e-07],\n",
       "            [-1.2647e-06, -2.6471e-07,  2.1770e-06,  ...,  2.0470e-07,\n",
       "             -2.5910e-06, -7.0355e-07],\n",
       "            [ 4.9252e-06,  3.4605e-07,  4.8983e-06,  ..., -6.7360e-08,\n",
       "             -6.5913e-06, -2.8057e-07],\n",
       "            ...,\n",
       "            [ 1.2961e-06,  1.2951e-07,  1.9278e-06,  ..., -1.1659e-07,\n",
       "              8.0336e-07, -1.3749e-07],\n",
       "            [ 1.4552e-05,  2.1411e-06, -2.6082e-05,  ..., -1.8628e-06,\n",
       "              3.6593e-06,  3.9247e-06],\n",
       "            [ 8.3433e-06, -2.3131e-06,  6.9629e-06,  ..., -3.0421e-08,\n",
       "             -3.7904e-05,  7.5304e-06]]),\n",
       "    'exp_avg_sq': tensor([[6.6460e-11, 1.8976e-12, 6.6119e-10,  ..., 3.3799e-12, 5.0222e-10,\n",
       "             2.7761e-11],\n",
       "            [3.6179e-11, 9.2459e-13, 2.3423e-10,  ..., 2.3871e-12, 3.2905e-10,\n",
       "             1.1881e-11],\n",
       "            [1.8776e-10, 4.2647e-12, 3.2038e-10,  ..., 2.5892e-12, 1.0205e-09,\n",
       "             4.4866e-11],\n",
       "            ...,\n",
       "            [3.9084e-10, 2.8316e-12, 2.8216e-10,  ..., 9.0729e-12, 2.7478e-10,\n",
       "             2.2222e-11],\n",
       "            [4.6236e-09, 8.0887e-11, 4.2779e-09,  ..., 8.1074e-11, 6.7808e-09,\n",
       "             4.1118e-10],\n",
       "            [8.4232e-09, 1.7631e-10, 9.8204e-09,  ..., 4.8951e-10, 1.4207e-08,\n",
       "             1.2181e-09]])},\n",
       "   140493485556112: {'step': 1528596,\n",
       "    'exp_avg': tensor([ 3.6442e-08,  1.9909e-07, -4.3373e-07, -6.5109e-07, -3.3344e-07,\n",
       "             1.7717e-07, -5.3880e-07, -1.1702e-06,  4.1871e-07, -5.6224e-07,\n",
       "             1.5072e-08,  2.9007e-07, -1.5960e-07, -1.7937e-07,  7.6437e-07,\n",
       "             1.6370e-06,  1.1251e-07,  8.2791e-07, -6.2955e-07, -7.5474e-07,\n",
       "            -2.6294e-07,  1.0066e-08, -2.4175e-08, -7.7073e-09,  2.9406e-07,\n",
       "            -9.5716e-07,  3.6871e-07, -8.6870e-08, -5.5454e-07,  6.9526e-07,\n",
       "            -5.5976e-07, -2.4163e-07,  4.1730e-07, -2.7738e-07, -3.8112e-07,\n",
       "            -5.1382e-08, -1.1357e-06,  5.4794e-07,  1.1967e-07, -6.5966e-09,\n",
       "             2.3640e-07, -4.2677e-07, -6.5832e-07,  5.3181e-07,  4.4448e-07,\n",
       "            -1.0885e-06, -3.7739e-07, -3.3163e-07,  7.0551e-07,  8.5670e-08,\n",
       "            -3.4614e-07,  9.1867e-09, -2.8231e-07, -1.7597e-07,  5.5161e-09,\n",
       "             1.7390e-07,  1.0104e-07, -2.4702e-07,  2.2027e-07,  4.3067e-09,\n",
       "             3.9574e-07,  3.1002e-07, -1.3366e-06, -2.1677e-07,  3.6762e-07,\n",
       "             4.4611e-07, -7.8347e-08,  3.8463e-07, -5.1196e-06,  2.1386e-07,\n",
       "             9.0696e-09,  5.2517e-08, -1.1242e-06, -5.2542e-08,  5.5209e-07,\n",
       "             3.0048e-07,  2.0364e-07,  3.4162e-07,  4.6820e-07,  3.5183e-07,\n",
       "             2.0041e-07, -7.4689e-07,  4.6588e-07,  2.3699e-07,  1.6320e-07,\n",
       "            -2.9313e-08, -3.7810e-07, -8.5487e-07,  1.3176e-07, -2.4049e-07,\n",
       "             1.2490e-06, -3.5829e-07, -1.5022e-06,  9.6704e-08, -1.1307e-06,\n",
       "             6.8987e-09, -1.3044e-06, -1.2107e-07,  2.2927e-07,  1.9756e-07,\n",
       "             1.0179e-07,  1.2847e-06, -5.5379e-07,  2.7832e-07,  9.1495e-07,\n",
       "            -1.1126e-07, -4.8498e-07, -1.0525e-07, -2.6225e-07, -1.2298e-07,\n",
       "             2.1324e-08,  9.6154e-08,  1.2974e-07,  9.1072e-07, -1.0208e-06,\n",
       "             8.5597e-08, -5.6831e-06, -8.2754e-07,  5.8546e-07,  6.0939e-07,\n",
       "             2.6159e-07,  3.7994e-07,  1.2153e-07, -4.3059e-07, -3.5093e-06,\n",
       "             5.5328e-08, -1.2003e-07,  1.7266e-07, -2.4256e-07,  8.2147e-08,\n",
       "             1.1721e-06, -3.1288e-07,  3.8241e-07, -4.6965e-06,  3.8669e-07,\n",
       "             3.1363e-07,  1.6305e-07,  2.2671e-07,  1.1835e-06, -6.2411e-07,\n",
       "            -6.2761e-07,  4.5126e-08,  1.5149e-07, -1.9460e-07,  1.3331e-07,\n",
       "            -5.5386e-07, -1.1914e-07,  2.3706e-07, -3.4780e-06, -5.5910e-07,\n",
       "             5.4500e-08, -1.4361e-07,  1.0122e-08, -3.2063e-08, -4.4610e-06,\n",
       "             2.4398e-06,  3.1672e-08,  4.3257e-07, -1.4431e-06, -6.1568e-07,\n",
       "            -2.3359e-07,  3.3633e-08, -4.0405e-06, -1.1904e-06, -2.9141e-07,\n",
       "            -3.9923e-07, -2.9400e-07,  9.2601e-08,  4.0072e-08,  7.2267e-08,\n",
       "             5.1429e-07,  1.3381e-07,  1.2662e-07,  1.6946e-07, -3.3352e-07,\n",
       "            -3.0981e-07, -6.0127e-07, -8.9844e-07, -3.1222e-07, -1.3794e-06,\n",
       "             5.4211e-07, -5.0553e-07,  1.2540e-07, -6.5047e-07, -2.0911e-07,\n",
       "            -5.1193e-07,  8.6813e-08,  8.6403e-08,  3.8406e-07, -2.9908e-07,\n",
       "            -7.4170e-08,  1.8922e-07, -9.4789e-07, -9.2567e-08,  7.3805e-07,\n",
       "            -8.3133e-07,  4.0063e-08, -5.2333e-08, -2.9664e-07, -8.5837e-07,\n",
       "             8.6377e-08, -5.1270e-07,  1.5175e-07,  4.2816e-07, -4.6482e-07,\n",
       "            -1.0427e-07,  1.3903e-07,  2.3899e-07,  3.1969e-07, -6.0430e-06,\n",
       "            -2.7122e-07,  2.5979e-07, -1.0026e-06,  7.2014e-07, -1.3630e-06,\n",
       "             2.1966e-07, -8.6546e-08,  1.9913e-07, -1.0478e-06,  2.3921e-07,\n",
       "            -2.6752e-07, -1.7693e-06,  6.6961e-07, -8.4834e-07,  1.1668e-06,\n",
       "             9.6839e-09,  7.4194e-07, -5.1818e-07, -2.1539e-07,  4.7927e-07,\n",
       "             4.1171e-07, -7.1136e-08,  3.2807e-07,  4.5643e-07,  9.1219e-08,\n",
       "            -1.2790e-07, -2.5269e-06, -1.2302e-07, -9.5509e-07,  2.2317e-08,\n",
       "            -1.3446e-06, -4.9661e-07, -1.7222e-06, -2.3385e-09, -8.4078e-07,\n",
       "            -3.1425e-07, -4.9509e-07, -2.8090e-07,  2.7017e-07,  1.9053e-07,\n",
       "             6.7677e-08,  5.6191e-08,  2.7111e-07, -1.0870e-07, -1.2552e-06,\n",
       "            -1.0269e-06]),\n",
       "    'exp_avg_sq': tensor([1.3422e-12, 7.5408e-13, 1.8765e-12, 4.6348e-11, 2.7085e-12, 3.1248e-12,\n",
       "            1.1839e-12, 2.2873e-11, 1.8189e-12, 3.0211e-12, 2.9541e-12, 7.7417e-12,\n",
       "            6.1087e-13, 1.5585e-12, 9.6140e-12, 1.6871e-11, 2.2474e-12, 1.2541e-11,\n",
       "            3.0098e-12, 7.1827e-12, 3.2918e-12, 6.1247e-12, 1.6288e-12, 2.8940e-12,\n",
       "            2.2347e-12, 1.2375e-10, 2.6082e-12, 4.5912e-12, 1.0756e-11, 4.4287e-12,\n",
       "            2.3772e-12, 1.8511e-12, 2.9763e-12, 6.7042e-12, 2.6133e-12, 1.7175e-12,\n",
       "            8.0467e-12, 1.1611e-11, 8.2901e-13, 3.7097e-12, 5.5928e-12, 2.9037e-12,\n",
       "            2.4593e-11, 1.1451e-11, 4.1487e-12, 1.6420e-11, 8.6874e-12, 4.1161e-12,\n",
       "            1.4269e-11, 5.4776e-12, 1.1546e-12, 1.9317e-12, 2.0144e-12, 8.4473e-12,\n",
       "            8.7064e-13, 3.0011e-12, 3.9114e-12, 1.7868e-12, 2.6514e-12, 3.8512e-12,\n",
       "            2.6656e-12, 7.6856e-12, 9.5097e-12, 3.9047e-11, 4.6815e-12, 4.8140e-12,\n",
       "            6.7382e-13, 4.7611e-12, 1.6204e-10, 6.1372e-12, 7.7298e-12, 1.1310e-12,\n",
       "            1.3072e-11, 3.7059e-13, 3.4264e-12, 6.6807e-12, 9.9575e-13, 2.2584e-11,\n",
       "            3.2208e-12, 3.8030e-11, 6.8339e-12, 3.7936e-12, 1.0449e-11, 3.2245e-10,\n",
       "            9.6197e-12, 3.3916e-12, 1.3543e-11, 1.5656e-11, 9.5961e-12, 1.8566e-12,\n",
       "            8.8812e-12, 9.3742e-12, 3.8922e-10, 3.8810e-12, 2.0824e-11, 3.5200e-12,\n",
       "            7.0683e-12, 2.2642e-12, 3.2160e-12, 1.9921e-11, 3.8675e-12, 3.6498e-12,\n",
       "            4.5031e-12, 1.2507e-11, 2.1549e-11, 6.2859e-12, 6.9189e-12, 4.0803e-12,\n",
       "            1.0911e-12, 1.0929e-12, 2.8709e-13, 1.4585e-12, 8.4043e-12, 1.6451e-11,\n",
       "            2.7045e-12, 8.8441e-12, 7.4027e-11, 7.3394e-12, 3.9565e-12, 4.6926e-12,\n",
       "            1.4248e-12, 3.9496e-12, 2.3240e-11, 2.5131e-12, 2.3303e-11, 1.6016e-12,\n",
       "            7.1642e-13, 3.0029e-12, 3.1633e-11, 1.3638e-11, 1.1952e-11, 7.0148e-12,\n",
       "            6.8012e-12, 1.0133e-10, 1.0656e-11, 1.2009e-12, 2.1910e-12, 1.0502e-11,\n",
       "            1.8726e-11, 2.3041e-12, 1.5138e-11, 1.6379e-12, 1.5059e-12, 2.6049e-12,\n",
       "            3.0820e-12, 3.5323e-12, 4.4189e-12, 4.7702e-12, 1.5618e-10, 9.9859e-12,\n",
       "            1.8839e-12, 3.3649e-12, 1.8081e-12, 8.9525e-13, 2.9707e-10, 1.4594e-11,\n",
       "            2.6688e-12, 1.8848e-12, 4.9742e-10, 6.0890e-12, 4.2274e-11, 2.1249e-12,\n",
       "            6.4209e-11, 1.0464e-11, 3.1828e-12, 3.6214e-12, 8.1291e-12, 5.5907e-12,\n",
       "            6.6021e-13, 1.2140e-11, 6.9031e-12, 3.7908e-11, 4.3189e-12, 7.0930e-12,\n",
       "            1.1155e-11, 1.0003e-12, 2.6897e-12, 3.0187e-11, 1.4291e-12, 4.4374e-10,\n",
       "            1.4536e-12, 1.0797e-11, 1.3624e-11, 4.7740e-12, 4.8574e-12, 6.9383e-12,\n",
       "            2.8669e-12, 2.9273e-12, 2.8262e-12, 5.7325e-12, 3.4893e-12, 1.7416e-11,\n",
       "            5.2754e-12, 3.7832e-12, 2.0126e-11, 3.6569e-12, 6.0466e-13, 7.0788e-12,\n",
       "            5.8426e-13, 2.8127e-12, 6.8471e-12, 3.3161e-12, 2.2010e-12, 4.1263e-12,\n",
       "            3.0392e-12, 1.0576e-12, 4.7755e-12, 2.9828e-12, 5.9036e-12, 3.9553e-11,\n",
       "            1.4279e-12, 7.7086e-12, 3.2486e-11, 9.4827e-12, 1.3459e-11, 8.3999e-11,\n",
       "            1.7195e-12, 3.3920e-12, 8.8567e-11, 3.2867e-12, 8.8326e-13, 2.9196e-11,\n",
       "            2.5208e-12, 7.7806e-12, 9.2462e-12, 4.4192e-13, 1.3997e-11, 2.5026e-12,\n",
       "            7.3330e-12, 9.7735e-11, 5.2641e-12, 2.8223e-11, 1.0586e-12, 4.0481e-11,\n",
       "            1.6975e-12, 9.8310e-12, 6.0643e-11, 2.0800e-12, 4.8717e-12, 3.4533e-12,\n",
       "            3.4108e-12, 1.0805e-11, 1.3882e-11, 2.1569e-12, 2.3625e-11, 2.8199e-12,\n",
       "            3.0515e-12, 3.5790e-12, 6.0582e-12, 4.4463e-12, 1.0032e-12, 3.1505e-11,\n",
       "            1.3719e-12, 3.6265e-12, 4.2199e-11, 8.3719e-11])},\n",
       "   140493485557072: {'step': 1528596,\n",
       "    'exp_avg': tensor([[-5.7403e-15, -5.5852e-15, -1.0880e-14,  ..., -3.5365e-15,\n",
       "             -5.7557e-15,  2.4572e-15],\n",
       "            [-3.0519e-07, -2.3328e-07, -2.2103e-07,  ...,  7.6445e-08,\n",
       "             -2.3100e-07,  3.1170e-07],\n",
       "            [ 1.3370e-05,  2.2312e-06,  1.4822e-05,  ...,  5.6038e-07,\n",
       "             -3.5753e-07, -3.7796e-07],\n",
       "            ...,\n",
       "            [-1.3198e-07, -1.2995e-07, -1.2995e-07,  ...,  6.7245e-08,\n",
       "             -5.1659e-08, -1.7010e-07],\n",
       "            [ 1.0612e-09,  1.0612e-09,  1.0612e-09,  ...,  1.0626e-09,\n",
       "             -1.0625e-09,  1.0614e-09],\n",
       "            [-1.1025e-08, -1.1088e-08, -1.1017e-08,  ..., -5.0662e-09,\n",
       "              1.3392e-08,  1.0851e-08]]),\n",
       "    'exp_avg_sq': tensor([[1.0431e-20, 1.1116e-20, 5.2711e-21,  ..., 6.0753e-22, 4.4321e-21,\n",
       "             4.4713e-21],\n",
       "            [3.6829e-11, 1.0649e-11, 1.5073e-11,  ..., 6.2931e-12, 4.7088e-12,\n",
       "             5.5793e-12],\n",
       "            [7.2444e-10, 6.9878e-11, 3.0447e-09,  ..., 2.6352e-12, 2.6149e-12,\n",
       "             2.6329e-12],\n",
       "            ...,\n",
       "            [6.3613e-12, 3.5600e-12, 3.4924e-12,  ..., 2.1306e-12, 1.9630e-12,\n",
       "             2.0515e-12],\n",
       "            [1.2630e-13, 3.5195e-12, 1.2630e-13,  ..., 2.2857e-14, 1.0758e-13,\n",
       "             6.5119e-14],\n",
       "            [1.4754e-13, 1.4795e-13, 1.4718e-13,  ..., 9.4566e-14, 1.0251e-13,\n",
       "             1.0801e-13]])},\n",
       "   140493485556832: {'step': 1528596,\n",
       "    'exp_avg': tensor([ 6.4180e-15,  2.3143e-07,  4.5084e-07,  9.2966e-08,  1.2940e-06,\n",
       "             3.4761e-08,  5.2475e-07,  4.3065e-08,  6.6557e-08,  5.8529e-07,\n",
       "            -2.6679e-08,  1.4205e-07, -2.5064e-07,  1.4245e-07,  4.3834e-08,\n",
       "             2.2203e-07, -8.9567e-07,  5.6797e-06,  2.3420e-07,  4.4866e-08,\n",
       "             3.4660e-07, -7.4159e-07,  4.6387e-07,  2.9344e-08,  4.1382e-07,\n",
       "             5.4945e-07, -9.0588e-07,  6.6647e-07, -2.6043e-07,  2.2957e-06,\n",
       "            -1.4076e-07, -3.2349e-08, -2.2959e-08, -1.4099e-08,  1.6808e-07,\n",
       "             1.5241e-06,  9.9974e-09,  6.4018e-08,  1.3665e-08, -1.0718e-08,\n",
       "             4.6821e-07, -1.5290e-07,  1.7495e-08,  1.9361e-07, -1.9822e-07,\n",
       "            -9.2384e-09,  1.8322e-07, -2.2754e-08, -1.8936e-07,  4.9223e-08,\n",
       "             1.8758e-07, -2.6405e-07, -2.5580e-07,  9.7245e-09,  7.0000e-07,\n",
       "             1.3084e-07, -1.9635e-07, -1.0457e-09, -2.3538e-07,  1.5308e-07,\n",
       "             9.6376e-08,  1.2346e-06,  1.0813e-07,  6.5512e-07, -2.6585e-07,\n",
       "            -1.1408e-06, -2.2780e-08, -3.0755e-07, -4.1456e-08,  1.2007e-08,\n",
       "            -1.2974e-07,  8.3211e-07, -2.9583e-07, -1.7139e-09,  1.4289e-07,\n",
       "            -2.1076e-07,  1.0985e-07,  1.8204e-09, -6.3210e-07, -6.7365e-08,\n",
       "             5.4701e-08, -4.4997e-07,  1.4575e-07,  2.5583e-14,  2.5069e-08,\n",
       "             1.4771e-07,  2.7085e-06,  1.3783e-06, -8.7772e-07, -1.7682e-07,\n",
       "            -8.0763e-08, -3.3554e-08,  7.2571e-08,  2.4852e-06, -2.3113e-09,\n",
       "             1.2891e-09, -1.0491e-10,  2.6804e-07,  4.5468e-07,  3.0245e-07,\n",
       "            -6.3644e-07,  9.9294e-08, -4.4365e-07, -7.3315e-07,  5.0451e-08,\n",
       "            -1.4519e-07, -1.6209e-07,  7.6808e-08, -4.9775e-07,  2.6124e-07,\n",
       "             1.2264e-08, -2.4117e-07, -9.0985e-07,  8.3503e-07,  8.2120e-07,\n",
       "             9.6784e-07,  3.5906e-07,  1.4518e-08, -5.2904e-08,  2.9842e-06,\n",
       "             1.4190e-08,  4.4676e-06,  5.4841e-07, -1.7840e-07,  6.4444e-07,\n",
       "             1.2995e-07, -1.0612e-09,  1.1025e-08]),\n",
       "    'exp_avg_sq': tensor([4.4793e-21, 8.7454e-12, 4.6625e-12, 6.5880e-13, 3.3710e-11, 9.1068e-13,\n",
       "            5.8842e-12, 1.1063e-12, 6.1991e-13, 9.5092e-12, 1.4071e-12, 2.4116e-12,\n",
       "            1.1702e-12, 6.2749e-11, 1.9993e-13, 9.4838e-13, 4.1978e-11, 3.9177e-10,\n",
       "            2.8225e-12, 6.5022e-13, 3.1836e-12, 3.7551e-11, 7.1586e-12, 1.6586e-12,\n",
       "            7.8408e-12, 2.9013e-12, 8.3116e-12, 6.9578e-13, 6.8427e-13, 9.8420e-11,\n",
       "            8.1560e-13, 4.9589e-12, 3.3201e-13, 1.4471e-13, 3.0975e-12, 3.8492e-11,\n",
       "            7.4491e-13, 2.2911e-12, 1.8198e-12, 1.9880e-12, 2.3841e-12, 1.3911e-12,\n",
       "            1.3674e-13, 2.4199e-12, 1.0366e-11, 1.1543e-12, 1.6386e-11, 5.9838e-13,\n",
       "            6.1307e-12, 8.2601e-12, 9.8231e-12, 3.6270e-12, 6.6016e-12, 4.1091e-12,\n",
       "            1.5033e-11, 2.0967e-12, 2.2370e-12, 4.6657e-13, 1.1920e-11, 1.2188e-12,\n",
       "            1.7772e-12, 2.6717e-11, 2.6884e-11, 2.2266e-11, 1.2687e-11, 1.0417e-11,\n",
       "            5.9565e-12, 3.2621e-12, 1.0652e-12, 2.9578e-13, 3.5135e-13, 1.0944e-11,\n",
       "            2.6550e-12, 1.2657e-13, 1.4606e-11, 1.4910e-12, 2.1198e-13, 7.4469e-13,\n",
       "            1.3642e-11, 1.6360e-12, 2.2028e-12, 1.7119e-11, 1.0964e-12, 8.7215e-27,\n",
       "            1.8763e-13, 7.2365e-12, 7.2444e-11, 2.8678e-11, 1.0067e-12, 1.5057e-12,\n",
       "            4.8449e-12, 4.6744e-12, 3.9976e-12, 7.6651e-11, 7.0158e-12, 7.0856e-14,\n",
       "            4.8804e-14, 1.3744e-11, 1.4781e-12, 1.8994e-12, 2.9272e-12, 3.4211e-12,\n",
       "            2.2073e-12, 5.0207e-12, 3.1494e-11, 7.5649e-13, 2.1811e-13, 3.3048e-12,\n",
       "            1.7188e-12, 9.0693e-13, 2.5861e-11, 7.1016e-12, 8.8884e-12, 1.7029e-10,\n",
       "            3.2724e-11, 2.7391e-12, 8.1976e-13, 2.2806e-13, 2.9364e-12, 1.2704e-11,\n",
       "            5.6855e-13, 5.5954e-11, 3.8857e-11, 3.0321e-12, 3.3128e-12, 3.3129e-12,\n",
       "            1.2632e-13, 1.4756e-13])},\n",
       "   140493485556992: {'step': 1528596,\n",
       "    'exp_avg': tensor([[-4.5117e-04, -5.7592e-04, -5.0160e-04, -5.0079e-04, -7.9550e-04,\n",
       "             -4.7487e-04, -5.1498e-04, -4.5971e-04, -3.9032e-04, -9.5886e-04,\n",
       "             -3.4458e-04, -3.3678e-04, -3.6531e-04, -1.3123e-04, -5.0430e-04,\n",
       "             -4.4290e-04,  1.6614e-04,  5.9958e-03, -4.7517e-04, -4.7197e-04,\n",
       "             -6.1417e-04, -5.8092e-04, -4.7511e-04, -4.1909e-04, -5.3806e-04,\n",
       "             -3.9887e-04,  3.9931e-04, -3.2061e-04, -2.3955e-04, -1.4659e-03,\n",
       "             -4.3467e-04, -4.4275e-04, -4.6762e-04, -4.3330e-04, -5.7268e-04,\n",
       "             -1.6836e-03, -5.2965e-04, -4.5740e-04, -4.4017e-04, -4.8762e-04,\n",
       "             -3.8947e-04, -5.2651e-04, -4.5019e-04, -2.9243e-04, -6.3160e-04,\n",
       "             -4.5014e-04, -3.9112e-04, -4.4985e-04, -2.5570e-04, -3.6508e-04,\n",
       "             -3.1644e-04, -3.6051e-04, -4.3054e-04, -4.5476e-04, -9.0473e-04,\n",
       "             -5.2070e-04, -5.9494e-04, -4.5113e-04, -3.6371e-04, -4.7649e-04,\n",
       "             -4.3112e-04,  3.8310e-04, -1.4454e-04, -4.2620e-04, -4.4172e-04,\n",
       "             -5.4905e-04, -7.5049e-04, -4.3707e-04, -4.4946e-04, -4.5280e-04,\n",
       "             -4.8830e-04, -2.9229e-04, -5.9580e-04, -4.5078e-04, -4.6120e-04,\n",
       "             -6.5202e-04, -4.5884e-04, -4.7269e-04, -7.9496e-04, -4.1836e-04,\n",
       "             -4.7896e-04, -7.0965e-04, -4.7843e-04, -4.5117e-04, -4.5233e-04,\n",
       "             -4.3416e-04,  9.3236e-04, -6.1366e-04,  4.8457e-05, -6.3360e-04,\n",
       "             -4.6689e-04, -3.5251e-04, -4.4792e-04, -2.6399e-03, -4.4314e-04,\n",
       "             -4.5128e-04, -4.5116e-04, -4.2480e-04, -4.9256e-04, -1.2715e-04,\n",
       "             -7.4110e-04, -3.8441e-04, -6.8761e-04,  9.7190e-05, -1.5529e-03,\n",
       "             -5.1115e-04, -6.5271e-04, -3.2726e-04, -6.8540e-04, -3.2810e-04,\n",
       "             -4.3916e-04, -7.3414e-04, -3.8923e-04,  1.3981e-03, -9.7048e-04,\n",
       "             -5.8618e-04, -6.3206e-04, -4.6456e-04, -4.4512e-04, -9.2098e-04,\n",
       "             -4.5259e-04, -1.6913e-03, -5.3700e-04, -5.4907e-04, -6.9599e-04,\n",
       "             -5.0308e-04, -4.5110e-04, -4.4808e-04]]),\n",
       "    'exp_avg_sq': tensor([[2.6694e-05, 2.7153e-05, 3.7088e-05, 2.6784e-05, 2.6459e-05, 2.6779e-05,\n",
       "             2.6660e-05, 2.6863e-05, 2.6674e-05, 2.6621e-05, 2.6455e-05, 2.6707e-05,\n",
       "             2.6776e-05, 1.6368e-05, 2.7077e-05, 2.6939e-05, 3.2356e-05, 2.7833e-04,\n",
       "             2.6757e-05, 2.6926e-05, 2.7439e-05, 3.3408e-05, 2.6862e-05, 2.6701e-05,\n",
       "             2.6764e-05, 2.6580e-05, 3.7989e-05, 2.6968e-05, 2.6844e-05, 3.8301e-05,\n",
       "             2.6768e-05, 2.6739e-05, 2.6875e-05, 2.7021e-05, 2.6512e-05, 3.1793e-05,\n",
       "             2.6907e-05, 2.6733e-05, 2.7068e-05, 2.6471e-05, 2.6894e-05, 2.6566e-05,\n",
       "             2.6678e-05, 2.7157e-05, 2.6958e-05, 2.6865e-05, 3.7470e-05, 2.6664e-05,\n",
       "             2.7428e-05, 2.6338e-05, 2.5736e-05, 2.6487e-05, 2.6587e-05, 2.6602e-05,\n",
       "             2.9416e-05, 2.6944e-05, 2.6625e-05, 2.6696e-05, 2.7193e-05, 2.6773e-05,\n",
       "             2.6795e-05, 9.1222e-06, 3.2474e-05, 2.6797e-05, 2.6698e-05, 2.6491e-05,\n",
       "             2.7971e-05, 2.6883e-05, 2.6739e-05, 2.6720e-05, 2.6726e-05, 2.0969e-05,\n",
       "             2.7050e-05, 2.6659e-05, 2.6491e-05, 2.7145e-05, 2.6707e-05, 2.7058e-05,\n",
       "             1.2920e-05, 2.6693e-05, 2.6688e-05, 1.0934e-05, 2.7671e-05, 2.6694e-05,\n",
       "             2.6665e-05, 2.6461e-05, 1.2727e-05, 2.7129e-05, 2.6845e-05, 2.6766e-05,\n",
       "             2.6791e-05, 2.6897e-05, 2.6662e-05, 6.7541e-05, 2.6710e-05, 2.6627e-05,\n",
       "             2.6737e-05, 2.7062e-05, 2.7134e-05, 2.9753e-05, 2.7194e-05, 2.6633e-05,\n",
       "             2.6752e-05, 3.1115e-05, 3.7581e-05, 2.7039e-05, 2.6750e-05, 2.6484e-05,\n",
       "             2.6506e-05, 2.6675e-05, 2.6931e-05, 2.6564e-05, 2.6875e-05, 1.3238e-04,\n",
       "             2.8084e-05, 2.6613e-05, 2.7805e-05, 2.6765e-05, 2.6740e-05, 2.6746e-05,\n",
       "             2.6704e-05, 2.7702e-05, 2.8106e-05, 2.7453e-05, 2.7076e-05, 2.6625e-05,\n",
       "             2.6792e-05, 2.6543e-05]])},\n",
       "   140493485556912: {'step': 1528596,\n",
       "    'exp_avg': tensor([0.0005]),\n",
       "    'exp_avg_sq': tensor([2.6694e-05])}},\n",
       "  'param_groups': [{'lr': 0.0003,\n",
       "    'betas': (0.9, 0.999),\n",
       "    'eps': 1e-08,\n",
       "    'weight_decay': 0,\n",
       "    'amsgrad': False,\n",
       "    'params': [140493485556192,\n",
       "     140493485556112,\n",
       "     140493485557072,\n",
       "     140493485556832,\n",
       "     140493485556992,\n",
       "     140493485556912]}]},\n",
       " 'actor_1': OrderedDict([('fc1.weight',\n",
       "               tensor([[-9.3496e-02,  3.0299e-01,  4.7631e-02,  ...,  1.3294e+00,\n",
       "                         7.1037e-03,  8.3835e-02],\n",
       "                       [-1.2011e-03, -1.4606e-03,  7.8925e-02,  ..., -5.9312e-01,\n",
       "                        -3.1928e-02, -7.3588e-02],\n",
       "                       [-8.9933e-02,  3.8401e-01,  8.6985e-03,  ..., -9.4861e-02,\n",
       "                         2.6126e-02, -1.0047e-01],\n",
       "                       ...,\n",
       "                       [ 9.6105e-02,  3.1997e-01, -5.7108e-02,  ..., -5.0797e-01,\n",
       "                         1.7850e-01, -5.7527e-01],\n",
       "                       [ 4.9266e-02,  4.0558e-02,  7.6466e-02,  ...,  2.9149e-01,\n",
       "                         1.0773e-01,  1.3764e-01],\n",
       "                       [-3.9270e-02, -8.2326e-02,  2.8007e-02,  ..., -7.2417e-01,\n",
       "                         4.8848e-02, -6.9996e-02]])),\n",
       "              ('fc1.bias',\n",
       "               tensor([-0.3284,  0.2090, -0.0141, -0.0321, -0.1009, -0.2017, -0.2790,  0.1369,\n",
       "                        0.1597, -0.1836,  0.1721, -0.4098, -0.1432, -0.1682,  0.2323, -0.2591,\n",
       "                       -0.1693,  0.0876, -0.1796, -0.0548, -0.0537, -0.1011, -0.0520,  0.3694,\n",
       "                       -0.3531, -0.0114,  0.0497,  0.0521,  0.0319, -0.4698,  0.0114, -0.4555,\n",
       "                        0.2873,  0.1939,  0.0931,  0.1422,  0.1787, -0.0827,  0.3059, -0.2308,\n",
       "                       -0.1375,  0.0074,  0.2708, -0.0479,  0.0152, -0.2590, -0.0714, -0.3848,\n",
       "                        0.1776,  0.0581, -0.0282, -0.4635,  0.1699, -0.3071,  0.0768, -0.1750,\n",
       "                       -0.1133, -0.3006, -0.0263, -0.5990, -0.2255,  0.1208, -0.4378, -0.1790,\n",
       "                        0.0641,  0.3023, -0.6303,  0.2324, -0.3040,  0.2708, -0.4780, -0.5067,\n",
       "                       -0.1538,  0.0397, -0.1721, -0.1515, -0.4708, -0.5741,  0.5658, -0.1809,\n",
       "                       -0.3486,  0.1464, -0.1534, -0.0355, -0.0534,  0.0398, -0.2944, -0.0581,\n",
       "                       -0.0613,  0.0262,  0.1761, -0.0774, -0.6490, -0.0943, -0.1714, -0.3222,\n",
       "                       -0.0265,  0.2168, -0.0220,  0.3552, -0.0115,  0.0569, -0.0012, -0.3944,\n",
       "                       -0.1654, -0.0120,  0.2059, -0.0723, -0.0744, -0.2554, -0.5201, -0.7446,\n",
       "                       -0.0543, -0.0846,  0.0382, -0.2146,  0.0622,  0.0140,  0.1110,  0.4921,\n",
       "                       -0.3385, -0.4471,  0.1024,  0.1352,  0.1884,  0.1710,  0.2516,  0.0478,\n",
       "                       -0.2603,  0.1782,  0.0666, -0.0124, -0.0420, -0.3092,  0.2197, -0.0369,\n",
       "                       -0.1215, -0.0129, -0.0212, -0.1900, -0.3358,  0.1066, -0.3299, -0.1171,\n",
       "                        0.1290, -0.2251, -0.3939,  0.0297, -0.0531,  0.1235, -0.1148, -0.1014,\n",
       "                       -0.2165,  0.2138, -0.0789,  0.3572, -0.0569,  0.3082, -0.3012, -0.1025,\n",
       "                       -0.0792, -0.0996, -0.1290, -0.5019, -0.3188, -0.2116, -0.2345,  0.5634,\n",
       "                       -0.0908, -0.3414,  0.2019,  0.2096,  0.0603, -0.0079,  0.2999,  0.6186,\n",
       "                       -0.3150,  0.1314, -0.2158, -0.2866, -0.2181, -0.0027, -0.1258, -0.3069,\n",
       "                        0.0064,  0.2337,  0.3656,  0.3289, -0.1988, -0.2532, -0.2392,  0.2874,\n",
       "                       -0.2271, -0.2130,  0.2157,  0.0710, -0.4178,  0.1359, -0.1315,  0.1640,\n",
       "                        0.2544, -0.4515,  0.0890,  0.0185, -0.4368,  0.2184, -0.1989, -0.2861,\n",
       "                        0.0530,  0.0375,  0.0299,  0.0824,  0.2421, -0.0687, -0.2925, -0.4339,\n",
       "                       -0.1087,  0.4223,  0.3263, -0.0414, -0.3629,  0.1712, -0.0625, -0.4148,\n",
       "                       -0.5435,  0.3345, -0.0119,  0.0497, -0.5691, -0.1829,  0.0841,  0.2282,\n",
       "                       -0.0584, -0.2124,  0.2269, -0.4332, -0.1047, -0.0738,  0.0572,  0.1626,\n",
       "                        0.1921, -0.0495,  0.1414, -0.0328,  0.0105, -0.1106, -0.1802,  0.1697,\n",
       "                       -0.1122, -0.3009,  0.2669,  0.0629, -0.0587, -0.3230,  0.5605, -0.3660,\n",
       "                        0.2661,  0.0732, -0.6031, -0.3287,  0.1556,  0.1702, -0.1591,  0.0863,\n",
       "                        0.1263])),\n",
       "              ('fc2.weight',\n",
       "               tensor([[ 0.2774,  0.1454, -0.0638,  ...,  0.0302, -0.0094, -0.0494],\n",
       "                       [-0.0135,  0.0489,  0.2487,  ...,  0.0468,  0.0578, -0.0917],\n",
       "                       [ 0.5416, -0.1453, -0.0219,  ...,  0.0127, -0.0794,  0.0268],\n",
       "                       ...,\n",
       "                       [ 0.0365, -0.1251, -0.2353,  ...,  0.0700, -0.1079,  0.0586],\n",
       "                       [-0.2415,  0.1149, -0.1233,  ..., -0.1000, -0.5142, -0.0065],\n",
       "                       [ 0.3775,  0.1005, -0.0262,  ..., -0.1088,  0.0019, -0.0651]])),\n",
       "              ('fc2.bias',\n",
       "               tensor([ 1.0927e-01, -2.3433e-01, -2.3634e-01, -1.6438e-01, -1.9948e-02,\n",
       "                       -1.5563e-01, -1.0325e-01,  1.3742e-01, -1.6464e-01,  1.2121e-01,\n",
       "                        1.2571e-01,  3.8287e-04,  3.9940e-02,  1.3432e-01,  1.1286e-01,\n",
       "                       -1.2994e-01, -3.5490e-02,  9.9287e-02, -7.0028e-02,  4.1922e-02,\n",
       "                       -9.5560e-02,  1.4091e-01,  1.5462e-01, -8.0928e-02,  1.2148e-01,\n",
       "                       -2.6433e-01, -3.9030e-02, -2.3930e-01,  6.3890e-04, -1.2459e-01,\n",
       "                       -1.2650e-01, -1.2263e-01, -3.8057e-02,  3.6250e-02,  4.2011e-02,\n",
       "                        1.2679e-01, -7.8907e-02, -2.4473e-01,  9.9555e-02, -3.0768e-01,\n",
       "                       -1.3785e-01, -6.0936e-02, -2.3340e-01,  7.0095e-02, -4.1291e-01,\n",
       "                        7.5958e-02, -8.4180e-02,  1.5001e-01, -1.5411e-02, -1.5960e-01,\n",
       "                        3.7970e-02, -1.1863e-01, -6.9211e-01,  5.1431e-03, -6.7448e-02,\n",
       "                       -2.0116e-01, -7.0332e-02,  1.1270e-02, -5.1399e-01,  1.2290e-01,\n",
       "                       -1.1011e-01, -4.0203e-02, -1.2503e-01,  1.4731e-01,  3.9777e-02,\n",
       "                       -1.6255e-01, -1.5373e-01, -3.0330e-02, -1.5763e-01, -2.5875e-03,\n",
       "                       -3.6088e-02, -4.3062e-02, -1.8349e-01,  1.7195e-01,  7.7004e-02,\n",
       "                        4.0228e-02,  1.5356e-01,  2.8480e-02, -2.2121e-01, -9.8650e-02,\n",
       "                        2.0612e-01, -2.2289e-01, -5.6252e-02,  3.4811e-02,  9.2687e-02,\n",
       "                       -7.8288e-02, -1.7810e-01,  8.7469e-03, -1.2072e-01,  5.5810e-02,\n",
       "                       -1.7368e-01,  3.2651e-02, -4.2807e-01, -7.8746e-02,  2.4163e-01,\n",
       "                       -1.7438e-01, -1.6948e-01, -5.8085e-02, -1.1638e-01, -2.4340e-02,\n",
       "                        5.7490e-02,  8.1748e-02, -3.7859e-01, -1.9939e-01,  4.4408e-02,\n",
       "                       -3.8583e-02, -1.2634e-01,  1.8602e-01, -1.1178e-01, -3.2647e-02,\n",
       "                        1.4430e-01, -3.9117e-01,  3.4102e-02,  1.1009e-01, -1.4747e-01,\n",
       "                       -1.1674e-01, -2.4396e-01,  5.5364e-02,  1.2680e-01,  4.9217e-02,\n",
       "                       -3.7082e-02, -1.4064e-01, -2.1873e-01, -2.2465e-01, -2.2202e-01,\n",
       "                       -1.3338e-01,  1.1021e-01,  2.7799e-02])),\n",
       "              ('fc3.weight',\n",
       "               tensor([[-0.1576, -0.2345,  0.1048, -0.2473, -0.0717,  0.0414, -0.4221,  0.4686,\n",
       "                        -0.0641, -1.2910,  0.1890,  0.3351,  0.1969,  0.1355,  0.0846,  0.9535,\n",
       "                        -0.0084,  0.0629, -0.0707, -0.0034,  0.3677,  0.1864,  0.5650,  0.4588,\n",
       "                         0.2806,  0.2532, -0.1397, -0.2842, -0.1251,  0.1753, -0.1512, -0.1675,\n",
       "                         0.0732,  0.3770,  0.2078,  0.1040, -0.3713, -0.9084,  0.2393, -0.5786,\n",
       "                         0.2025, -0.2957,  0.6272,  0.2505, -0.6901,  0.3269, -0.1289,  0.0883,\n",
       "                         0.0723, -0.0842,  0.0773, -0.0622, -0.6127, -0.1112, -0.0842, -0.1503,\n",
       "                        -0.4349,  0.1948,  0.5570,  0.2849, -0.0913, -0.5489, -0.4721,  0.0372,\n",
       "                         0.1141, -0.3728, -0.1223, -0.3454,  0.0305,  0.3088, -0.3704, -0.0950,\n",
       "                         0.1538, -0.0505, -0.9672,  0.0942,  0.0154,  0.1172,  0.4419,  0.1056,\n",
       "                         0.0913, -0.4407, -0.0959,  0.2438,  0.1597,  0.3119, -0.1459, -0.0890,\n",
       "                        -0.1644,  0.2477, -0.1033,  0.1541,  1.2268, -0.2268,  0.0514,  0.0096,\n",
       "                         0.7485, -0.0697, -0.4214,  0.3108,  0.2650, -0.0685, -0.2311, -0.2057,\n",
       "                        -0.1936,  0.4488, -0.1085, -0.0279, -0.1773,  0.0464,  0.2307, -0.5807,\n",
       "                         0.1323,  0.0496, -0.2293, -0.3392, -0.3313, -0.0181,  0.1770, -0.2804,\n",
       "                        -0.1793, -0.2530, -0.3195, -0.6312, -0.0544,  0.2611, -0.1818, -0.5067],\n",
       "                       [-0.3655,  0.0231,  0.4340,  0.6328, -0.3491,  0.4909, -0.0738, -0.0906,\n",
       "                         0.2867,  0.3784, -0.2570,  0.5954, -0.0495, -0.0705, -0.4976, -0.4236,\n",
       "                         0.4744, -0.0681,  1.2447,  0.5254,  0.3580, -0.5161, -0.2880, -0.4023,\n",
       "                         0.3659,  0.3464, -0.6487, -0.0363, -0.1837,  0.7870,  0.1604,  0.2295,\n",
       "                         0.5542, -0.1424, -0.2713, -2.3242, -0.7986, -0.0891, -0.2217,  0.7091,\n",
       "                         0.3423,  0.2427,  0.7509, -0.0986,  0.3297, -0.7215,  0.3223, -0.1253,\n",
       "                         0.3601, -0.8817, -0.9614,  0.7377,  1.6778, -0.2471,  0.0454,  0.4423,\n",
       "                        -1.0221,  0.7061,  0.5213,  0.2927,  0.4602,  0.2738,  0.0695, -0.3942,\n",
       "                        -0.2047,  0.4791, -0.2167, -0.4698,  0.5526,  0.4468, -0.3528,  0.3005,\n",
       "                         0.6273,  0.2649, -0.9347,  0.9637, -0.3508,  0.0148, -0.0225,  0.3293,\n",
       "                        -0.1713,  0.4849,  0.2589, -0.5379, -0.1686, -1.0196,  0.4155, -0.6279,\n",
       "                         0.0030, -0.0618,  0.0376,  0.3345,  0.2520, -0.5155, -0.3449,  0.5863,\n",
       "                         0.7140,  0.7763, -0.1038, -0.9858, -0.1207,  0.0635,  0.6470, -0.3179,\n",
       "                         1.2807,  0.8366,  0.1998, -0.3289,  0.1950,  0.6578, -0.6948, -0.3592,\n",
       "                        -0.0475, -0.5819,  0.3162,  0.1332,  0.2917, -0.2196, -0.0200, -0.1597,\n",
       "                        -0.4508, -0.6331, -0.1203, -0.6674,  0.4685,  0.1524, -0.5806,  0.5329]])),\n",
       "              ('fc3.bias', tensor([-0.0804, -0.1858]))]),\n",
       " 'critic_1': OrderedDict([('fcs1.weight',\n",
       "               tensor([[ 0.4641, -0.5379, -0.0771,  ..., -0.8129,  0.0507,  0.5135],\n",
       "                       [-0.3218,  0.6982, -0.0307,  ..., -1.0066,  0.0606, -0.1709],\n",
       "                       [-0.0458,  1.9655,  0.1377,  ..., -0.9681, -0.0080, -0.2938],\n",
       "                       ...,\n",
       "                       [-0.1475,  2.9141, -0.0711,  ..., -1.9098,  0.0902, -0.1692],\n",
       "                       [-0.1012,  1.8533, -0.1013,  ..., -0.1005, -0.3026, -0.4012],\n",
       "                       [ 0.5402, -0.7179, -0.1781,  ..., -0.1667,  0.0704, -0.1588]])),\n",
       "              ('fcs1.bias',\n",
       "               tensor([-1.2245e+00, -5.1902e-01,  1.1733e-01,  1.1968e+00,  2.6939e-01,\n",
       "                       -5.7849e-01, -2.7205e-01, -7.9863e-01, -2.0776e-03, -2.7267e-01,\n",
       "                       -4.4122e-01,  1.3783e-01,  5.5918e-01, -2.6089e-01, -6.4066e-01,\n",
       "                        1.2416e-01, -4.3067e-01,  1.9772e-01, -4.0916e-02,  4.6496e-01,\n",
       "                       -7.5442e-01, -4.3287e-01, -3.2873e-01,  6.4495e-01, -8.8668e-01,\n",
       "                        2.2639e-01, -8.9558e-01,  4.0995e-01,  2.5902e-01, -4.5572e-01,\n",
       "                       -1.0139e+00,  4.4459e-01, -1.0657e+00, -1.4266e+00,  2.6135e-01,\n",
       "                       -2.7837e-01, -8.4810e-02,  9.6651e-02, -7.2156e-01, -5.8397e-01,\n",
       "                       -2.3878e+00,  9.3494e-01, -1.8875e+00, -4.9005e-01, -1.0627e-01,\n",
       "                       -8.5984e-01, -2.0675e-01,  8.6148e-01, -2.7544e-01, -8.9039e-01,\n",
       "                        2.9921e-01, -5.4170e-01,  4.8419e-01,  5.6215e-02,  8.7709e-01,\n",
       "                        3.6118e-01, -3.2502e-01, -3.6782e-01,  7.2632e-01, -8.3583e-01,\n",
       "                       -1.1957e-01, -1.4867e+00, -1.5958e-01, -1.2537e+00,  7.1810e-02,\n",
       "                       -1.9497e+00, -1.2820e+00, -1.6251e+00,  7.2458e-01,  1.1397e+00,\n",
       "                       -8.7997e-01, -1.5963e+00, -4.9528e-01, -5.9023e-01, -3.5083e-01,\n",
       "                        5.8901e-01, -6.6104e-01, -8.5117e-01,  3.8535e-03, -1.4203e+00,\n",
       "                       -1.5768e+00, -4.9617e-01, -2.5077e-01,  7.6378e-02, -2.9640e-01,\n",
       "                       -1.0168e-01,  1.9583e+00,  8.3553e-01, -4.2957e-01,  2.6478e-01,\n",
       "                       -2.0859e-02, -4.5241e-01, -1.6138e+00,  2.3009e-01, -4.2748e-01,\n",
       "                        3.0495e-03, -4.7928e-01, -7.4729e-01, -6.3920e-02, -9.2021e-01,\n",
       "                       -1.6077e-01,  9.0923e-02,  2.3266e+00, -4.2022e-01, -7.1405e-02,\n",
       "                       -4.5739e-01, -5.0761e-01, -5.9106e-01, -9.6067e-01, -6.9013e-01,\n",
       "                       -1.7919e+00, -2.5892e-01,  6.4711e-01, -7.6654e-02, -3.9996e-01,\n",
       "                       -5.2106e-02, -7.0855e-01,  3.6302e-01, -6.9830e-01, -6.3636e-01,\n",
       "                       -5.8850e-01, -7.5798e-01, -2.8182e-01,  1.0022e+00, -1.7513e+00,\n",
       "                       -8.7714e-01, -2.0001e-01, -2.9764e-01, -2.8588e-03, -2.9256e+00,\n",
       "                        3.3627e-01, -7.6759e-01, -6.0879e-01,  4.5436e-01, -1.3590e-01,\n",
       "                        1.3935e+00, -2.8333e-01, -1.6819e+00,  5.0950e-01, -1.4798e+00,\n",
       "                       -2.8182e-01, -5.2695e-01,  6.3661e-02, -1.6977e+00, -5.5898e-01,\n",
       "                        1.3523e+00, -7.8298e-01, -3.5391e-01,  1.7496e+00, -4.0944e+00,\n",
       "                        3.4290e-01,  6.8254e-01, -8.8925e-01, -3.7061e-01, -4.2249e-01,\n",
       "                       -1.0519e+00,  1.4059e-01, -1.2002e-01, -6.3335e-01, -2.8957e+00,\n",
       "                       -8.5968e-01,  1.6568e-01, -8.1027e-01, -6.0771e-01, -6.4831e-01,\n",
       "                        1.2422e+00, -7.7789e-01,  4.5786e-02, -7.9021e-01,  1.3498e+00,\n",
       "                       -1.2826e+00, -6.7352e-01, -2.5803e-01, -4.9437e-01,  8.4798e-01,\n",
       "                       -4.3082e-01,  8.9083e-03,  3.8312e-01, -5.7323e-01,  5.7015e-01,\n",
       "                        1.5609e+00, -2.1648e-02, -5.3812e-01,  5.0032e-01, -1.1128e+00,\n",
       "                        6.8903e-01,  2.3268e-01,  1.9948e-01, -1.0806e+00, -5.4280e-01,\n",
       "                        5.4810e-01, -2.6075e+00, -4.5453e-01,  2.8885e-01,  6.7961e-02,\n",
       "                       -3.0270e-01,  8.4231e-01,  2.2973e-01, -1.4938e+00, -1.2421e+00,\n",
       "                       -9.2630e-01,  1.5849e+00, -5.9267e-01, -4.4915e-01, -4.0105e-01,\n",
       "                        1.4440e+00, -2.3938e-01,  9.2427e-01, -6.8595e-01, -2.1804e+00,\n",
       "                        4.9516e-01,  1.2934e+00,  1.6303e+00,  3.2955e-01,  1.2576e-01,\n",
       "                        1.3501e+00, -9.1221e-01,  2.4583e-01, -2.4298e-01, -1.9764e-01,\n",
       "                        7.4011e-01,  2.2546e-01,  2.7648e-01, -9.8715e-01,  8.4541e-01,\n",
       "                        9.3284e-01, -4.1052e-01,  1.0922e-01,  5.7511e-01,  1.6281e-01,\n",
       "                       -2.9675e+00, -2.6026e-01, -2.5248e-01, -7.4579e-02, -3.3834e-01,\n",
       "                       -4.9255e-02, -5.8400e-01, -9.6909e-02, -8.7340e-01, -1.6330e+00,\n",
       "                       -1.5557e-01, -3.7496e-01, -1.3505e+00, -4.5732e-01,  2.5426e-01,\n",
       "                       -7.4189e-01,  1.1761e+00, -7.1920e-01, -2.5320e-01,  1.7131e-01,\n",
       "                       -2.8037e-01,  6.9555e-01, -1.0855e-01,  4.6431e-02, -9.5209e-01,\n",
       "                       -4.4066e-01])),\n",
       "              ('fc2.weight',\n",
       "               tensor([[-0.0425, -0.3490, -0.0823,  ..., -0.2083, -5.3102,  0.5685],\n",
       "                       [-0.1919,  0.1761,  0.1863,  ...,  1.2489,  0.2155, -0.2761],\n",
       "                       [-0.1637, -0.3548,  0.1710,  ...,  0.0240,  0.9154, -0.1381],\n",
       "                       ...,\n",
       "                       [-0.3516,  0.1119,  0.3467,  ..., -0.9511,  2.4242,  0.2801],\n",
       "                       [-0.0073,  0.0076, -0.0680,  ..., -1.0166,  1.0147,  0.1600],\n",
       "                       [ 0.7300,  0.0684,  0.4232,  ...,  0.6261,  4.0337,  0.9097]])),\n",
       "              ('fc2.bias',\n",
       "               tensor([-0.0487,  0.3707, -0.7681, -0.8840, -0.5883, -0.4012, -0.4705, -0.2927,\n",
       "                       -0.5066, -0.2067, -0.4684, -0.2782, -0.7162, -0.2165, -0.6449, -0.1822,\n",
       "                       -0.3607, -0.7426, -0.5160, -1.0587, -0.1629, -0.4012, -0.4121,  1.0619,\n",
       "                       -0.0408, -0.3449, -0.5286, -0.5170, -0.3464, -0.7416, -0.2356, -0.5417,\n",
       "                       -0.3430, -0.5113, -0.3714, -0.2530, -0.2027, -0.7465, -0.4115, -0.1077,\n",
       "                       -0.1375, -0.1226, -0.6300, -0.5971, -0.5735, -0.2791, -0.6352, -0.5060,\n",
       "                       -0.9466, -0.4187,  0.3515, -0.5869, -1.9161, -0.5156, -0.7353, -0.4866,\n",
       "                       -0.3871, -0.3212, -0.2629, -0.3419,  0.0415, -0.9600, -0.5469, -0.5752,\n",
       "                       -0.4018, -0.5688, -0.4268, -0.5395,  0.5657, -0.8209, -0.4381, -0.3817,\n",
       "                       -0.4165, -0.5514, -0.5210, -2.3428, -0.9405, -0.4419, -0.5151, -0.4291,\n",
       "                       -0.2815,  0.1536, -0.4103, -1.3821, -0.1951, -0.6906, -0.4576, -0.6060,\n",
       "                       -1.7480, -0.5471, -0.3791, -0.3695, -0.4632, -1.3890, -0.2977, -0.5554,\n",
       "                       -0.2563, -0.3755, -0.1203, -0.6352, -1.0097, -0.5670, -0.4022, -0.7678,\n",
       "                       -0.8205, -0.2211, -0.9972, -0.3958, -0.6733, -1.5546, -1.8257, -0.4166,\n",
       "                       -0.4178, -0.6638, -0.5820, -0.3162, -0.4181, -0.4055, -0.5566, -0.2366,\n",
       "                       -0.6973, -0.2827, -0.9281, -0.8329, -0.4528, -0.3701, -0.2154, -0.6546])),\n",
       "              ('fc3.weight',\n",
       "               tensor([[-0.0284, -0.0103,  0.0107,  0.0048, -0.0110,  0.0087, -0.0124,  0.0078,\n",
       "                         0.0173, -0.0164,  0.0119,  0.0054,  0.0033,  0.0060,  0.0145,  0.0193,\n",
       "                         0.0084, -0.0082, -0.0114,  0.0057, -0.0231,  0.0064,  0.0081, -0.0170,\n",
       "                        -0.0188,  0.0073, -0.0114,  0.0078, -0.0401,  0.0086, -0.0165,  0.0107,\n",
       "                        -0.0392,  0.0132, -0.0122, -0.0205,  0.0099, -0.0137,  0.0108, -0.0224,\n",
       "                        -0.0163,  0.0062, -0.0169,  0.0398,  0.0040,  0.0057,  0.0096,  0.0081,\n",
       "                        -0.0083,  0.0100, -0.0125,  0.0166, -0.0150, -0.0084, -0.0256, -0.0328,\n",
       "                         0.0082,  0.0139,  0.0224,  0.0095, -0.0194,  0.0107, -0.0160, -0.0170,\n",
       "                         0.0191, -0.0106, -0.0210, -0.0191, -0.0128,  0.0208,  0.0078,  0.0049,\n",
       "                        -0.0175,  0.0129,  0.0043,  0.0037,  0.0115, -0.0188,  0.0058, -0.0152,\n",
       "                        -0.0196, -0.0163, -0.0125, -0.0102,  0.0062,  0.0067,  0.0051, -0.0112,\n",
       "                         0.0092,  0.0033,  0.0128,  0.0075,  0.0102, -0.0110,  0.0085,  0.0138,\n",
       "                        -0.0237,  0.0071, -0.0168,  0.0102, -0.0248, -0.0137,  0.0050, -0.0141,\n",
       "                         0.0152, -0.0112,  0.0070, -0.0183, -0.0106, -0.0211, -0.0168,  0.0133,\n",
       "                         0.0081, -0.0047, -0.0102,  0.0091, -0.0288, -0.0116,  0.0077,  0.0120,\n",
       "                         0.0097,  0.0069, -0.0129,  0.0099, -0.0165,  0.0115,  0.0063, -0.0150]])),\n",
       "              ('fc3.bias', tensor([-0.0795]))]),\n",
       " 'actor_opt_1': {'state': {140493485557872: {'step': 1528596,\n",
       "    'exp_avg': tensor([[ 8.1206e-07,  5.1955e-06,  7.6487e-06,  ...,  1.3979e-05,\n",
       "             -5.1049e-05, -1.8945e-05],\n",
       "            [-5.6830e-05, -4.9582e-07,  2.3416e-05,  ...,  1.1975e-05,\n",
       "              2.2938e-06, -5.3201e-06],\n",
       "            [-7.9761e-06, -9.3450e-07, -6.1429e-06,  ...,  3.9464e-06,\n",
       "             -1.1709e-05, -9.6804e-07],\n",
       "            ...,\n",
       "            [-7.5149e-06, -3.2091e-07,  7.3719e-06,  ...,  4.6089e-07,\n",
       "             -3.6806e-06, -1.9215e-06],\n",
       "            [-1.1932e-05, -5.2629e-06, -2.1195e-05,  ...,  3.9043e-06,\n",
       "              2.6977e-06,  6.5880e-06],\n",
       "            [-1.1081e-04,  5.2074e-06,  4.3238e-05,  ...,  2.5481e-05,\n",
       "              1.7265e-04, -4.3074e-06]]),\n",
       "    'exp_avg_sq': tensor([[1.2682e-07, 1.1975e-09, 2.3558e-08,  ..., 1.1577e-08, 6.1883e-08,\n",
       "             1.4080e-08],\n",
       "            [1.0549e-07, 1.5753e-09, 1.2808e-08,  ..., 8.8726e-09, 1.4761e-07,\n",
       "             6.6105e-09],\n",
       "            [5.9834e-08, 2.8853e-10, 9.4538e-09,  ..., 3.4717e-09, 9.4847e-08,\n",
       "             6.2510e-09],\n",
       "            ...,\n",
       "            [9.2424e-09, 6.2584e-11, 1.2157e-09,  ..., 3.2630e-10, 1.5372e-08,\n",
       "             1.0763e-09],\n",
       "            [6.1343e-08, 5.3665e-10, 5.9084e-09,  ..., 7.7625e-09, 5.9688e-08,\n",
       "             3.2971e-09],\n",
       "            [4.1869e-07, 5.3999e-09, 3.5108e-08,  ..., 5.0574e-08, 2.5925e-07,\n",
       "             2.0176e-08]])},\n",
       "   140493485558272: {'step': 1528596,\n",
       "    'exp_avg': tensor([-3.6700e-08,  5.4888e-06,  1.1358e-06, -3.4765e-07,  6.1395e-07,\n",
       "            -7.3530e-06, -1.6664e-06,  3.9342e-06, -6.4955e-06, -3.3308e-06,\n",
       "            -3.6892e-07,  4.1756e-07,  1.0940e-06,  2.5210e-08, -1.2463e-06,\n",
       "            -1.0873e-06,  3.4388e-06,  3.0582e-07,  5.5364e-07, -3.4526e-06,\n",
       "            -1.4846e-06, -2.6215e-07, -4.6519e-06,  7.2886e-06, -2.0530e-06,\n",
       "             1.0160e-06, -5.0700e-06,  4.0148e-07,  1.2208e-06, -5.7346e-07,\n",
       "            -5.8576e-06, -4.3075e-06,  2.5296e-06,  5.3472e-07, -2.0081e-06,\n",
       "             5.0362e-07, -3.7595e-06, -4.7630e-06, -2.6232e-07, -5.7399e-07,\n",
       "             3.5652e-06,  4.8235e-06, -4.4001e-06,  9.2257e-07,  1.4683e-06,\n",
       "            -1.0658e-06,  3.1831e-06, -1.2843e-06,  3.8920e-06, -4.8497e-07,\n",
       "            -2.1263e-06,  6.0441e-07, -1.5741e-06, -2.5379e-07,  4.4303e-07,\n",
       "            -1.9230e-08,  7.7736e-07, -1.0608e-06, -2.8917e-07, -2.6067e-06,\n",
       "             3.7426e-07, -2.9091e-06, -1.1582e-06,  5.5904e-07,  8.6092e-07,\n",
       "             3.4433e-06,  2.2787e-06,  1.4280e-06, -5.1215e-06, -2.0021e-06,\n",
       "            -9.2393e-07,  1.1897e-06, -7.2460e-07, -5.8108e-07,  1.0937e-06,\n",
       "             1.9012e-06, -1.7508e-05,  7.6320e-07,  1.3945e-05, -1.4462e-07,\n",
       "             4.1604e-07,  1.9472e-06,  4.3431e-08,  8.9452e-07, -3.6990e-07,\n",
       "            -2.4569e-06, -1.2071e-06,  3.7489e-07, -2.8570e-07,  5.9023e-06,\n",
       "             2.8819e-06, -5.4397e-07, -3.3210e-06,  8.7960e-06, -6.9331e-07,\n",
       "             1.7800e-06, -6.0488e-07,  3.8980e-06,  2.1685e-06,  1.0581e-06,\n",
       "            -8.3823e-07, -2.8971e-06,  6.9576e-06, -7.1832e-06, -4.5373e-06,\n",
       "             1.3249e-06,  1.8397e-06,  1.6671e-06, -2.7873e-07, -1.6382e-06,\n",
       "             1.2380e-05,  2.5898e-07, -3.1210e-07,  1.1462e-06, -2.1080e-07,\n",
       "            -1.4698e-06, -3.7134e-06,  1.8775e-06,  1.8700e-06,  1.6588e-07,\n",
       "            -8.1745e-06,  3.0943e-07,  6.4518e-06,  3.3369e-07,  2.7147e-07,\n",
       "             6.9661e-07,  4.9989e-06,  2.1951e-06,  2.1199e-06, -1.4011e-06,\n",
       "            -1.4244e-06, -6.8446e-08,  1.0898e-06,  2.8593e-06, -1.0308e-06,\n",
       "            -1.7298e-06, -2.9183e-06, -7.0457e-07, -1.8973e-06,  2.2312e-06,\n",
       "             3.4758e-06,  1.1977e-06, -1.3228e-06, -4.3204e-07,  3.8423e-07,\n",
       "            -3.1467e-06, -3.0639e-06, -5.3594e-06,  5.9129e-06,  3.9672e-06,\n",
       "            -1.2123e-05,  2.9761e-07, -8.6052e-07, -2.1163e-06,  4.1289e-07,\n",
       "             4.1864e-06, -1.8113e-06,  1.7403e-06, -2.4266e-06, -4.2036e-07,\n",
       "             5.6480e-07, -9.6902e-06, -1.0781e-05, -2.8965e-06, -5.4891e-07,\n",
       "             4.8173e-07,  2.0135e-06,  8.5809e-07,  4.2175e-06, -1.4652e-06,\n",
       "            -2.2868e-06,  1.6390e-06,  1.5044e-06, -1.4334e-06, -2.1194e-06,\n",
       "            -1.0996e-07,  1.3048e-06,  6.2176e-06, -5.9852e-07, -1.8109e-07,\n",
       "             1.6058e-06, -4.7041e-06, -1.4422e-07, -2.0237e-06, -1.1615e-06,\n",
       "             7.2182e-07,  1.9161e-06,  4.9965e-07, -2.7160e-06, -7.7077e-07,\n",
       "            -4.0393e-07, -4.0259e-07,  3.6645e-07,  7.2687e-07, -4.0613e-07,\n",
       "            -3.6172e-07, -3.6719e-07,  2.7369e-06, -2.1934e-06,  1.9145e-06,\n",
       "             3.8739e-07, -6.6685e-07,  6.2564e-07,  2.1818e-06, -1.1187e-06,\n",
       "             1.1064e-06,  1.2059e-06,  9.1319e-07,  2.3315e-06, -1.2267e-07,\n",
       "             5.7553e-07, -1.8568e-06,  6.9322e-07,  6.3218e-07, -2.3208e-06,\n",
       "            -1.0432e-06,  1.4534e-06,  1.1468e-06,  8.5950e-06,  2.1789e-06,\n",
       "             1.8486e-06, -2.7751e-06, -8.2125e-07, -2.3834e-07,  1.5006e-06,\n",
       "             7.3327e-06,  3.6973e-07, -4.3728e-06,  7.6458e-07, -7.4657e-07,\n",
       "             1.4166e-06,  4.2144e-06, -2.0813e-07, -1.3323e-05, -2.5623e-06,\n",
       "            -1.7260e-06, -3.3569e-06,  2.1011e-06, -1.9891e-06,  9.2538e-07,\n",
       "            -3.5248e-07, -2.8626e-07, -7.1848e-09,  4.2300e-07, -2.6306e-06,\n",
       "             4.1437e-06, -2.8438e-06,  8.6231e-07,  3.8291e-08,  2.2030e-06,\n",
       "             6.4076e-06,  6.4138e-06, -2.2652e-07,  8.8744e-07,  4.3094e-06,\n",
       "             4.4413e-07,  6.0372e-06,  6.9190e-07, -1.6888e-06,  5.3378e-07,\n",
       "             2.8546e-06,  5.5326e-06,  7.1555e-07,  1.2042e-06,  1.0896e-05]),\n",
       "    'exp_avg_sq': tensor([1.1006e-09, 9.1015e-10, 5.1591e-10, 1.9899e-10, 3.1047e-10, 5.2534e-10,\n",
       "            8.0885e-10, 7.8912e-10, 5.0613e-10, 4.5514e-10, 3.2324e-11, 6.0325e-10,\n",
       "            7.6923e-11, 1.0960e-11, 4.8168e-10, 1.4065e-10, 1.0182e-09, 3.8893e-10,\n",
       "            1.3136e-10, 2.3180e-10, 1.0127e-10, 6.7558e-12, 2.9540e-09, 8.4171e-10,\n",
       "            4.1108e-10, 6.0401e-11, 4.7978e-10, 1.4007e-10, 6.1710e-11, 6.9023e-11,\n",
       "            5.8500e-10, 3.9056e-10, 3.4639e-10, 9.2281e-10, 6.3206e-10, 2.5938e-10,\n",
       "            3.3850e-10, 1.8326e-10, 1.9497e-10, 6.1917e-10, 1.4988e-10, 6.3460e-10,\n",
       "            7.0498e-10, 1.5580e-10, 5.2527e-10, 1.9114e-10, 3.9816e-10, 6.0243e-11,\n",
       "            1.3647e-09, 3.0299e-11, 3.4315e-10, 5.9655e-10, 9.1857e-11, 1.2956e-10,\n",
       "            4.2113e-11, 2.7433e-10, 3.5117e-10, 4.3692e-11, 4.0024e-10, 2.0333e-10,\n",
       "            3.3961e-10, 1.2838e-10, 1.5985e-10, 6.9877e-11, 4.8317e-11, 1.2452e-10,\n",
       "            5.8299e-10, 5.5319e-11, 1.6831e-09, 7.9450e-10, 3.3737e-11, 1.2040e-10,\n",
       "            2.1571e-10, 1.0691e-10, 3.1498e-10, 1.8717e-10, 2.8622e-09, 5.8580e-10,\n",
       "            4.6805e-09, 6.5662e-10, 1.1733e-10, 4.1636e-10, 1.4884e-10, 1.1293e-10,\n",
       "            2.3341e-10, 4.7591e-10, 5.0053e-10, 5.9615e-10, 1.0034e-10, 6.0604e-10,\n",
       "            6.0367e-10, 2.8211e-10, 2.4856e-10, 2.6436e-10, 1.3086e-11, 1.2343e-09,\n",
       "            4.3711e-10, 5.3596e-10, 2.1493e-10, 9.9119e-10, 2.4961e-10, 3.5556e-10,\n",
       "            8.7248e-10, 2.3957e-09, 2.8531e-10, 1.0925e-10, 6.8018e-10, 2.5967e-10,\n",
       "            1.7510e-10, 1.8344e-10, 2.6462e-09, 5.7448e-10, 3.5665e-10, 3.6702e-10,\n",
       "            6.2089e-10, 4.4420e-10, 2.5197e-10, 8.3085e-10, 1.5616e-10, 3.0726e-10,\n",
       "            2.9989e-10, 3.1430e-11, 7.2408e-10, 7.2360e-11, 1.3032e-10, 3.8132e-10,\n",
       "            4.8585e-10, 9.2144e-10, 4.0892e-10, 1.6560e-10, 1.1908e-10, 3.6684e-10,\n",
       "            5.9756e-10, 2.5148e-09, 5.8397e-11, 2.1641e-10, 5.8704e-11, 5.2447e-10,\n",
       "            2.8383e-10, 4.2572e-11, 3.3215e-10, 1.7052e-10, 1.4140e-10, 1.1346e-11,\n",
       "            8.8934e-11, 1.9775e-09, 2.1840e-10, 8.3512e-10, 5.5156e-10, 2.8608e-10,\n",
       "            5.5202e-10, 6.9341e-11, 4.5643e-10, 4.4731e-10, 3.9473e-11, 5.9824e-10,\n",
       "            1.1798e-10, 8.9734e-10, 1.7556e-10, 3.4600e-10, 4.3809e-10, 8.8686e-10,\n",
       "            7.3168e-10, 2.2967e-10, 2.5010e-11, 1.5605e-09, 1.8377e-10, 7.7725e-10,\n",
       "            7.9404e-10, 3.0999e-10, 2.6018e-11, 1.5407e-10, 2.9402e-10, 3.2267e-10,\n",
       "            5.7210e-10, 1.1865e-10, 1.0721e-10, 4.8303e-10, 1.3772e-11, 5.1960e-11,\n",
       "            2.7392e-10, 1.8931e-10, 1.9003e-11, 1.1938e-10, 1.3267e-10, 1.1099e-09,\n",
       "            2.6561e-10, 1.6638e-10, 2.2124e-10, 4.3276e-11, 3.8206e-11, 5.1824e-10,\n",
       "            4.3791e-10, 6.3672e-10, 4.2703e-11, 1.0060e-11, 1.1041e-11, 3.4945e-10,\n",
       "            1.4772e-10, 2.6390e-10, 5.5014e-10, 2.6292e-10, 1.2888e-10, 6.8765e-11,\n",
       "            5.0338e-10, 4.8803e-11, 7.9075e-10, 3.2846e-09, 5.5944e-11, 4.4193e-11,\n",
       "            7.0229e-10, 2.7067e-10, 1.0214e-09, 5.9694e-11, 8.4095e-11, 2.5710e-10,\n",
       "            3.4777e-10, 1.7401e-10, 3.2561e-10, 1.2905e-10, 5.5415e-11, 2.2761e-10,\n",
       "            7.0542e-11, 3.0947e-11, 1.9905e-11, 2.0316e-09, 1.4308e-10, 2.0495e-10,\n",
       "            3.8611e-11, 2.7767e-10, 1.4944e-10, 6.0882e-10, 2.1960e-11, 3.3085e-09,\n",
       "            4.5441e-10, 3.1862e-10, 5.4067e-10, 1.3868e-10, 6.4470e-11, 3.8695e-11,\n",
       "            1.6986e-10, 3.6078e-11, 1.4163e-10, 8.3062e-10, 1.0617e-10, 4.0329e-10,\n",
       "            5.0671e-10, 7.7903e-09, 2.1126e-10, 1.1865e-10, 9.2661e-10, 7.0486e-10,\n",
       "            1.6465e-11, 3.2641e-10, 5.3952e-10, 9.1547e-12, 1.1679e-09, 2.7587e-10,\n",
       "            4.8550e-11, 3.6957e-10, 2.8965e-10, 5.5146e-10, 7.9292e-11, 5.2772e-10,\n",
       "            3.6237e-09])},\n",
       "   140493485558192: {'step': 1528596,\n",
       "    'exp_avg': tensor([[-5.2333e-07, -3.2945e-06,  1.0742e-05,  ...,  6.6660e-06,\n",
       "             -3.6353e-06, -9.6262e-06],\n",
       "            [ 1.0996e-06,  1.6728e-06,  2.6610e-06,  ...,  4.2854e-07,\n",
       "              6.6328e-07, -3.8608e-07],\n",
       "            [ 1.7438e-06, -1.6252e-06, -4.4315e-07,  ...,  1.9626e-06,\n",
       "              1.3575e-06, -9.3170e-06],\n",
       "            ...,\n",
       "            [-3.6197e-07, -5.3647e-07, -1.2282e-06,  ...,  2.5502e-07,\n",
       "              4.5722e-07,  6.2180e-07],\n",
       "            [-1.3104e-07,  4.5610e-06,  4.3288e-06,  ...,  2.8224e-06,\n",
       "              7.8250e-08,  1.0046e-07],\n",
       "            [ 3.7538e-06, -2.1495e-06,  4.1041e-06,  ..., -7.4463e-07,\n",
       "             -3.1995e-06, -5.7147e-06]]),\n",
       "    'exp_avg_sq': tensor([[1.6440e-10, 2.0918e-09, 1.9414e-09,  ..., 1.4725e-09, 7.6652e-10,\n",
       "             2.2767e-09],\n",
       "            [5.3408e-11, 1.6446e-09, 1.1243e-08,  ..., 5.2447e-09, 1.2475e-09,\n",
       "             2.8683e-10],\n",
       "            [2.6342e-10, 8.3372e-10, 7.5549e-10,  ..., 1.1293e-09, 9.0223e-10,\n",
       "             4.7320e-09],\n",
       "            ...,\n",
       "            [9.6263e-12, 4.8445e-11, 8.2376e-10,  ..., 1.8459e-09, 5.8235e-10,\n",
       "             5.6599e-11],\n",
       "            [4.0196e-11, 1.3288e-09, 4.1744e-09,  ..., 1.9835e-09, 2.3240e-10,\n",
       "             1.1365e-09],\n",
       "            [1.3889e-09, 6.6454e-09, 3.5762e-09,  ..., 4.3391e-09, 7.0862e-09,\n",
       "             3.1449e-08]])},\n",
       "   140493485559072: {'step': 1528596,\n",
       "    'exp_avg': tensor([ 1.9241e-07,  3.8378e-07, -1.1518e-06, -9.7241e-07, -2.8891e-07,\n",
       "             4.3368e-06,  6.5502e-08, -2.3224e-06, -5.6550e-07, -7.9140e-07,\n",
       "             1.5978e-06,  3.7808e-06,  4.5538e-07,  2.0869e-06,  9.0162e-07,\n",
       "            -3.9462e-06,  8.8248e-07,  1.3379e-06,  2.8729e-06,  1.6082e-06,\n",
       "             5.0650e-07, -2.6262e-06, -1.3188e-06,  3.9220e-08,  2.6615e-07,\n",
       "            -7.0128e-07,  4.8896e-07,  1.1767e-06, -7.9648e-07, -1.2880e-07,\n",
       "            -2.4792e-06,  1.2445e-07,  6.8663e-07, -5.6749e-07, -9.7456e-07,\n",
       "            -7.4974e-06,  5.2534e-07,  1.0989e-06,  1.0498e-06, -1.9820e-06,\n",
       "            -9.7721e-07,  6.6903e-07,  3.4467e-06,  3.2863e-06,  2.1363e-06,\n",
       "            -6.7752e-07,  1.3787e-06,  6.0100e-07,  8.5864e-07, -1.3279e-07,\n",
       "            -1.1142e-06, -1.7258e-07,  5.2323e-06, -6.3600e-07, -1.6064e-06,\n",
       "             2.9363e-07, -1.6206e-06,  1.4936e-06, -1.2138e-06,  3.3330e-07,\n",
       "             1.0888e-07, -2.8223e-06,  1.7771e-06, -1.5823e-06,  1.0088e-06,\n",
       "            -1.2860e-06, -1.7572e-06, -8.1313e-07, -1.3560e-07,  7.2268e-07,\n",
       "             1.6576e-07,  6.8698e-08, -8.2165e-07,  2.2788e-07,  4.9171e-07,\n",
       "             4.4304e-06, -8.6869e-07,  3.9432e-07, -2.0052e-06, -6.7841e-07,\n",
       "             1.3278e-06, -3.2718e-06, -1.3990e-06, -1.3601e-06, -1.0223e-06,\n",
       "            -2.2690e-06, -1.1203e-06,  5.6708e-07, -4.1314e-07,  4.5635e-06,\n",
       "             2.3221e-07,  3.8575e-07, -1.1454e-05, -5.1621e-07, -1.3032e-06,\n",
       "             3.5058e-07, -4.6360e-08,  1.9152e-06,  6.5155e-09,  4.6315e-07,\n",
       "             3.9182e-07, -1.3208e-06,  1.4656e-06, -2.6699e-06, -3.7156e-07,\n",
       "             7.2206e-07, -4.0014e-07, -1.1317e-06,  3.0228e-07,  1.8051e-06,\n",
       "             1.4309e-07,  3.8286e-07,  1.2758e-07, -8.8695e-07, -5.9755e-07,\n",
       "            -3.2949e-06,  1.9658e-06, -1.6517e-06,  5.6419e-06, -7.1912e-06,\n",
       "            -2.8893e-06, -4.5704e-06,  1.6755e-06,  2.7355e-06, -4.6730e-07,\n",
       "            -2.8592e-07,  9.7591e-07,  5.8219e-07]),\n",
       "    'exp_avg_sq': tensor([1.2784e-10, 2.8422e-10, 1.0356e-10, 2.1305e-11, 5.7885e-11, 1.1457e-10,\n",
       "            7.6433e-11, 1.3418e-10, 2.9362e-11, 9.7887e-10, 3.5265e-10, 7.1979e-10,\n",
       "            1.2439e-10, 1.4413e-10, 8.2880e-11, 3.4342e-10, 7.2914e-11, 5.8594e-11,\n",
       "            5.0813e-10, 9.2814e-11, 3.0241e-10, 9.1360e-11, 7.6527e-10, 1.4482e-11,\n",
       "            4.9343e-11, 3.0191e-11, 1.2799e-10, 1.4661e-10, 8.4709e-11, 1.2339e-10,\n",
       "            4.2985e-10, 2.9062e-10, 9.1890e-11, 4.8602e-11, 1.2075e-10, 1.1202e-09,\n",
       "            5.6257e-11, 6.8455e-11, 3.7930e-10, 1.9380e-11, 6.2251e-11, 3.8612e-10,\n",
       "            2.3670e-10, 8.6325e-10, 1.8931e-10, 2.1027e-10, 1.4301e-10, 1.2600e-10,\n",
       "            6.2725e-11, 3.6447e-11, 3.9113e-10, 2.7113e-10, 3.0928e-10, 1.1927e-10,\n",
       "            1.3483e-10, 3.4689e-11, 5.4739e-10, 1.5148e-10, 1.8722e-10, 9.2460e-11,\n",
       "            4.9868e-11, 4.3004e-10, 4.2079e-10, 7.1268e-11, 1.1785e-10, 3.2540e-10,\n",
       "            7.4828e-11, 3.0094e-10, 6.8188e-12, 1.8874e-10, 6.9747e-11, 1.7476e-10,\n",
       "            2.6052e-10, 1.0533e-10, 2.5307e-11, 1.8051e-10, 5.2157e-11, 1.9402e-10,\n",
       "            9.1524e-11, 1.8349e-11, 1.6420e-10, 4.0772e-10, 1.8334e-10, 3.1736e-10,\n",
       "            1.4781e-10, 4.4718e-10, 2.9387e-10, 2.4753e-11, 5.0312e-11, 2.2873e-10,\n",
       "            8.0272e-11, 5.6278e-11, 3.6967e-10, 1.1464e-10, 5.6797e-11, 1.7104e-10,\n",
       "            5.8951e-10, 8.7316e-11, 4.9199e-11, 3.6389e-10, 6.3189e-10, 9.7659e-11,\n",
       "            1.9077e-11, 3.7208e-10, 1.8501e-10, 1.6225e-10, 5.2819e-11, 4.0725e-11,\n",
       "            1.9324e-10, 8.2062e-12, 5.0229e-11, 9.7375e-11, 1.5975e-10, 9.2620e-11,\n",
       "            2.0530e-10, 5.2443e-10, 2.0863e-10, 2.0867e-11, 2.9755e-10, 5.4751e-10,\n",
       "            1.5639e-10, 8.2756e-10, 5.2950e-10, 1.4414e-10, 5.2526e-11, 1.3839e-11,\n",
       "            1.3682e-10, 6.1200e-10])},\n",
       "   140493485558992: {'step': 1528596,\n",
       "    'exp_avg': tensor([[-1.5733e-05,  6.9736e-06, -1.3219e-04, -1.5108e-07, -1.1707e-04,\n",
       "              3.9351e-05, -2.2336e-05, -7.7475e-05,  1.0701e-04, -3.1946e-05,\n",
       "             -5.1256e-05,  8.0256e-05, -2.8462e-05,  1.5177e-04,  1.8741e-05,\n",
       "             -5.4171e-05, -1.1661e-04,  2.0555e-04,  1.2280e-04,  1.6210e-04,\n",
       "             -5.4409e-05, -4.9437e-05, -4.1643e-05, -2.2225e-05,  3.7313e-05,\n",
       "             -5.3107e-05, -1.3052e-04, -1.7077e-04, -2.3671e-05,  2.3178e-05,\n",
       "              3.4031e-05,  3.4284e-05, -2.0518e-05, -2.5535e-05, -7.1477e-05,\n",
       "              5.0065e-07, -3.3950e-05, -2.4830e-05,  1.7390e-05, -8.2750e-07,\n",
       "              5.2293e-06, -3.1903e-05, -1.0857e-05,  7.1382e-05, -4.3391e-05,\n",
       "              5.8149e-05, -8.7694e-05,  2.0228e-04, -7.4264e-05, -1.8914e-05,\n",
       "              2.4070e-04,  1.2371e-04, -7.5367e-05,  8.7704e-05,  1.5427e-04,\n",
       "              5.8953e-06,  1.8010e-05, -1.0541e-05, -9.1392e-05, -3.6165e-05,\n",
       "             -7.4943e-05, -9.6199e-06, -1.2469e-04, -2.1769e-04,  9.9898e-05,\n",
       "              5.7175e-07,  9.3078e-05,  1.9542e-05, -3.7039e-05, -1.8171e-05,\n",
       "             -2.2016e-05, -6.3257e-05, -1.1639e-04,  9.5630e-05, -2.1692e-05,\n",
       "              1.6908e-05,  2.4240e-05, -1.2324e-04, -4.7373e-05, -9.9791e-05,\n",
       "              1.0711e-04,  1.8679e-05,  2.2832e-04, -4.9757e-05, -8.0013e-05,\n",
       "             -1.2202e-04,  1.7584e-04, -1.8318e-05, -9.4433e-05,  4.6894e-05,\n",
       "             -5.2820e-05, -2.4246e-05, -6.2074e-05, -1.4371e-05,  6.8273e-05,\n",
       "             -4.7377e-05, -2.5781e-05, -7.6919e-05,  1.2849e-05, -4.9349e-07,\n",
       "              3.6203e-07,  2.7024e-04, -4.1253e-05,  3.5712e-05, -1.5295e-05,\n",
       "             -2.6432e-05,  4.1693e-05, -4.8105e-05, -1.7261e-04,  3.0996e-05,\n",
       "             -3.7900e-06, -3.3049e-05, -3.8457e-05,  9.7340e-05, -2.9703e-05,\n",
       "              3.7323e-05, -5.0137e-05,  5.1325e-05,  1.5631e-04,  9.3668e-05,\n",
       "             -1.2687e-04,  9.6365e-05, -1.1420e-04, -4.0630e-05,  1.1330e-05,\n",
       "             -2.9062e-05,  5.2181e-05, -2.7658e-05],\n",
       "            [ 1.1691e-05, -2.0562e-05,  2.8679e-05, -2.5672e-06,  4.0569e-06,\n",
       "              5.9784e-05, -8.2162e-06, -5.8148e-06,  2.6331e-06,  5.8689e-08,\n",
       "              3.5536e-05,  6.1887e-05,  1.7173e-05,  2.8834e-05,  1.4386e-06,\n",
       "             -8.3005e-06, -3.8489e-07,  1.7470e-05,  1.8430e-05,  1.4288e-05,\n",
       "             -7.5563e-06,  3.1842e-05, -5.6524e-06, -6.5486e-06, -6.9928e-06,\n",
       "             -9.6028e-06,  2.4397e-05, -1.9504e-05,  1.3817e-05, -3.6762e-06,\n",
       "              2.5233e-05,  1.2081e-05, -2.1587e-05, -6.1136e-06, -1.3618e-05,\n",
       "              9.6325e-06, -5.5567e-06, -1.2758e-05,  1.8647e-05, -7.9972e-06,\n",
       "             -2.0641e-05,  1.9902e-05, -7.5428e-06,  4.3072e-05, -3.5206e-06,\n",
       "             -8.5445e-06,  1.6847e-05,  8.8031e-05,  4.4134e-05, -6.1934e-06,\n",
       "              1.4682e-05,  8.0655e-06,  3.6085e-06, -7.8815e-06,  6.7373e-05,\n",
       "             -7.5339e-06,  2.6205e-05,  1.1723e-07, -6.4762e-06,  1.3001e-05,\n",
       "             -1.4398e-05, -4.9445e-06,  2.7828e-05,  1.8094e-05,  1.9452e-05,\n",
       "             -4.8888e-07,  7.4387e-06,  1.0178e-05, -6.7446e-06, -5.0264e-06,\n",
       "             -1.1606e-05,  7.1469e-05,  4.1839e-06,  8.4610e-05, -1.0114e-05,\n",
       "              2.2454e-06,  3.1412e-05,  2.8206e-05, -9.8076e-06, -2.2115e-05,\n",
       "              7.2130e-05,  9.9197e-06,  1.8545e-05,  2.9933e-05,  2.5493e-05,\n",
       "             -5.5430e-06,  5.6989e-05, -1.9363e-05,  8.6490e-06, -3.7216e-06,\n",
       "              2.0025e-06,  6.5556e-06, -6.6983e-06, -5.6464e-06,  6.3836e-06,\n",
       "              1.1105e-05, -1.1141e-05,  1.7585e-05,  9.6056e-07,  1.5025e-05,\n",
       "              5.5156e-05,  8.8377e-05, -1.1248e-06,  6.0074e-05, -7.2361e-06,\n",
       "             -9.0757e-07,  3.3583e-06,  2.2918e-05, -3.6013e-06,  5.3339e-06,\n",
       "             -5.9067e-06, -9.4924e-06,  2.4874e-06,  1.9926e-05, -4.7909e-07,\n",
       "              6.8289e-06,  1.1070e-05,  1.9761e-05,  1.0647e-06,  5.5016e-06,\n",
       "             -1.4311e-05,  3.5894e-05, -1.1652e-06, -8.5031e-06, -1.7749e-05,\n",
       "             -7.4708e-06, -1.5935e-05,  1.2801e-05]]),\n",
       "    'exp_avg_sq': tensor([[2.7299e-07, 4.3069e-07, 1.0601e-06, 2.7242e-08, 2.8040e-07, 1.6791e-06,\n",
       "             6.9490e-08, 6.0221e-08, 2.7796e-07, 2.7174e-08, 6.7509e-07, 1.0283e-06,\n",
       "             2.3989e-07, 3.6623e-07, 4.4989e-08, 4.1094e-08, 4.2812e-07, 1.1712e-06,\n",
       "             4.5716e-07, 1.3467e-06, 1.2109e-07, 2.4286e-07, 6.7845e-08, 2.6816e-08,\n",
       "             9.5056e-08, 6.8947e-08, 7.1579e-07, 3.5320e-07, 2.7617e-07, 8.7591e-08,\n",
       "             1.3020e-06, 1.4528e-06, 1.4629e-06, 4.5189e-08, 9.0444e-08, 1.8587e-07,\n",
       "             3.0761e-08, 2.9748e-08, 3.3029e-07, 2.3649e-08, 4.2876e-07, 1.5038e-07,\n",
       "             3.0781e-08, 6.1938e-07, 3.3024e-08, 7.3124e-08, 1.8427e-07, 2.0468e-06,\n",
       "             3.6410e-07, 4.2666e-08, 8.0615e-07, 2.1665e-06, 6.5485e-08, 1.2790e-06,\n",
       "             1.8849e-06, 2.0824e-07, 3.4004e-07, 5.4592e-08, 4.6858e-08, 8.0608e-08,\n",
       "             1.8899e-07, 4.0570e-08, 2.9702e-07, 2.4802e-06, 3.8863e-07, 7.8235e-08,\n",
       "             9.3226e-08, 3.2584e-07, 8.2418e-08, 8.5304e-08, 3.6422e-08, 2.3375e-06,\n",
       "             5.3171e-07, 2.4733e-06, 2.3167e-08, 1.3131e-07, 1.2209e-06, 7.9949e-07,\n",
       "             3.3634e-08, 8.2770e-08, 1.3352e-06, 4.5978e-08, 1.5747e-06, 1.6546e-07,\n",
       "             8.1304e-07, 1.5114e-07, 9.1803e-07, 1.9900e-07, 1.8169e-07, 1.3296e-07,\n",
       "             9.0039e-07, 1.7714e-07, 4.1364e-08, 3.3463e-08, 1.6906e-06, 2.9243e-07,\n",
       "             4.7092e-08, 2.5718e-07, 4.5686e-08, 2.3090e-07, 8.8413e-07, 3.1231e-06,\n",
       "             3.3610e-08, 5.6573e-07, 2.3822e-08, 4.8955e-08, 2.9400e-07, 6.1286e-07,\n",
       "             1.6357e-06, 4.1965e-08, 3.2477e-08, 3.5937e-08, 2.4821e-06, 8.6997e-07,\n",
       "             9.8706e-08, 1.3730e-07, 4.5871e-08, 4.9953e-07, 1.4577e-07, 2.2918e-07,\n",
       "             5.2683e-07, 1.0719e-06, 3.0872e-07, 3.6693e-08, 2.6089e-07, 3.1066e-08,\n",
       "             1.5381e-07, 8.1879e-08],\n",
       "            [2.6625e-08, 2.8824e-08, 6.7234e-08, 1.4321e-09, 1.3750e-08, 7.3868e-08,\n",
       "             5.6287e-09, 5.1584e-09, 1.7709e-08, 1.1266e-08, 8.1901e-08, 1.1556e-07,\n",
       "             1.7913e-08, 3.5628e-08, 5.2678e-09, 6.9986e-09, 2.9650e-08, 2.5096e-08,\n",
       "             7.8807e-09, 1.2152e-08, 1.0046e-08, 1.8152e-08, 9.3406e-09, 1.3685e-09,\n",
       "             1.2004e-08, 7.7229e-09, 5.5319e-08, 1.9592e-08, 1.9280e-08, 7.0157e-09,\n",
       "             2.6103e-08, 5.1734e-08, 2.8809e-08, 2.2601e-09, 8.5779e-09, 1.0399e-08,\n",
       "             2.8072e-09, 1.9054e-09, 1.5500e-08, 1.3144e-09, 2.2546e-08, 5.5450e-09,\n",
       "             9.9802e-10, 9.2067e-08, 2.0605e-09, 6.9285e-09, 1.9688e-08, 5.3968e-08,\n",
       "             4.0081e-08, 2.1731e-09, 1.0418e-08, 4.8883e-08, 1.2023e-08, 2.9135e-08,\n",
       "             3.7726e-08, 1.3034e-08, 5.4086e-08, 2.9233e-09, 3.6761e-09, 9.0807e-09,\n",
       "             1.3450e-08, 9.5940e-10, 4.9754e-08, 1.1194e-07, 4.6590e-08, 1.5881e-08,\n",
       "             4.6411e-09, 1.2062e-08, 3.8448e-09, 1.6160e-09, 1.3173e-09, 1.3735e-07,\n",
       "             2.9360e-08, 1.5406e-07, 2.6094e-09, 2.4353e-09, 2.6351e-08, 3.5554e-08,\n",
       "             2.7533e-09, 4.2726e-09, 6.4348e-08, 5.4886e-09, 7.4338e-08, 2.4181e-08,\n",
       "             5.1597e-08, 1.1835e-08, 7.3842e-08, 8.3243e-09, 1.0076e-08, 1.2636e-09,\n",
       "             4.1948e-08, 2.4150e-08, 4.8419e-09, 2.1410e-09, 8.7457e-08, 4.7108e-08,\n",
       "             3.0029e-09, 1.1597e-08, 4.3416e-09, 2.2310e-08, 9.2390e-08, 8.1910e-08,\n",
       "             2.7377e-09, 7.7736e-08, 1.6986e-09, 4.8042e-09, 6.9347e-09, 6.8255e-08,\n",
       "             1.0541e-07, 1.8040e-09, 2.2120e-09, 3.1764e-09, 6.7752e-08, 3.6421e-08,\n",
       "             4.9358e-09, 1.4238e-08, 9.3507e-09, 1.6704e-08, 1.1451e-08, 3.8407e-09,\n",
       "             3.7082e-08, 5.9588e-08, 1.5482e-08, 2.3059e-09, 8.2990e-09, 1.9189e-09,\n",
       "             1.0108e-08, 9.0931e-09]])},\n",
       "   140493485559312: {'step': 1528596,\n",
       "    'exp_avg': tensor([2.2835e-05, 6.1678e-06]),\n",
       "    'exp_avg_sq': tensor([2.2755e-08, 6.7980e-10])}},\n",
       "  'param_groups': [{'lr': 0.0001,\n",
       "    'betas': (0.9, 0.999),\n",
       "    'eps': 1e-08,\n",
       "    'weight_decay': 0,\n",
       "    'amsgrad': False,\n",
       "    'params': [140493485557872,\n",
       "     140493485558272,\n",
       "     140493485558192,\n",
       "     140493485559072,\n",
       "     140493485558992,\n",
       "     140493485559312]}]},\n",
       " 'critic_opt_1': {'state': {140493485539568: {'step': 1528596,\n",
       "    'exp_avg': tensor([[ 3.1859e-06, -1.8844e-07,  3.7041e-06,  ..., -6.2898e-07,\n",
       "             -3.7548e-06, -2.7033e-06],\n",
       "            [ 5.1700e-06, -6.7545e-07, -2.1041e-05,  ..., -2.3032e-06,\n",
       "             -4.0891e-06,  2.2426e-06],\n",
       "            [-8.9005e-06, -2.1837e-07,  5.3809e-06,  ...,  5.3545e-07,\n",
       "              5.8500e-06, -3.5482e-06],\n",
       "            ...,\n",
       "            [-2.8993e-06, -6.7697e-08, -6.8496e-07,  ...,  2.1055e-07,\n",
       "              3.4221e-06, -1.4419e-06],\n",
       "            [ 1.7734e-06,  3.2976e-07,  3.0546e-07,  ..., -2.6515e-07,\n",
       "             -2.8688e-06,  1.6913e-07],\n",
       "            [-7.7196e-07, -1.2770e-07,  2.5048e-07,  ...,  3.8829e-08,\n",
       "              3.5490e-06,  2.4134e-07]]),\n",
       "    'exp_avg_sq': tensor([[5.3209e-10, 1.0833e-11, 1.2598e-09,  ..., 2.4291e-11, 2.0600e-09,\n",
       "             7.8351e-11],\n",
       "            [4.3175e-10, 4.8003e-12, 1.5927e-09,  ..., 1.6151e-11, 1.5215e-09,\n",
       "             5.7945e-11],\n",
       "            [3.6569e-10, 1.7680e-12, 1.0054e-09,  ..., 2.1256e-11, 8.1656e-10,\n",
       "             5.4014e-11],\n",
       "            ...,\n",
       "            [2.7475e-10, 2.0161e-12, 7.5805e-10,  ..., 1.3139e-11, 1.5384e-09,\n",
       "             8.9055e-11],\n",
       "            [4.3978e-10, 2.1759e-12, 8.3426e-10,  ..., 6.3072e-11, 1.1633e-09,\n",
       "             4.6039e-11],\n",
       "            [3.8468e-11, 9.7736e-13, 3.9550e-10,  ..., 2.9804e-12, 2.7974e-10,\n",
       "             1.6752e-11]])},\n",
       "   140493485539488: {'step': 1528596,\n",
       "    'exp_avg': tensor([-4.4939e-07, -6.4093e-07,  8.6697e-07,  3.7483e-07,  2.7031e-07,\n",
       "            -1.2753e-07, -7.1075e-07,  1.8099e-07,  7.3006e-07, -1.5177e-07,\n",
       "            -8.8410e-07,  1.0350e-06, -3.3024e-07,  7.5205e-08,  2.9639e-07,\n",
       "            -1.4662e-08, -1.5404e-06, -3.5262e-07, -1.0021e-06,  6.6606e-08,\n",
       "             5.3011e-08,  1.6940e-07,  7.7689e-07, -1.5825e-06,  1.3233e-07,\n",
       "            -1.6949e-07, -1.9656e-07,  8.1644e-07, -2.3525e-07, -2.9263e-08,\n",
       "             1.0038e-06,  1.7457e-08, -5.5751e-07, -2.5131e-07,  1.2830e-07,\n",
       "            -1.3484e-08, -3.2080e-07,  1.3970e-06, -7.5877e-08,  1.2731e-07,\n",
       "            -5.9942e-07,  4.2111e-07,  8.2402e-07,  1.3752e-07, -1.2494e-07,\n",
       "             1.0836e-06, -1.9389e-07, -1.1208e-06, -3.2702e-07, -1.4554e-07,\n",
       "            -1.5392e-07,  5.0579e-07, -1.7326e-07,  4.7689e-07, -3.9734e-09,\n",
       "             2.1408e-07,  5.8262e-08, -1.8701e-08,  2.4547e-09,  3.1416e-07,\n",
       "             6.3820e-07, -2.2449e-06,  4.5831e-07,  1.4872e-06, -2.0070e-07,\n",
       "             4.5055e-07, -1.1931e-07, -8.5805e-07, -5.7140e-08, -3.4017e-07,\n",
       "            -3.9794e-07,  1.8382e-07,  2.9905e-07,  1.3143e-07, -1.1280e-07,\n",
       "            -1.9528e-06, -1.8379e-07, -1.2590e-06, -4.7168e-07,  2.4572e-07,\n",
       "             7.6748e-07,  4.2608e-07, -4.8685e-07,  5.8204e-07,  2.4510e-07,\n",
       "             1.2086e-07,  1.1555e-06, -2.1145e-08,  4.5656e-07,  2.6095e-07,\n",
       "             1.3648e-06, -1.6925e-08,  8.0088e-08,  2.8479e-07,  1.0187e-07,\n",
       "            -3.5128e-07, -1.8195e-07,  2.9406e-09, -6.0663e-07,  8.8558e-09,\n",
       "            -1.3109e-06,  2.4775e-07,  1.2750e-06, -4.6972e-07, -5.5146e-07,\n",
       "            -6.8132e-07,  1.2605e-07,  2.6772e-07, -1.6763e-08, -4.0314e-07,\n",
       "            -1.1004e-07, -6.4382e-07,  4.5302e-07,  4.0397e-08, -3.1823e-07,\n",
       "             7.3975e-07, -2.5141e-07,  9.8935e-07,  5.1709e-07,  3.9174e-08,\n",
       "             3.6871e-07,  6.5905e-07, -2.3242e-07,  2.8410e-07, -1.5043e-06,\n",
       "             2.5258e-07,  4.1365e-07, -2.4175e-08,  1.0906e-07, -9.1228e-06,\n",
       "            -6.1882e-07, -4.3793e-08, -1.5843e-07,  2.1165e-07, -4.7715e-07,\n",
       "             4.0400e-07, -2.6051e-08, -2.0189e-06, -2.0581e-07,  2.5727e-06,\n",
       "            -7.2296e-07,  3.2017e-07,  7.4079e-09,  6.9962e-07, -4.7443e-07,\n",
       "             8.4045e-07, -9.8534e-08,  7.8268e-08,  8.1025e-07,  1.5724e-07,\n",
       "            -1.3377e-07, -1.0534e-07, -2.5836e-07, -1.4512e-07,  1.4407e-06,\n",
       "             3.0164e-07,  4.1162e-07,  1.2452e-06, -3.4461e-07,  3.5176e-07,\n",
       "             2.9204e-07, -9.7196e-09, -1.2734e-06, -6.8421e-08, -9.6071e-07,\n",
       "             1.6937e-07,  2.5609e-07,  1.5418e-07, -1.9744e-07,  2.9046e-07,\n",
       "             7.7446e-07, -6.6287e-07, -2.5371e-07, -1.5962e-07, -1.3105e-06,\n",
       "            -3.8510e-08, -4.9133e-07,  3.0104e-08, -6.3138e-07,  6.1189e-09,\n",
       "            -9.8604e-07,  8.3078e-07,  1.0315e-07,  8.9255e-07, -7.8109e-08,\n",
       "             4.8863e-07,  2.2430e-07,  8.6170e-07, -2.0410e-07,  2.5217e-06,\n",
       "            -2.6092e-07,  6.0529e-07,  1.4429e-06, -4.6408e-07, -3.1830e-07,\n",
       "             3.9296e-07, -1.4119e-07, -2.6891e-08,  2.5173e-07,  1.8691e-07,\n",
       "             2.9851e-07, -4.4883e-07, -4.9845e-07, -7.8382e-07,  5.6347e-07,\n",
       "            -7.4163e-07,  1.7279e-07, -4.9020e-07, -5.1807e-07,  9.6381e-08,\n",
       "             6.5385e-07, -5.5127e-08, -4.5594e-07,  6.2651e-08, -3.8042e-07,\n",
       "            -1.3952e-07,  6.4340e-08,  1.5293e-07, -1.5995e-07,  4.3847e-07,\n",
       "             4.6843e-08, -9.7714e-07,  3.9628e-07,  2.4063e-07, -1.8059e-07,\n",
       "             9.7112e-07, -1.7805e-07, -9.0667e-07,  1.5605e-07, -2.3314e-07,\n",
       "            -2.6270e-06, -1.3901e-07, -8.0937e-07,  1.5846e-07, -4.0877e-07,\n",
       "             3.6150e-07,  3.8735e-08, -1.4691e-07,  1.1924e-07,  2.3948e-07,\n",
       "             4.2036e-07, -4.1928e-07,  6.9932e-08,  2.7633e-07,  3.3916e-07,\n",
       "            -8.1189e-08,  9.4030e-07,  1.2146e-06, -2.4063e-08,  5.4361e-07,\n",
       "             2.4098e-07, -1.4903e-06, -2.2449e-07,  2.2403e-07, -3.0698e-07,\n",
       "             1.7846e-07]),\n",
       "    'exp_avg_sq': tensor([6.2127e-12, 4.9836e-12, 4.2878e-12, 2.1672e-11, 5.5750e-12, 2.5200e-12,\n",
       "            6.3868e-12, 2.2210e-12, 6.7475e-12, 3.5637e-12, 1.0088e-11, 1.0938e-11,\n",
       "            2.7871e-12, 1.7895e-11, 2.5730e-12, 7.0733e-12, 1.1386e-11, 8.6722e-12,\n",
       "            2.0732e-11, 5.0835e-12, 7.2599e-13, 1.4655e-12, 7.9941e-12, 4.0728e-11,\n",
       "            4.6179e-12, 9.5950e-12, 2.7834e-12, 1.5391e-11, 8.9677e-12, 5.4209e-12,\n",
       "            2.6042e-11, 3.2546e-12, 3.6952e-12, 1.2816e-11, 7.3020e-12, 4.5996e-12,\n",
       "            2.7929e-12, 1.4236e-11, 1.1150e-12, 1.8718e-12, 4.2561e-11, 1.6744e-10,\n",
       "            6.0360e-11, 2.8101e-12, 1.1756e-12, 6.0624e-12, 4.2640e-12, 1.2058e-11,\n",
       "            5.2713e-12, 2.9471e-12, 1.4079e-11, 9.5985e-12, 7.3036e-12, 1.1415e-11,\n",
       "            2.5668e-11, 3.9907e-12, 1.1305e-12, 6.8343e-13, 1.5844e-11, 2.7059e-12,\n",
       "            8.5167e-12, 2.3428e-10, 6.5212e-12, 2.1543e-11, 1.2002e-11, 2.8940e-11,\n",
       "            1.7348e-12, 2.6917e-11, 4.6157e-12, 1.3664e-11, 3.9199e-12, 8.1736e-12,\n",
       "            3.1794e-12, 8.6667e-12, 6.9202e-12, 6.1737e-11, 1.2312e-12, 1.6114e-11,\n",
       "            4.5806e-12, 2.5379e-12, 4.2270e-12, 8.1548e-12, 9.6665e-12, 6.4592e-12,\n",
       "            4.0315e-12, 2.8537e-12, 7.9843e-11, 2.9793e-11, 4.2228e-12, 3.3968e-12,\n",
       "            7.7665e-11, 9.7039e-13, 1.7847e-12, 2.5005e-12, 1.0044e-12, 1.8071e-12,\n",
       "            7.6853e-11, 3.6339e-12, 1.8684e-11, 3.3002e-11, 1.8447e-11, 7.1380e-12,\n",
       "            2.4009e-10, 8.4259e-11, 8.5940e-12, 2.9395e-12, 2.1226e-12, 6.9177e-12,\n",
       "            3.9700e-12, 6.9112e-12, 6.6636e-11, 7.0020e-12, 1.8666e-11, 4.4674e-12,\n",
       "            6.7350e-12, 2.3133e-12, 1.7268e-12, 8.4549e-12, 3.4615e-12, 5.3282e-12,\n",
       "            3.3365e-12, 6.1623e-12, 2.1734e-12, 1.5154e-11, 1.7795e-11, 2.3110e-12,\n",
       "            1.0541e-11, 4.0851e-12, 1.1455e-12, 8.0928e-10, 4.1736e-12, 2.0922e-12,\n",
       "            2.3998e-12, 3.8937e-12, 1.6252e-12, 1.8300e-12, 8.6854e-13, 1.1732e-10,\n",
       "            3.3692e-12, 4.1431e-11, 4.9015e-12, 4.0876e-12, 9.5080e-13, 9.8234e-12,\n",
       "            1.8726e-12, 7.9233e-11, 4.0857e-12, 1.8113e-12, 1.2873e-10, 1.7297e-11,\n",
       "            3.4660e-12, 2.3026e-12, 1.8439e-12, 1.0689e-12, 1.5604e-11, 1.1316e-11,\n",
       "            1.5649e-11, 5.2529e-11, 2.0906e-12, 7.1783e-11, 5.1891e-12, 1.0907e-12,\n",
       "            2.5521e-12, 5.2012e-12, 8.2144e-12, 5.5370e-12, 1.7284e-12, 3.6121e-12,\n",
       "            1.1972e-12, 2.8265e-10, 5.6347e-12, 2.6225e-12, 1.1394e-12, 5.4841e-12,\n",
       "            1.0124e-11, 1.1495e-12, 4.3340e-12, 9.1626e-12, 1.3815e-11, 4.5384e-12,\n",
       "            2.9248e-11, 2.7793e-12, 7.3785e-13, 4.3786e-11, 6.0366e-12, 2.4828e-11,\n",
       "            1.7019e-11, 1.4817e-11, 6.7286e-12, 2.0225e-10, 2.3549e-12, 2.3290e-11,\n",
       "            1.4348e-11, 1.2260e-11, 4.6159e-12, 3.8988e-12, 4.5766e-11, 1.5080e-12,\n",
       "            1.4991e-12, 4.3835e-12, 1.1941e-12, 1.2900e-11, 9.0055e-12, 8.0316e-12,\n",
       "            5.5258e-12, 1.1596e-10, 2.6932e-12, 1.3687e-11, 2.6605e-12, 1.5056e-11,\n",
       "            1.3872e-10, 1.1449e-11, 6.5627e-12, 5.3635e-12, 7.9523e-12, 2.1468e-11,\n",
       "            6.4577e-12, 5.9875e-12, 3.0391e-12, 4.2016e-12, 6.9274e-12, 5.2547e-12,\n",
       "            7.5872e-12, 3.0860e-12, 9.7417e-12, 8.2019e-12, 3.9563e-12, 7.3762e-12,\n",
       "            3.6395e-12, 4.0313e-12, 1.1042e-09, 2.7786e-12, 8.4339e-12, 9.3795e-12,\n",
       "            2.2458e-12, 3.8715e-12, 1.9360e-12, 3.2608e-12, 2.1759e-12, 8.9595e-12,\n",
       "            1.7855e-11, 2.1874e-12, 8.2876e-12, 2.5080e-12, 7.5472e-12, 2.3783e-12,\n",
       "            6.4423e-11, 6.5307e-12, 2.3024e-12, 7.3250e-12, 1.9545e-12, 6.8169e-11,\n",
       "            1.0879e-11, 3.2304e-12, 5.9949e-12, 7.6914e-13])},\n",
       "   140493485539408: {'step': 1528596,\n",
       "    'exp_avg': tensor([[ 9.6924e-08, -2.2769e-07,  9.6898e-08,  ..., -1.6427e-07,\n",
       "             -3.1131e-07,  2.6832e-07],\n",
       "            [ 3.9910e-08, -1.4543e-07,  1.4511e-07,  ...,  7.0964e-07,\n",
       "              3.6831e-07,  6.2601e-08],\n",
       "            [ 1.0737e-06,  2.2109e-06,  3.9914e-07,  ..., -2.9747e-08,\n",
       "             -2.9370e-07, -6.4395e-07],\n",
       "            ...,\n",
       "            [-3.3149e-07, -3.3036e-07, -3.2351e-07,  ..., -1.0897e-07,\n",
       "              3.2233e-08,  3.7260e-07],\n",
       "            [ 3.5340e-09,  2.4740e-08,  3.5662e-09,  ...,  3.6560e-09,\n",
       "              1.2044e-08, -2.9102e-09],\n",
       "            [ 7.3069e-08, -1.0824e-07, -1.0632e-07,  ..., -1.2837e-07,\n",
       "             -1.8013e-07,  2.1385e-07]]),\n",
       "    'exp_avg_sq': tensor([[1.7927e-11, 5.1111e-11, 1.9894e-11,  ..., 1.4172e-11, 1.2060e-11,\n",
       "             1.3878e-11],\n",
       "            [1.6757e-11, 5.9298e-11, 4.6108e-11,  ..., 1.0359e-11, 1.1011e-11,\n",
       "             9.6024e-12],\n",
       "            [4.7317e-10, 4.8864e-10, 1.0016e-09,  ..., 7.6195e-12, 7.6025e-12,\n",
       "             7.2596e-12],\n",
       "            ...,\n",
       "            [1.5233e-12, 1.0975e-11, 9.6500e-12,  ..., 1.0381e-12, 8.5976e-13,\n",
       "             9.7371e-13],\n",
       "            [2.4075e-12, 4.4312e-12, 8.3453e-14,  ..., 5.9772e-14, 5.2081e-14,\n",
       "             7.1046e-14],\n",
       "            [3.5998e-12, 8.5412e-13, 8.5205e-13,  ..., 7.8536e-13, 4.2232e-13,\n",
       "             5.0058e-13]])},\n",
       "   140493485540768: {'step': 1528596,\n",
       "    'exp_avg': tensor([-9.6953e-08, -1.9759e-08, -8.3740e-08,  2.9143e-06,  2.9510e-07,\n",
       "            -1.5871e-07,  7.1904e-08,  1.5455e-07,  9.5473e-07, -2.1878e-07,\n",
       "            -4.5509e-07, -2.0833e-07, -4.7293e-08,  9.2219e-07, -1.1179e-07,\n",
       "            -6.0300e-07,  9.9986e-08,  6.3274e-09,  5.8946e-07,  4.0167e-07,\n",
       "            -5.7106e-07, -1.0690e-07,  3.1427e-08, -1.4465e-06, -1.5115e-06,\n",
       "             1.1861e-07, -3.5251e-07, -9.5525e-08, -3.1082e-08,  1.1204e-07,\n",
       "            -1.7065e-07, -3.2983e-07, -3.4685e-06, -3.2836e-08, -1.3332e-07,\n",
       "             1.5529e-07,  2.8431e-07, -1.9316e-07,  1.2534e-07,  4.8141e-07,\n",
       "             3.3699e-06,  1.1408e-07, -5.5497e-10, -6.0125e-08,  7.6197e-07,\n",
       "             1.0093e-07, -3.1857e-07, -1.9367e-08, -2.3739e-07,  2.0291e-07,\n",
       "             1.8901e-07, -3.3151e-08,  1.2380e-06,  1.0587e-07, -1.1805e-08,\n",
       "            -3.1019e-08,  1.6609e-07,  3.2163e-07,  1.2152e-06,  2.5236e-08,\n",
       "             3.8557e-07,  7.5916e-08,  1.5143e-07, -7.5907e-08, -2.8747e-07,\n",
       "             1.6931e-07,  3.6123e-07, -2.3658e-09, -1.8994e-07, -4.9174e-07,\n",
       "             8.9454e-08, -1.7697e-08, -1.5998e-07, -3.1003e-07, -3.5525e-07,\n",
       "            -4.8447e-07, -3.3757e-08, -9.2751e-08,  1.0437e-06,  4.5431e-09,\n",
       "             6.9683e-08,  1.1941e-06,  1.1243e-09, -2.6267e-08, -6.8937e-08,\n",
       "            -4.8179e-08,  4.9259e-07, -3.2122e-07, -7.0402e-07,  1.4293e-07,\n",
       "             1.9891e-09, -4.1891e-08,  2.9215e-08, -6.7478e-08, -1.6443e-07,\n",
       "            -2.0467e-07,  1.5291e-07,  2.4119e-07, -1.3728e-06,  2.3225e-09,\n",
       "            -8.0600e-08,  2.1978e-07, -1.4416e-08,  4.5779e-07, -3.3354e-07,\n",
       "             7.5408e-09,  2.9880e-08, -3.2115e-08, -1.3179e-09,  1.2169e-07,\n",
       "             2.8460e-09,  2.2487e-07, -5.5703e-08,  4.8043e-10,  6.7476e-07,\n",
       "            -2.9684e-07,  8.1405e-07,  6.9237e-08, -9.9052e-09,  5.6105e-08,\n",
       "            -1.4567e-08,  6.1289e-08,  1.0741e-07, -3.4632e-07,  2.3583e-09,\n",
       "             3.3149e-07, -3.5725e-09,  1.0632e-07]),\n",
       "    'exp_avg_sq': tensor([1.7905e-11, 1.5547e-11, 1.2629e-11, 2.7658e-10, 2.0092e-12, 2.8450e-12,\n",
       "            4.1932e-12, 2.8492e-13, 6.9782e-12, 3.3194e-12, 7.1217e-13, 1.6104e-12,\n",
       "            3.6846e-13, 6.5235e-12, 6.0681e-12, 9.5932e-11, 1.1048e-12, 5.8857e-14,\n",
       "            2.0899e-12, 2.5699e-12, 7.6704e-12, 1.4833e-13, 4.6394e-13, 8.8189e-11,\n",
       "            3.0251e-11, 5.3637e-13, 2.9921e-12, 1.7110e-12, 3.0048e-12, 6.8401e-13,\n",
       "            5.8393e-12, 1.6972e-12, 1.0862e-10, 3.2517e-12, 2.2661e-12, 1.9075e-12,\n",
       "            1.3521e-12, 1.4069e-12, 3.8826e-13, 2.0009e-11, 5.2786e-11, 4.3493e-13,\n",
       "            1.0547e-13, 3.0323e-11, 7.4433e-11, 5.2745e-13, 6.9132e-13, 2.7054e-13,\n",
       "            1.4544e-12, 1.0214e-12, 1.6538e-12, 3.1485e-12, 4.3988e-11, 5.7061e-13,\n",
       "            4.8440e-12, 1.6521e-11, 1.9692e-13, 1.3802e-12, 7.0458e-12, 2.3630e-12,\n",
       "            4.4131e-12, 2.1903e-12, 3.0794e-12, 1.2370e-12, 2.8822e-12, 2.3455e-13,\n",
       "            7.0664e-12, 1.1039e-12, 1.1975e-11, 1.1153e-11, 3.1353e-13, 5.6598e-14,\n",
       "            2.8165e-12, 3.3311e-12, 2.5332e-12, 2.7277e-11, 1.1806e-11, 3.2504e-12,\n",
       "            3.1003e-11, 8.1745e-13, 1.8494e-12, 2.1705e-11, 5.2844e-13, 1.2157e-12,\n",
       "            1.7274e-13, 2.4075e-13, 5.8929e-11, 6.3338e-13, 5.5449e-10, 7.9177e-13,\n",
       "            1.2066e-12, 2.2424e-13, 9.2214e-13, 1.0879e-11, 1.1034e-12, 1.0122e-11,\n",
       "            7.5057e-12, 5.9917e-13, 1.3636e-11, 2.1120e-12, 8.2342e-12, 3.6618e-12,\n",
       "            3.3091e-13, 7.1985e-13, 1.4600e-12, 3.6605e-13, 3.7616e-13, 5.5651e-11,\n",
       "            9.9936e-12, 1.0528e-11, 1.7280e-10, 2.2413e-12, 1.5330e-12, 3.9523e-14,\n",
       "            1.5725e-11, 3.9885e-13, 6.4489e-12, 3.4432e-12, 4.5692e-13, 2.7405e-12,\n",
       "            2.4079e-12, 2.9293e-13, 3.4715e-12, 1.9977e-12, 3.2023e-13, 1.5237e-12,\n",
       "            8.3898e-14, 8.5231e-13])},\n",
       "   140493485539968: {'step': 1528596,\n",
       "    'exp_avg': tensor([[-2.1906e-04,  1.0997e-04,  3.2871e-04,  3.9150e-03, -2.7437e-04,\n",
       "             -2.5282e-04, -1.1903e-04, -7.6888e-05, -1.5231e-04, -1.1652e-04,\n",
       "             -2.8722e-04, -8.6840e-04, -1.5739e-04,  5.6872e-04, -1.7044e-04,\n",
       "             -6.7913e-04, -2.4060e-04, -2.2769e-04, -4.3745e-04,  1.7845e-04,\n",
       "             -1.3756e-04, -2.3685e-04, -2.0130e-04,  8.7048e-04,  2.2943e-05,\n",
       "             -1.5457e-04, -4.6154e-05, -2.3495e-04, -2.0883e-04, -8.2238e-05,\n",
       "             -1.8993e-04, -3.6622e-04,  1.8538e-04, -2.4288e-04, -1.6415e-04,\n",
       "             -3.3994e-04, -2.2185e-04, -8.6203e-05, -1.3537e-04, -2.0729e-04,\n",
       "             -1.1867e-03, -1.2016e-04, -2.0933e-04, -3.1415e-04,  4.0161e-04,\n",
       "             -1.9875e-04, -3.5954e-04, -2.5428e-04, -1.6026e-04, -1.0046e-04,\n",
       "             -1.5504e-04, -1.6127e-04, -1.6311e-03, -2.7698e-04, -2.3112e-04,\n",
       "             -2.0541e-04, -1.5422e-04, -1.3737e-04, -1.3795e-04, -1.8263e-04,\n",
       "             -3.4182e-04, -2.1560e-04, -2.3029e-04, -1.9893e-04, -2.5502e-04,\n",
       "             -2.3993e-04, -2.7543e-04, -2.0939e-04,  1.5718e-04, -2.2804e-04,\n",
       "             -9.7578e-05, -2.3112e-04, -1.4909e-04, -2.8362e-04,  4.0300e-04,\n",
       "             -1.7042e-04, -3.8046e-04, -1.8781e-04,  1.8160e-04, -2.1033e-04,\n",
       "             -2.1332e-04, -3.1852e-04, -2.0215e-04, -3.3064e-04, -2.2788e-04,\n",
       "             -2.6686e-04,  4.3329e-04, -1.5059e-04, -2.1690e-03,  1.3862e-05,\n",
       "             -2.0634e-04, -2.3491e-04, -2.0282e-04, -7.1630e-04, -3.1568e-04,\n",
       "             -4.2384e-04, -2.1598e-04, -2.8839e-04, -8.6208e-05, -2.0600e-04,\n",
       "             -2.0731e-04, -2.4327e-04, -2.6036e-04, -7.6163e-04, -2.4810e-04,\n",
       "             -2.0725e-04, -1.1941e-04,  1.1282e-05, -4.2085e-04, -1.8268e-04,\n",
       "             -7.4537e-04, -2.1130e-04, -3.4731e-04, -2.0973e-04, -1.0889e-03,\n",
       "             -2.5486e-04, -2.5376e-04, -2.7448e-04, -2.6784e-04, -3.8194e-04,\n",
       "             -2.9560e-04, -1.9853e-04, -2.3760e-04, -3.9440e-04, -2.0895e-04,\n",
       "             -1.8140e-04, -2.1073e-04, -1.7419e-04]]),\n",
       "    'exp_avg_sq': tensor([[3.0271e-05, 3.4702e-05, 6.1156e-05, 3.1263e-04, 3.0270e-05, 3.0578e-05,\n",
       "             3.1488e-05, 2.9939e-05, 2.9945e-05, 3.0289e-05, 3.0023e-05, 2.9835e-05,\n",
       "             3.7815e-05, 2.8401e-05, 2.9800e-05, 7.7398e-05, 3.0256e-05, 2.9951e-05,\n",
       "             3.0009e-05, 2.9015e-05, 3.0225e-05, 3.0014e-05, 2.9912e-05, 9.8301e-05,\n",
       "             3.1220e-05, 2.9836e-05, 3.0213e-05, 3.0431e-05, 2.9970e-05, 3.0753e-05,\n",
       "             2.9847e-05, 3.0727e-05, 3.1427e-05, 2.9733e-05, 3.0394e-05, 3.0060e-05,\n",
       "             2.9982e-05, 3.0149e-05, 2.9916e-05, 3.1205e-05, 3.3238e-05, 3.0858e-05,\n",
       "             3.0078e-05, 3.0076e-05, 2.1157e-05, 2.9836e-05, 3.0128e-05, 3.0297e-05,\n",
       "             3.0141e-05, 3.0028e-05, 3.0641e-05, 2.9919e-05, 5.1558e-05, 3.0669e-05,\n",
       "             3.0396e-05, 3.0098e-05, 3.0068e-05, 2.9720e-05, 2.9974e-05, 3.0109e-05,\n",
       "             2.9891e-05, 3.0179e-05, 2.9983e-05, 3.0214e-05, 2.9986e-05, 3.0138e-05,\n",
       "             2.9948e-05, 2.9987e-05, 3.2662e-05, 3.0489e-05, 2.9935e-05, 3.0507e-05,\n",
       "             2.9928e-05, 2.9856e-05, 2.9990e-05, 1.4160e-05, 3.0482e-05, 3.0124e-05,\n",
       "             1.9490e-05, 3.0040e-05, 2.9910e-05, 3.0955e-05, 3.0234e-05, 3.0195e-05,\n",
       "             3.0213e-05, 2.9840e-05, 1.0076e-05, 2.9834e-05, 1.2873e-04, 2.9190e-05,\n",
       "             3.0080e-05, 3.0035e-05, 3.0013e-05, 3.1895e-05, 3.0243e-05, 3.0978e-05,\n",
       "             3.0188e-05, 3.0667e-05, 3.1469e-05, 3.0828e-05, 3.0446e-05, 3.1187e-05,\n",
       "             2.9972e-05, 2.9978e-05, 2.9980e-05, 2.9902e-05, 2.9959e-05, 3.3427e-05,\n",
       "             3.5032e-05, 3.0724e-05, 9.0405e-05, 2.9956e-05, 3.0625e-05, 2.9934e-05,\n",
       "             4.1783e-05, 2.9882e-05, 3.0097e-05, 3.0572e-05, 2.9939e-05, 3.1977e-05,\n",
       "             3.0190e-05, 3.0360e-05, 3.0961e-05, 3.1301e-05, 3.0064e-05, 3.0064e-05,\n",
       "             3.0083e-05, 3.0182e-05]])},\n",
       "   140493485540208: {'step': 1528596,\n",
       "    'exp_avg': tensor([0.0002]),\n",
       "    'exp_avg_sq': tensor([2.9979e-05])}},\n",
       "  'param_groups': [{'lr': 0.0003,\n",
       "    'betas': (0.9, 0.999),\n",
       "    'eps': 1e-08,\n",
       "    'weight_decay': 0,\n",
       "    'amsgrad': False,\n",
       "    'params': [140493485539568,\n",
       "     140493485539488,\n",
       "     140493485539408,\n",
       "     140493485540768,\n",
       "     140493485539968,\n",
       "     140493485540208]}]}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = torch.load('./solverd_state.ckp')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-4.m46",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-4:m46"
  },
  "kernelspec": {
   "display_name": "drlnd",
   "language": "python",
   "name": "drlnd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
