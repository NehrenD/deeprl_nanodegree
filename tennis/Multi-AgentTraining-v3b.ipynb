{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from unityagents import UnityEnvironment\n",
    "import numpy as np\n",
    "import random\n",
    "from collections import deque\n",
    "import copy\n",
    "import ptan\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from maddpg_model import Config,Actor,Critic,ReplayBuffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "Unity brain name: TennisBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 8\n",
      "        Number of stacked Vector Observation: 3\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 2\n",
      "        Vector Action descriptions: , \n"
     ]
    }
   ],
   "source": [
    "env = UnityEnvironment(file_name='Tennis_Linux/Tennis.x86_64',no_graphics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "n_agents = len(env_info.agents)\n",
    "state_size = env_info.vector_observations.shape[1]\n",
    "action_size = env_info.previous_vector_actions.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config()\n",
    "\n",
    "writer = SummaryWriter(comment=\"-tennis_maddpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MDDPGAgent(object):\n",
    "    \"\"\"\n",
    "        This Agent is very similar to a DDPG Agent with the only difference that the critic network leverages the full states and actions for both agents\n",
    "        The Actor only uses it's own network so that pst training there is no more sharing of information between the agents.\n",
    "    \n",
    "    \"\"\"\n",
    "        \n",
    "    def __init__(self, state_size, action_size, num_agents,config):\n",
    "        \n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size        \n",
    "        self.config = config\n",
    "        \n",
    "        # Actor Network (w/ Target Network)\n",
    "        self.actor_local = Actor(state_size, action_size,config.ACTOR_FC1_UNITS,config.ACTOR_FC2_UNITS).to(config.DEVICE)\n",
    "        self.actor_target = Actor(state_size, action_size,config.ACTOR_FC1_UNITS,config.ACTOR_FC2_UNITS).to(config.DEVICE)\n",
    "        self.actor_optimizer = optim.Adam(self.actor_local.parameters(), lr=config.LR_ACTOR, weight_decay=config.WEIGHT_DECAY)\n",
    "\n",
    "        # Critic Network (w/ Target Network)\n",
    "        self.critic_local = Critic(num_agents*state_size, num_agents*action_size,config.CRITIC_FC1_UNITS,config.CRITIC_FC2_UNITS).to(config.DEVICE)\n",
    "        self.critic_target = Critic(num_agents*state_size, num_agents*action_size,config.CRITIC_FC1_UNITS,config.CRITIC_FC2_UNITS).to(config.DEVICE)\n",
    "        self.critic_optimizer = optim.Adam(self.critic_local.parameters(), lr=config.LR_CRITIC, weight_decay=config.WEIGHT_DECAY)\n",
    "\n",
    "        # Noise process        \n",
    "        self.noise_scale = config.NOISE_START\n",
    "    \n",
    "        # Make sure target is initialized with the same weight as the source (makes a big difference)\n",
    "        self.hard_update()\n",
    "\n",
    "    def act(self, states, add_noise=True,noise_scale=1.0):\n",
    "        \"\"\"Returns actions for given state as per current policy.\"\"\"\n",
    "                \n",
    "        if not add_noise:\n",
    "            self.noise_scale = 0.0\n",
    "                                    \n",
    "        states = torch.from_numpy(states).float().to(self.config.DEVICE)\n",
    "        self.actor_local.eval()\n",
    "        with torch.no_grad():\n",
    "            actions = self.actor_local(states).cpu().data.numpy()\n",
    "        self.actor_local.train()\n",
    "        \n",
    "        #add noise\n",
    "        actions += self.noise_scale*np.random.normal(0,0.5,self.action_size) #works much better than OU Noise process\n",
    "        \n",
    "        return np.clip(actions, -1, 1)\n",
    "        \n",
    "    def learning_step(self, experiences, gamma):\n",
    "        \n",
    "        full_states, actor_full_actions, full_actions, agent_rewards, agent_dones, full_next_states, critic_full_next_actions = experiences\n",
    "        \n",
    "        # Learning Step for Critic using full state, action and next state and full next action#\n",
    "\n",
    "        #Q Target\n",
    "        Q_target_next = self.critic_target(full_next_states, critic_full_next_actions)        \n",
    "        Q_target = agent_rewards + gamma * Q_target_next * (1 - agent_dones)\n",
    "        \n",
    "        #Q Expected\n",
    "        Q_expected = self.critic_local(full_states, full_actions)\n",
    "        \n",
    "        #Loss\n",
    "        critic_loss = F.mse_loss(input=Q_expected, target=Q_target)\n",
    "        \n",
    "        #Training Step\n",
    "        self.critic_optimizer.zero_grad()\n",
    "        critic_loss.backward()        \n",
    "        self.critic_optimizer.step()\n",
    "        \n",
    "        # Learning Step for Actor #\n",
    "        \n",
    "        #Loss\n",
    "        actor_loss = -self.critic_local.forward(full_states, actor_full_actions).mean() \n",
    "        \n",
    "        #Training Step\n",
    "        self.actor_optimizer.zero_grad()\n",
    "        actor_loss.backward()\n",
    "        self.actor_optimizer.step()                  \n",
    "\n",
    "        return (critic_loss,actor_loss)\n",
    "                \n",
    "    def soft_update(self):\n",
    "        \"\"\"\n",
    "        Soft update traget networks for actor an critic\n",
    "        \"\"\"\n",
    "        self._soft_update(self.critic_local, self.critic_target, self.config.TAU)\n",
    "        self._soft_update(self.actor_local, self.actor_target, self.config.TAU)\n",
    "   \n",
    "    def _soft_update(self, local_model, target_model, tau):\n",
    "        \"\"\"\n",
    "        Soft Update\n",
    "        \"\"\"\n",
    "        for target_param, local_param in zip(target_model.parameters(), local_model.parameters()):\n",
    "            target_param.data.copy_(tau*local_param.data + (1.0-tau)*target_param.data)\n",
    "\n",
    "    def hard_update(self):\n",
    "        \"\"\"\n",
    "        Soft update traget networks for actor an critic\n",
    "        \"\"\"\n",
    "        self._hard_update(self.critic_local, self.critic_target)\n",
    "        self._hard_update(self.actor_local, self.actor_target)\n",
    "        \n",
    "    def _hard_update(self, target, source):\n",
    "        \"\"\"\n",
    "        Hard Update to be used at initialization\n",
    "        \"\"\"\n",
    "        for target_param, source_param in zip(target.parameters(), source.parameters()):\n",
    "            target_param.data.copy_(source_param.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.ACTOR_FC1_UNITS = 265\n",
    "config.ACTOR_FC2_UNITS = 128\n",
    "config.CRITIC_FC1_UNITS = 256\n",
    "config.CRITIC_FC2_UNITS = 128\n",
    "config.LR_ACTOR = 1e-4\n",
    "config.LR_CRITIC = 3e-4\n",
    "config.TAU = 1e-3\n",
    "\n",
    "#REPLAY BUFFER\n",
    "config.BUFFER_SIZE = int(1e5)\n",
    "config.BATCH_SIZE = 256\n",
    "config.GAMMA = 0.99\n",
    "config.WEIGHT_DECAY = 0\n",
    "config.DEVICE = 'cpu'\n",
    "\n",
    "config.WAIT_EPOCHS = 300\n",
    "config.NOISE_START=1.0\n",
    "config.NOISE_END=0.1\n",
    "config.NOISE_REDUCTION=0.999\n",
    "\n",
    "config.TRAINING_ITERATIONS_PER_STEP = 3\n",
    "\n",
    "seed = 14\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "_ = torch.manual_seed(seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "agents = [MDDPGAgent(state_size,action_size,n_agents,config) for _ in range(n_agents)]\n",
    "replay_buffer = ReplayBuffer(config.BUFFER_SIZE,config.BATCH_SIZE,config.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50\tAverage Score: 0.02\tCurrent Score: 0.0\n",
      "Noise Scaling: 1.0, Memory size: 862 and Num Steps: 14\n",
      "Epoch 100\tAverage Score: 0.02\tCurrent Score: 0.0\n",
      "Noise Scaling: 1.0, Memory size: 1808 and Num Steps: 15\n",
      "Epoch 150\tAverage Score: 0.02\tCurrent Score: 0.0\n",
      "Noise Scaling: 1.0, Memory size: 2772 and Num Steps: 14\n",
      "Epoch 200\tAverage Score: 0.02\tCurrent Score: 0.0\n",
      "Noise Scaling: 1.0, Memory size: 3651 and Num Steps: 14\n",
      "Epoch 250\tAverage Score: 0.02\tCurrent Score: 0.0\n",
      "Noise Scaling: 1.0, Memory size: 4589 and Num Steps: 14\n",
      "Epoch 300\tAverage Score: 0.01\tCurrent Score: 0.0\n",
      "Noise Scaling: 1.0, Memory size: 5485 and Num Steps: 17\n",
      "Epoch 350\tAverage Score: 0.01\tCurrent Score: 0.0\n",
      "Noise Scaling: 0.9512056281970314, Memory size: 6195 and Num Steps: 14\n",
      "Epoch 400\tAverage Score: 0.01\tCurrent Score: 0.0\n",
      "Noise Scaling: 0.9047921471137089, Memory size: 7058 and Num Steps: 15\n",
      "Epoch 450\tAverage Score: 0.01\tCurrent Score: 0.0\n",
      "Noise Scaling: 0.8606433826830363, Memory size: 7831 and Num Steps: 15\n",
      "Epoch 500\tAverage Score: 0.01\tCurrent Score: 0.10000000149011612\n",
      "Noise Scaling: 0.8186488294786356, Memory size: 8749 and Num Steps: 45\n",
      "Epoch 550\tAverage Score: 0.03\tCurrent Score: 0.10000000149011612\n",
      "Noise Scaling: 0.7787033741169899, Memory size: 9880 and Num Steps: 56\n",
      "Epoch 600\tAverage Score: 0.05\tCurrent Score: 0.10000000149011612\n",
      "Noise Scaling: 0.7407070321560992, Memory size: 11189 and Num Steps: 30\n",
      "Epoch 650\tAverage Score: 0.07\tCurrent Score: 0.10000000149011612\n",
      "Noise Scaling: 0.704564697832001, Memory size: 12571 and Num Steps: 31\n",
      "Epoch 700\tAverage Score: 0.08\tCurrent Score: 0.10000000149011612\n",
      "Noise Scaling: 0.6701859060067401, Memory size: 14170 and Num Steps: 39\n",
      "Epoch 750\tAverage Score: 0.09\tCurrent Score: 0.10000000149011612\n",
      "Noise Scaling: 0.6374846057319378, Memory size: 15963 and Num Steps: 48\n",
      "Epoch 800\tAverage Score: 0.08\tCurrent Score: 0.0\n",
      "Noise Scaling: 0.6063789448611847, Memory size: 17590 and Num Steps: 13\n",
      "Epoch 850\tAverage Score: 0.06\tCurrent Score: 0.10000000149011612\n",
      "Noise Scaling: 0.5767910651721362, Memory size: 18977 and Num Steps: 71\n",
      "Epoch 900\tAverage Score: 0.07\tCurrent Score: 0.0\n",
      "Noise Scaling: 0.5486469074854967, Memory size: 20787 and Num Steps: 14\n",
      "Epoch 950\tAverage Score: 0.09\tCurrent Score: 0.30000000447034836\n",
      "Noise Scaling: 0.5218760262931004, Memory size: 22943 and Num Steps: 110\n",
      "Epoch 1000\tAverage Score: 0.11\tCurrent Score: 0.0\n",
      "Noise Scaling: 0.49641141343109896, Memory size: 25394 and Num Steps: 13\n",
      "Epoch 1050\tAverage Score: 0.13\tCurrent Score: 0.10000000149011612\n",
      "Noise Scaling: 0.47218933035690475, Memory size: 28098 and Num Steps: 42\n",
      "Epoch 1100\tAverage Score: 0.13\tCurrent Score: 0.10000000149011612\n",
      "Noise Scaling: 0.4491491486100751, Memory size: 30679 and Num Steps: 31\n",
      "Epoch 1150\tAverage Score: 0.14\tCurrent Score: 0.09000000171363354\n",
      "Noise Scaling: 0.42723319805780824, Memory size: 33881 and Num Steps: 30\n",
      "Epoch 1200\tAverage Score: 0.15\tCurrent Score: 0.09000000171363354\n",
      "Noise Scaling: 0.4063866225452042, Memory size: 36901 and Num Steps: 31\n",
      "Epoch 1250\tAverage Score: 0.14\tCurrent Score: 0.09000000171363354\n",
      "Noise Scaling: 0.38655724258898083, Memory size: 40156 and Num Steps: 32\n",
      "Epoch 1300\tAverage Score: 0.21\tCurrent Score: 0.7000000104308128\n",
      "Noise Scaling: 0.36769542477096373, Memory size: 45693 and Num Steps: 300\n",
      "Epoch 1350\tAverage Score: 0.23\tCurrent Score: 0.30000000447034836\n",
      "Noise Scaling: 0.34975395750443883, Memory size: 49481 and Num Steps: 130\n",
      "Epoch 1400\tAverage Score: 0.20\tCurrent Score: 0.20000000298023224\n",
      "Noise Scaling: 0.3326879328624075, Memory size: 53914 and Num Steps: 70\n",
      "Epoch 1450\tAverage Score: 0.22\tCurrent Score: 0.30000000447034836\n",
      "Noise Scaling: 0.3164546341719581, Memory size: 58649 and Num Steps: 128\n",
      "Epoch 1500\tAverage Score: 0.22\tCurrent Score: 0.5000000074505806\n",
      "Noise Scaling: 0.3010134290933991, Memory size: 62854 and Num Steps: 206\n",
      "Epoch 1550\tAverage Score: 0.24\tCurrent Score: 0.10000000149011612\n",
      "Noise Scaling: 0.2863256679165293, Memory size: 68436 and Num Steps: 46\n",
      "Epoch 1600\tAverage Score: 0.29\tCurrent Score: 0.20000000298023224\n",
      "Noise Scaling: 0.2723545868194768, Memory size: 74241 and Num Steps: 57\n",
      "Epoch 1650\tAverage Score: 0.29\tCurrent Score: 0.0\n",
      "Noise Scaling: 0.2590652158479633, Memory size: 79892 and Num Steps: 14\n",
      "Epoch 1700\tAverage Score: 0.32\tCurrent Score: 0.10000000149011612\n",
      "Noise Scaling: 0.2464242913846615, Memory size: 86711 and Num Steps: 50\n",
      "Epoch 1750\tAverage Score: 0.32\tCurrent Score: 0.09000000171363354\n",
      "Noise Scaling: 0.2344001728895552, Memory size: 92288 and Num Steps: 31\n",
      "Epoch 1800\tAverage Score: 0.35\tCurrent Score: 0.20000000298023224\n",
      "Noise Scaling: 0.2229627637029021, Memory size: 100000 and Num Steps: 91\n",
      "Epoch 1850\tAverage Score: 0.35\tCurrent Score: 0.0\n",
      "Noise Scaling: 0.21208343571256524, Memory size: 100000 and Num Steps: 3\n",
      "Epoch 1900\tAverage Score: 0.31\tCurrent Score: 0.10000000149011612\n",
      "Noise Scaling: 0.20173495769715533, Memory size: 100000 and Num Steps: 46\n",
      "Epoch 1950\tAverage Score: 0.33\tCurrent Score: 0.20000000298023224\n",
      "Noise Scaling: 0.19189142716562418, Memory size: 100000 and Num Steps: 90\n",
      "Epoch 2000\tAverage Score: 0.36\tCurrent Score: 0.6000000089406967\n",
      "Noise Scaling: 0.18252820552270244, Memory size: 100000 and Num Steps: 222\n",
      "Epoch 2050\tAverage Score: 0.31\tCurrent Score: 0.0\n",
      "Noise Scaling: 0.173621856397899, Memory size: 100000 and Num Steps: 11\n",
      "Epoch 2100\tAverage Score: 0.31\tCurrent Score: 0.30000000447034836\n",
      "Noise Scaling: 0.16515008698369826, Memory size: 100000 and Num Steps: 129\n",
      "Epoch 2150\tAverage Score: 0.38\tCurrent Score: 0.800000011920929\n",
      "Noise Scaling: 0.15709169223612307, Memory size: 100000 and Num Steps: 300\n",
      "Epoch 2200\tAverage Score: 0.37\tCurrent Score: 0.10000000149011612\n",
      "Noise Scaling: 0.14942650179799616, Memory size: 100000 and Num Steps: 31\n",
      "Epoch 2250\tAverage Score: 0.38\tCurrent Score: 0.5000000074505806\n",
      "Noise Scaling: 0.14213532951204777, Memory size: 100000 and Num Steps: 190\n",
      "Epoch 2300\tAverage Score: 0.39\tCurrent Score: 0.800000011920929\n",
      "Noise Scaling: 0.13519992539749945, Memory size: 100000 and Num Steps: 300\n",
      "Epoch 2350\tAverage Score: 0.33\tCurrent Score: 0.10000000149011612\n",
      "Noise Scaling: 0.12860292996992023, Memory size: 100000 and Num Steps: 52\n",
      "Epoch 2400\tAverage Score: 0.36\tCurrent Score: 0.5000000074505806\n",
      "Noise Scaling: 0.12232783079001679, Memory size: 100000 and Num Steps: 206\n",
      "Epoch 2450\tAverage Score: 0.35\tCurrent Score: 0.10000000149011612\n",
      "Noise Scaling: 0.11635892113259806, Memory size: 100000 and Num Steps: 31\n",
      "Epoch 2500\tAverage Score: 0.27\tCurrent Score: 0.10000000149011612\n",
      "Noise Scaling: 0.11068126067226176, Memory size: 100000 and Num Steps: 50\n",
      "Epoch 2550\tAverage Score: 0.29\tCurrent Score: 0.20000000298023224\n",
      "Noise Scaling: 0.10528063808739813, Memory size: 100000 and Num Steps: 70\n",
      "Epoch 2600\tAverage Score: 0.30\tCurrent Score: 0.30000000447034836\n",
      "Noise Scaling: 0.10014353548890784, Memory size: 100000 and Num Steps: 122\n",
      "Epoch 2650\tAverage Score: 0.30\tCurrent Score: 0.0\n",
      "Noise Scaling: 0.09994334856146551, Memory size: 100000 and Num Steps: 11\n",
      "Epoch 2700\tAverage Score: 0.30\tCurrent Score: 0.0\n",
      "Noise Scaling: 0.09994334856146551, Memory size: 100000 and Num Steps: 17\n",
      "Epoch 2750\tAverage Score: 0.30\tCurrent Score: 0.6000000089406967\n",
      "Noise Scaling: 0.09994334856146551, Memory size: 100000 and Num Steps: 221\n",
      "Epoch 2800\tAverage Score: 0.34\tCurrent Score: 0.4000000059604645\n",
      "Noise Scaling: 0.09994334856146551, Memory size: 100000 and Num Steps: 178\n",
      "Epoch 2850\tAverage Score: 0.38\tCurrent Score: 0.10000000149011612\n",
      "Noise Scaling: 0.09994334856146551, Memory size: 100000 and Num Steps: 52\n",
      "Epoch 2900\tAverage Score: 0.36\tCurrent Score: 0.10000000149011612\n",
      "Noise Scaling: 0.09994334856146551, Memory size: 100000 and Num Steps: 30\n",
      "Epoch 2950\tAverage Score: 0.33\tCurrent Score: 0.20000000298023224\n",
      "Noise Scaling: 0.09994334856146551, Memory size: 100000 and Num Steps: 87\n",
      "Epoch 3000\tAverage Score: 0.33\tCurrent Score: 0.20000000298023224\n",
      "Noise Scaling: 0.09994334856146551, Memory size: 100000 and Num Steps: 69\n",
      "Epoch 3050\tAverage Score: 0.35\tCurrent Score: 0.800000011920929\n",
      "Noise Scaling: 0.09994334856146551, Memory size: 100000 and Num Steps: 300\n",
      "Epoch 3100\tAverage Score: 0.36\tCurrent Score: 0.0\n",
      "Noise Scaling: 0.09994334856146551, Memory size: 100000 and Num Steps: 15\n",
      "Epoch 3150\tAverage Score: 0.33\tCurrent Score: 0.30000000447034836\n",
      "Noise Scaling: 0.09994334856146551, Memory size: 100000 and Num Steps: 108\n",
      "Epoch 3200\tAverage Score: 0.35\tCurrent Score: 0.800000011920929\n",
      "Noise Scaling: 0.09994334856146551, Memory size: 100000 and Num Steps: 300\n",
      "Epoch 3250\tAverage Score: 0.43\tCurrent Score: 0.0\n",
      "Noise Scaling: 0.09994334856146551, Memory size: 100000 and Num Steps: 13\n",
      "Epoch 3300\tAverage Score: 0.40\tCurrent Score: 0.20000000298023224\n",
      "Noise Scaling: 0.09994334856146551, Memory size: 100000 and Num Steps: 69\n",
      "Epoch 3350\tAverage Score: 0.34\tCurrent Score: 0.0\n",
      "Noise Scaling: 0.09994334856146551, Memory size: 100000 and Num Steps: 14\n",
      "Epoch 3400\tAverage Score: 0.34\tCurrent Score: 0.30000000447034836\n",
      "Noise Scaling: 0.09994334856146551, Memory size: 100000 and Num Steps: 127\n",
      "Epoch 3450\tAverage Score: 0.33\tCurrent Score: 0.7000000104308128\n",
      "Noise Scaling: 0.09994334856146551, Memory size: 100000 and Num Steps: 282\n",
      "Epoch 3500\tAverage Score: 0.37\tCurrent Score: 0.800000011920929\n",
      "Noise Scaling: 0.09994334856146551, Memory size: 100000 and Num Steps: 300\n",
      "Epoch 3550\tAverage Score: 0.37\tCurrent Score: 0.800000011920929\n",
      "Noise Scaling: 0.09994334856146551, Memory size: 100000 and Num Steps: 300\n",
      "Epoch 3600\tAverage Score: 0.37\tCurrent Score: 0.30000000447034836\n",
      "Noise Scaling: 0.09994334856146551, Memory size: 100000 and Num Steps: 109\n",
      "Epoch 3650\tAverage Score: 0.40\tCurrent Score: 0.30000000447034836\n",
      "Noise Scaling: 0.09994334856146551, Memory size: 100000 and Num Steps: 124\n",
      "Epoch 3700\tAverage Score: 0.35\tCurrent Score: 0.5000000074505806\n",
      "Noise Scaling: 0.09994334856146551, Memory size: 100000 and Num Steps: 201\n",
      "Epoch 3750\tAverage Score: 0.36\tCurrent Score: 0.7000000104308128\n",
      "Noise Scaling: 0.09994334856146551, Memory size: 100000 and Num Steps: 280\n",
      "Epoch 3800\tAverage Score: 0.43\tCurrent Score: 0.10000000149011612\n",
      "Noise Scaling: 0.09994334856146551, Memory size: 100000 and Num Steps: 64\n",
      "Epoch 3850\tAverage Score: 0.37\tCurrent Score: 0.10000000149011612\n",
      "Noise Scaling: 0.09994334856146551, Memory size: 100000 and Num Steps: 53\n",
      "Epoch 3900\tAverage Score: 0.24\tCurrent Score: 0.20000000298023224\n",
      "Noise Scaling: 0.09994334856146551, Memory size: 100000 and Num Steps: 68\n",
      "Epoch 3950\tAverage Score: 0.23\tCurrent Score: 0.10000000149011612\n",
      "Noise Scaling: 0.09994334856146551, Memory size: 100000 and Num Steps: 52\n",
      "Epoch 4000\tAverage Score: 0.28\tCurrent Score: 0.30000000447034836\n",
      "Noise Scaling: 0.09994334856146551, Memory size: 100000 and Num Steps: 109\n",
      "Epoch 4050\tAverage Score: 0.35\tCurrent Score: 0.6000000089406967\n",
      "Noise Scaling: 0.09994334856146551, Memory size: 100000 and Num Steps: 242\n",
      "Epoch 4100\tAverage Score: 0.39\tCurrent Score: 0.800000011920929\n",
      "Noise Scaling: 0.09994334856146551, Memory size: 100000 and Num Steps: 300\n",
      "Epoch 4150\tAverage Score: 0.40\tCurrent Score: 0.800000011920929\n",
      "Noise Scaling: 0.09994334856146551, Memory size: 100000 and Num Steps: 300\n",
      "Epoch 4200\tAverage Score: 0.44\tCurrent Score: 0.10000000149011612\n",
      "Noise Scaling: 0.09994334856146551, Memory size: 100000 and Num Steps: 51\n",
      "Epoch 4250\tAverage Score: 0.33\tCurrent Score: 0.30000000447034836\n",
      "Noise Scaling: 0.09994334856146551, Memory size: 100000 and Num Steps: 100\n",
      "Epoch 4300\tAverage Score: 0.26\tCurrent Score: 0.30000000447034836\n",
      "Noise Scaling: 0.09994334856146551, Memory size: 100000 and Num Steps: 127\n",
      "Epoch 4350\tAverage Score: 0.36\tCurrent Score: 0.10000000149011612\n",
      "Noise Scaling: 0.09994334856146551, Memory size: 100000 and Num Steps: 31\n",
      "Epoch 4400\tAverage Score: 0.37\tCurrent Score: 0.10000000149011612\n",
      "Noise Scaling: 0.09994334856146551, Memory size: 100000 and Num Steps: 17\n",
      "Epoch 4450\tAverage Score: 0.37\tCurrent Score: 0.10000000149011612\n",
      "Noise Scaling: 0.09994334856146551, Memory size: 100000 and Num Steps: 52\n",
      "Epoch 4500\tAverage Score: 0.41\tCurrent Score: 0.20000000298023224\n",
      "Noise Scaling: 0.09994334856146551, Memory size: 100000 and Num Steps: 90\n",
      "Epoch 4550\tAverage Score: 0.39\tCurrent Score: 0.30000000447034836\n",
      "Noise Scaling: 0.09994334856146551, Memory size: 100000 and Num Steps: 129\n",
      "Epoch 4600\tAverage Score: 0.42\tCurrent Score: 0.4000000059604645\n",
      "Noise Scaling: 0.09994334856146551, Memory size: 100000 and Num Steps: 140\n",
      "Epoch 4650\tAverage Score: 0.39\tCurrent Score: 0.0\n",
      "Noise Scaling: 0.09994334856146551, Memory size: 100000 and Num Steps: 14\n",
      "Epoch 4700\tAverage Score: 0.27\tCurrent Score: 0.20000000298023224\n",
      "Noise Scaling: 0.09994334856146551, Memory size: 100000 and Num Steps: 71\n",
      "Epoch 4750\tAverage Score: 0.30\tCurrent Score: 0.10000000149011612\n",
      "Noise Scaling: 0.09994334856146551, Memory size: 100000 and Num Steps: 41\n",
      "Epoch 4800\tAverage Score: 0.46\tCurrent Score: 0.10000000149011612\n",
      "Noise Scaling: 0.09994334856146551, Memory size: 100000 and Num Steps: 17\n",
      "Solved!\n"
     ]
    }
   ],
   "source": [
    "NUM_EPOCHS=10000\n",
    "MAX_STEPS = 300\n",
    "\n",
    "with ptan.common.utils.TBMeanTracker(writer, batch_size=100) as tb_tracker:\n",
    "    scores_deque = deque(maxlen=100)\n",
    "    scores_list = []\n",
    "    scores_list_100_avg = []\n",
    "    \n",
    "    noise_scale = config.NOISE_START\n",
    "    \n",
    "    for epoch in range(1, NUM_EPOCHS+1):\n",
    "        \n",
    "        if epoch > config.WAIT_EPOCHS and noise_scale > config.NOISE_END:                \n",
    "            noise_scale = config.NOISE_REDUCTION**(epoch-config.WAIT_EPOCHS)\n",
    "           \n",
    "        env_info = env.reset(train_mode=True)[brain_name]                                \n",
    "        scores = np.zeros(n_agents)                  \n",
    "        \n",
    "        num_steps = 0\n",
    "        for _ in range(MAX_STEPS):\n",
    "            \n",
    "            states = env_info.vector_observations\n",
    "            \n",
    "            actions = np.asarray([agents[i].act(states[i],noise_scale=noise_scale) for i in range(len(agents))])\n",
    "            \n",
    "            env_info = env.step(actions)[brain_name]           \n",
    "            next_states = env_info.vector_observations\n",
    "            \n",
    "            rewards = env_info.rewards                         \n",
    "            dones = env_info.local_done                        \n",
    "            \n",
    "            full_states = np.reshape(states,(n_agents*state_size))\n",
    "            full_next_states = np.reshape(next_states,(n_agents*state_size))\n",
    "        \n",
    "            replay_buffer.add(full_states, states, actions, rewards, full_next_states, next_states, dones)            \n",
    "            scores += rewards                                  \n",
    "            \n",
    "            if len(replay_buffer) > config.BATCH_SIZE and epoch > config.WAIT_EPOCHS:\n",
    "            \n",
    "                for _ in range(config.TRAINING_ITERATIONS_PER_STEP): \n",
    "                \n",
    "                    #Run training step one per agent\n",
    "                    for agent_id in range(n_agents):\n",
    "\n",
    "                        rb_full_states, rb_states, rb_actions, rb_rewards, rb_full_next_states, rb_next_states, rb_dones = replay_buffer.sample()\n",
    "                        next_actions = [agents[i].actor_target.forward(rb_next_states[:,i,:]).detach().numpy() for i in range(n_agents)]\n",
    "                        full_next_actions = torch.from_numpy(np.concatenate(next_actions,axis=1)).to(config.device)\n",
    "\n",
    "                        agent = agents[agent_id]\n",
    "                        agent_state = rb_states[:,agent_id,:]\n",
    "                        agent_rewards = rb_rewards[:,agent_id].view(-1,1) \n",
    "                        agent_dones = rb_dones[:,agent_id].view(-1,1) \n",
    "\n",
    "                        actor_full_actions = rb_actions.clone()\n",
    "                        actor_full_actions[:,agent_id,:] = agent.actor_local.forward(agent_state)\n",
    "                        actor_full_actions = actor_full_actions.view(-1, n_agents*action_size)\n",
    "\n",
    "                        full_actions = rb_actions.view(-1,n_agents*action_size)\n",
    "\n",
    "                        experiences = (rb_full_states, actor_full_actions, full_actions, agent_rewards, agent_dones, rb_full_next_states, full_next_actions)\n",
    "                        agent_losses = agent.learning_step(experiences, config.GAMMA)\n",
    "\n",
    "                        agent.soft_update()\n",
    "\n",
    "                        tb_tracker.track(f\"loss_critic_{agent_id}\", agent_losses[0], epoch)\n",
    "                        tb_tracker.track(f\"loss_actor_{agent_id}\", agent_losses[1], epoch)                    \n",
    "            \n",
    "            num_steps += 1\n",
    "            if np.any(dones):                                  \n",
    "                break\n",
    "            \n",
    "        scores_deque.append(np.max(scores))\n",
    "        scores_list.append(np.max(scores))\n",
    "        scores_list_100_avg.append(np.mean(scores_deque))\n",
    "\n",
    "        tb_tracker.track(\"num_steps\", num_steps, epoch)\n",
    "        tb_tracker.track(\"reward\", np.max(scores), epoch)\n",
    "        tb_tracker.track(\"reward_100\", sum(scores_deque)/len(scores_deque), epoch)\n",
    "                    \n",
    "        if epoch % 50 == 0:\n",
    "            print('Epoch {}\\tAverage Score: {:.2f}\\tCurrent Score: {}'.format(epoch, np.mean(scores_deque), np.max(scores)))\n",
    "            print('Noise Scaling: {}, Memory size: {} and Num Steps: {}'.format(noise_scale, len(replay_buffer), num_steps))\n",
    "\n",
    "        if np.mean(scores_deque) > 0.5 and len(scores_deque) >= 100:\n",
    "            print(\"Solved!\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_state = {\n",
    "    'epoch': epoch,\n",
    "    'score_list': scores_list,    \n",
    "}\n",
    "\n",
    "for i,agent in enumerate(agents):\n",
    "    \n",
    "    learning_state[f'actor_{i}'] = agent.actor_local.state_dict()\n",
    "    learning_state[f'critic_{i}'] = agent.critic_local.state_dict()\n",
    "    learning_state[f'actor_opt_{i}'] = agent.actor_optimizer.state_dict()\n",
    "    learning_state[f'critic_opt_{i}'] = agent.critic_optimizer.state_dict()\n",
    "    \n",
    "torch.save(learning_state,'./solverd_state.ckp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5008000074885786"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(scores_list[-100:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fc6ce958750>]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(scores_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('./score_list',scores_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-4.m46",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-4:m46"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
