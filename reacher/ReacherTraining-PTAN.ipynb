{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from unityagents import UnityEnvironment\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "from collections import deque\n",
    "\n",
    "import ptan\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ddpg_model_ptan import DDPGActor,DDPGCritic,Config\n",
    "from utils.experience_unity import UnityExperienceSourceFirstLast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\tgoal_size -> 5.0\n",
      "\t\tgoal_speed -> 1.0\n",
      "Unity brain name: ReacherBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 33\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 4\n",
      "        Vector Action descriptions: , , , \n"
     ]
    }
   ],
   "source": [
    "env = UnityEnvironment(file_name='Reacher-2.app',no_graphics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]\n",
    "state_size = brain.vector_observation_space_size\n",
    "action_size = brain.vector_action_space_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter(comment=\"-reacherddpg_ptan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.ACTOR_FC1_UNITS = 64\n",
    "config.ACTOR_FC2_UNITS = 64\n",
    "config.CRITIC_FC1_UNITS = 64\n",
    "config.CRITIC_FC2_UNITS = 64\n",
    "config.NOISE_THETA = 0.15\n",
    "config.NOISE_SIGMA = 0.2\n",
    "config.LR_ACTOR = 1e-4\n",
    "config.LR_CRITIC = 1e-4\n",
    "config.TAU = 1e-4\n",
    "\n",
    "#REPLAY BUFFER\n",
    "config.BUFFER_SIZE = int(1e7)\n",
    "config.BATCH_SIZE = 256\n",
    "config.STEPS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "actor_net = DDPGActor(state_size,action_size,config.ACTOR_FC1_UNITS,config.ACTOR_FC2_UNITS)\n",
    "critic_net = DDPGCritic(state_size,action_size,config.CRITIC_FC1_UNITS,config.CRITIC_FC2_UNITS)\n",
    "\n",
    "actor_target = ptan.agent.TargetNet(actor_net)\n",
    "critic_target = ptan.agent.TargetNet(critic_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentDDPG(ptan.agent.BaseAgent):\n",
    "    \n",
    "    def __init__(self, net, device=\"cpu\", ou_enabled=True, ou_mu=0.0, ou_teta=0.15, ou_sigma=0.2, ou_epsilon=1.0):\n",
    "        self.net = net\n",
    "        self.device = device\n",
    "        self.ou_enabled = ou_enabled\n",
    "        self.ou_mu = ou_mu\n",
    "        self.ou_teta = ou_teta\n",
    "        self.ou_sigma = ou_sigma\n",
    "        self.ou_epsilon = ou_epsilon\n",
    "\n",
    "    def initial_state(self):\n",
    "        return None\n",
    "\n",
    "    def __call__(self, states, agent_states):\n",
    "        states_v = ptan.agent.float32_preprocessor(states).to(self.device)\n",
    "        mu_v = self.net(states_v)\n",
    "        actions = mu_v.data.cpu().numpy()\n",
    "\n",
    "        if self.ou_enabled and self.ou_epsilon > 0:\n",
    "            new_a_states = []\n",
    "            for a_state, action in zip(agent_states, actions):\n",
    "                if a_state is None:\n",
    "                    a_state = np.zeros(shape=action.shape, dtype=np.float32)\n",
    "                a_state += self.ou_teta * (self.ou_mu - a_state)\n",
    "                a_state += self.ou_sigma * np.random.normal(size=action.shape)\n",
    "\n",
    "                action += self.ou_epsilon * a_state\n",
    "                new_a_states.append(a_state)\n",
    "        else:\n",
    "            new_a_states = agent_states\n",
    "\n",
    "        actions = np.clip(actions, -1, 1)\n",
    "        return actions, new_a_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpack_batch(batch, device=\"cpu\"):\n",
    "    states, actions, rewards, dones, last_states = [], [], [], [], []\n",
    "    for exp in batch:\n",
    "        states.append(exp.state)\n",
    "        actions.append(exp.action)\n",
    "        rewards.append(exp.reward)\n",
    "        dones.append(exp.last_state is None)\n",
    "        if exp.last_state is None:\n",
    "            last_states.append(exp.state)\n",
    "        else:\n",
    "            last_states.append(exp.last_state)\n",
    "    states_v = ptan.agent.float32_preprocessor(states).to(device)\n",
    "    actions_v = ptan.agent.float32_preprocessor(actions).to(device)\n",
    "    rewards_v = ptan.agent.float32_preprocessor(rewards).to(device)\n",
    "    last_states_v = ptan.agent.float32_preprocessor(last_states).to(device)\n",
    "    dones_t = torch.BoolTensor(dones).to(device)\n",
    "    return states_v, actions_v, rewards_v, dones_t, last_states_v\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = AgentDDPG(actor_net, device=config.device,ou_teta=config.NOISE_THETA,ou_sigma=config.NOISE_SIGMA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_source = UnityExperienceSourceFirstLast(env, agent, gamma=config.GAMMA, steps_count=1)\n",
    "buffer = ptan.experience.ExperienceReplayBuffer(exp_source, buffer_size=config.BUFFER_SIZE)\n",
    "act_opt = optim.Adam(actor_net.parameters(), lr=config.LR_ACTOR)\n",
    "crt_opt = optim.Adam(critic_net.parameters(), lr=config.LR_CRITIC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7997: done 10 episodes, mean reward 0.534, speed 181.04 f/s\n",
      "11997: done 19 episodes, mean reward 0.677, speed 81.53 f/s\n",
      "15997: done 28 episodes, mean reward 0.633, speed 83.32 f/s\n",
      "19997: done 37 episodes, mean reward 0.596, speed 88.44 f/s\n",
      "23997: done 46 episodes, mean reward 0.674, speed 83.07 f/s\n",
      "27997: done 55 episodes, mean reward 0.644, speed 78.69 f/s\n",
      "31997: done 64 episodes, mean reward 0.637, speed 79.18 f/s\n",
      "35997: done 73 episodes, mean reward 0.650, speed 79.69 f/s\n",
      "39997: done 82 episodes, mean reward 0.649, speed 81.86 f/s\n",
      "43997: done 91 episodes, mean reward 0.663, speed 78.03 f/s\n",
      "47997: done 100 episodes, mean reward 0.661, speed 76.26 f/s\n",
      "51997: done 109 episodes, mean reward 0.698, speed 80.74 f/s\n",
      "55997: done 118 episodes, mean reward 0.679, speed 84.72 f/s\n",
      "59997: done 127 episodes, mean reward 0.681, speed 85.81 f/s\n",
      "63997: done 136 episodes, mean reward 0.726, speed 79.72 f/s\n",
      "67997: done 145 episodes, mean reward 0.719, speed 82.49 f/s\n",
      "71997: done 154 episodes, mean reward 0.751, speed 82.95 f/s\n",
      "75997: done 163 episodes, mean reward 0.856, speed 82.37 f/s\n",
      "79997: done 172 episodes, mean reward 0.883, speed 83.36 f/s\n",
      "83997: done 181 episodes, mean reward 0.969, speed 81.98 f/s\n",
      "87997: done 190 episodes, mean reward 0.989, speed 76.11 f/s\n",
      "91997: done 199 episodes, mean reward 1.047, speed 77.01 f/s\n",
      "95997: done 208 episodes, mean reward 1.042, speed 82.14 f/s\n",
      "99997: done 217 episodes, mean reward 1.081, speed 82.87 f/s\n",
      "103997: done 226 episodes, mean reward 1.099, speed 82.56 f/s\n",
      "107997: done 235 episodes, mean reward 1.123, speed 82.07 f/s\n",
      "111997: done 244 episodes, mean reward 1.126, speed 94.41 f/s\n",
      "119997: done 262 episodes, mean reward 1.071, speed 166.16 f/s\n",
      "127997: done 280 episodes, mean reward 1.032, speed 157.36 f/s\n",
      "135997: done 298 episodes, mean reward 1.020, speed 154.96 f/s\n",
      "143997: done 316 episodes, mean reward 1.005, speed 150.94 f/s\n",
      "151997: done 334 episodes, mean reward 0.988, speed 150.19 f/s\n",
      "159997: done 352 episodes, mean reward 1.041, speed 149.76 f/s\n",
      "167997: done 370 episodes, mean reward 1.085, speed 147.53 f/s\n",
      "175997: done 388 episodes, mean reward 1.184, speed 136.45 f/s\n",
      "179997: done 397 episodes, mean reward 1.229, speed 119.09 f/s\n",
      "183997: done 406 episodes, mean reward 1.217, speed 109.76 f/s\n",
      "187997: done 415 episodes, mean reward 1.263, speed 102.26 f/s\n",
      "191997: done 424 episodes, mean reward 1.332, speed 91.14 f/s\n",
      "195997: done 433 episodes, mean reward 1.353, speed 85.78 f/s\n",
      "199997: done 442 episodes, mean reward 1.415, speed 81.78 f/s\n",
      "203997: done 451 episodes, mean reward 1.403, speed 81.09 f/s\n",
      "207997: done 460 episodes, mean reward 1.355, speed 80.09 f/s\n",
      "211997: done 469 episodes, mean reward 1.342, speed 83.44 f/s\n",
      "215997: done 478 episodes, mean reward 1.266, speed 81.13 f/s\n",
      "219997: done 487 episodes, mean reward 1.205, speed 81.38 f/s\n",
      "223997: done 496 episodes, mean reward 1.119, speed 83.05 f/s\n",
      "227997: done 505 episodes, mean reward 1.131, speed 81.58 f/s\n",
      "231997: done 514 episodes, mean reward 1.093, speed 81.12 f/s\n",
      "235997: done 523 episodes, mean reward 1.084, speed 82.47 f/s\n",
      "239997: done 532 episodes, mean reward 1.033, speed 81.15 f/s\n",
      "243997: done 541 episodes, mean reward 0.992, speed 84.05 f/s\n",
      "247997: done 550 episodes, mean reward 0.949, speed 83.39 f/s\n",
      "251997: done 559 episodes, mean reward 0.938, speed 82.50 f/s\n",
      "255997: done 568 episodes, mean reward 1.007, speed 81.62 f/s\n",
      "259997: done 577 episodes, mean reward 1.064, speed 81.79 f/s\n",
      "263997: done 586 episodes, mean reward 1.102, speed 80.35 f/s\n",
      "267997: done 595 episodes, mean reward 1.142, speed 82.85 f/s\n",
      "271997: done 604 episodes, mean reward 1.185, speed 83.53 f/s\n",
      "275997: done 613 episodes, mean reward 1.219, speed 82.47 f/s\n",
      "279997: done 622 episodes, mean reward 1.325, speed 81.52 f/s\n",
      "283997: done 631 episodes, mean reward 1.539, speed 81.41 f/s\n",
      "287997: done 640 episodes, mean reward 1.695, speed 80.21 f/s\n",
      "291997: done 649 episodes, mean reward 1.751, speed 81.85 f/s\n",
      "295997: done 658 episodes, mean reward 1.806, speed 84.01 f/s\n",
      "299997: done 667 episodes, mean reward 1.862, speed 82.22 f/s\n",
      "303997: done 676 episodes, mean reward 1.874, speed 78.89 f/s\n",
      "307997: done 685 episodes, mean reward 1.899, speed 81.83 f/s\n",
      "311997: done 694 episodes, mean reward 1.990, speed 83.75 f/s\n",
      "315997: done 703 episodes, mean reward 2.045, speed 78.54 f/s\n",
      "319997: done 712 episodes, mean reward 2.177, speed 81.43 f/s\n",
      "323997: done 721 episodes, mean reward 2.217, speed 82.02 f/s\n",
      "327997: done 730 episodes, mean reward 2.124, speed 94.06 f/s\n",
      "335997: done 748 episodes, mean reward 2.179, speed 166.09 f/s\n",
      "343997: done 766 episodes, mean reward 2.233, speed 155.37 f/s\n",
      "351997: done 784 episodes, mean reward 2.484, speed 152.39 f/s\n",
      "359997: done 802 episodes, mean reward 2.571, speed 150.27 f/s\n",
      "367997: done 820 episodes, mean reward 2.380, speed 148.85 f/s\n",
      "375997: done 838 episodes, mean reward 2.363, speed 147.91 f/s\n",
      "383997: done 856 episodes, mean reward 2.428, speed 146.71 f/s\n",
      "391997: done 874 episodes, mean reward 2.278, speed 145.94 f/s\n",
      "395997: done 883 episodes, mean reward 2.123, speed 132.29 f/s\n",
      "399997: done 892 episodes, mean reward 2.101, speed 114.72 f/s\n",
      "403997: done 901 episodes, mean reward 1.999, speed 106.69 f/s\n",
      "407997: done 910 episodes, mean reward 1.913, speed 99.37 f/s\n",
      "411997: done 919 episodes, mean reward 2.024, speed 89.52 f/s\n",
      "415997: done 928 episodes, mean reward 2.058, speed 83.29 f/s\n",
      "419997: done 937 episodes, mean reward 2.145, speed 79.46 f/s\n",
      "423997: done 946 episodes, mean reward 2.209, speed 82.90 f/s\n",
      "427997: done 955 episodes, mean reward 2.218, speed 79.02 f/s\n",
      "431997: done 964 episodes, mean reward 2.334, speed 79.17 f/s\n",
      "435997: done 973 episodes, mean reward 2.577, speed 82.18 f/s\n",
      "439997: done 982 episodes, mean reward 2.971, speed 79.07 f/s\n",
      "443997: done 991 episodes, mean reward 3.461, speed 81.85 f/s\n",
      "447997: done 1000 episodes, mean reward 3.670, speed 82.95 f/s\n",
      "451997: done 1009 episodes, mean reward 3.999, speed 77.91 f/s\n",
      "455997: done 1018 episodes, mean reward 4.349, speed 83.04 f/s\n",
      "459997: done 1027 episodes, mean reward 4.673, speed 82.65 f/s\n",
      "463997: done 1036 episodes, mean reward 5.061, speed 80.68 f/s\n",
      "467997: done 1045 episodes, mean reward 5.337, speed 81.16 f/s\n",
      "471997: done 1054 episodes, mean reward 5.953, speed 77.16 f/s\n",
      "475997: done 1063 episodes, mean reward 6.460, speed 81.74 f/s\n",
      "479997: done 1072 episodes, mean reward 6.821, speed 83.21 f/s\n",
      "483997: done 1081 episodes, mean reward 7.078, speed 81.91 f/s\n",
      "487997: done 1090 episodes, mean reward 7.127, speed 79.39 f/s\n",
      "491997: done 1099 episodes, mean reward 7.451, speed 82.56 f/s\n",
      "495997: done 1108 episodes, mean reward 7.828, speed 82.97 f/s\n",
      "499997: done 1117 episodes, mean reward 7.985, speed 78.55 f/s\n",
      "503997: done 1126 episodes, mean reward 8.027, speed 81.44 f/s\n",
      "507997: done 1135 episodes, mean reward 8.109, speed 82.69 f/s\n",
      "511997: done 1144 episodes, mean reward 8.551, speed 79.88 f/s\n",
      "515997: done 1153 episodes, mean reward 8.596, speed 77.03 f/s\n",
      "519997: done 1162 episodes, mean reward 8.584, speed 82.73 f/s\n",
      "523997: done 1171 episodes, mean reward 8.738, speed 82.92 f/s\n",
      "527997: done 1180 episodes, mean reward 8.847, speed 79.56 f/s\n",
      "531997: done 1189 episodes, mean reward 8.938, speed 80.38 f/s\n",
      "535997: done 1198 episodes, mean reward 9.020, speed 83.41 f/s\n",
      "539997: done 1207 episodes, mean reward 8.889, speed 80.00 f/s\n",
      "543997: done 1216 episodes, mean reward 9.082, speed 78.35 f/s\n",
      "547997: done 1225 episodes, mean reward 9.493, speed 82.83 f/s\n",
      "551997: done 1234 episodes, mean reward 9.718, speed 81.42 f/s\n",
      "555997: done 1243 episodes, mean reward 9.735, speed 97.36 f/s\n",
      "563997: done 1261 episodes, mean reward 10.221, speed 165.09 f/s\n",
      "571997: done 1279 episodes, mean reward 10.380, speed 154.84 f/s\n",
      "579997: done 1297 episodes, mean reward 10.751, speed 151.90 f/s\n",
      "587997: done 1315 episodes, mean reward 10.887, speed 149.25 f/s\n",
      "595997: done 1333 episodes, mean reward 10.938, speed 148.09 f/s\n",
      "603997: done 1351 episodes, mean reward 11.162, speed 142.39 f/s\n",
      "611997: done 1369 episodes, mean reward 11.053, speed 143.60 f/s\n",
      "619997: done 1387 episodes, mean reward 11.290, speed 138.45 f/s\n",
      "623997: done 1396 episodes, mean reward 11.534, speed 118.15 f/s\n",
      "627997: done 1405 episodes, mean reward 11.784, speed 110.43 f/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "631997: done 1414 episodes, mean reward 12.041, speed 105.11 f/s\n",
      "635997: done 1423 episodes, mean reward 12.317, speed 89.48 f/s\n",
      "639997: done 1432 episodes, mean reward 12.644, speed 44.05 f/s\n",
      "643997: done 1441 episodes, mean reward 12.570, speed 46.76 f/s\n",
      "647997: done 1450 episodes, mean reward 12.688, speed 53.70 f/s\n",
      "651997: done 1459 episodes, mean reward 12.734, speed 49.74 f/s\n",
      "655997: done 1468 episodes, mean reward 12.806, speed 47.24 f/s\n",
      "659997: done 1477 episodes, mean reward 12.998, speed 55.67 f/s\n",
      "663997: done 1486 episodes, mean reward 12.748, speed 36.70 f/s\n",
      "667997: done 1495 episodes, mean reward 12.737, speed 62.23 f/s\n",
      "671997: done 1504 episodes, mean reward 12.821, speed 68.91 f/s\n",
      "675997: done 1513 episodes, mean reward 13.082, speed 41.15 f/s\n",
      "679997: done 1522 episodes, mean reward 12.940, speed 44.08 f/s\n",
      "683997: done 1531 episodes, mean reward 12.802, speed 58.14 f/s\n",
      "687997: done 1540 episodes, mean reward 12.827, speed 67.52 f/s\n",
      "691997: done 1549 episodes, mean reward 13.116, speed 57.50 f/s\n",
      "695997: done 1558 episodes, mean reward 13.249, speed 55.21 f/s\n",
      "699997: done 1567 episodes, mean reward 13.472, speed 64.27 f/s\n",
      "703997: done 1576 episodes, mean reward 13.361, speed 61.58 f/s\n",
      "707997: done 1585 episodes, mean reward 13.483, speed 56.14 f/s\n",
      "711997: done 1594 episodes, mean reward 13.653, speed 57.36 f/s\n",
      "715997: done 1603 episodes, mean reward 13.601, speed 46.62 f/s\n",
      "719997: done 1612 episodes, mean reward 13.577, speed 46.88 f/s\n",
      "723997: done 1621 episodes, mean reward 13.708, speed 44.67 f/s\n",
      "727997: done 1630 episodes, mean reward 14.004, speed 61.39 f/s\n",
      "731997: done 1639 episodes, mean reward 14.477, speed 116.86 f/s\n",
      "739997: done 1657 episodes, mean reward 14.723, speed 160.97 f/s\n",
      "747997: done 1675 episodes, mean reward 14.736, speed 148.23 f/s\n",
      "755997: done 1693 episodes, mean reward 15.314, speed 146.22 f/s\n",
      "763997: done 1711 episodes, mean reward 15.620, speed 148.10 f/s\n",
      "771997: done 1729 episodes, mean reward 15.937, speed 142.43 f/s\n",
      "775997: done 1738 episodes, mean reward 15.851, speed 131.48 f/s\n",
      "779997: done 1747 episodes, mean reward 15.978, speed 126.79 f/s\n",
      "783997: done 1756 episodes, mean reward 16.008, speed 124.11 f/s\n",
      "787997: done 1765 episodes, mean reward 16.185, speed 128.75 f/s\n",
      "791997: done 1774 episodes, mean reward 16.723, speed 100.65 f/s\n",
      "795997: done 1783 episodes, mean reward 16.776, speed 76.22 f/s\n",
      "799997: done 1792 episodes, mean reward 16.927, speed 53.86 f/s\n",
      "803997: done 1801 episodes, mean reward 16.374, speed 41.24 f/s\n",
      "807997: done 1810 episodes, mean reward 16.697, speed 45.00 f/s\n",
      "811997: done 1819 episodes, mean reward 16.798, speed 39.37 f/s\n",
      "815997: done 1828 episodes, mean reward 16.752, speed 67.16 f/s\n",
      "819997: done 1837 episodes, mean reward 16.680, speed 69.38 f/s\n",
      "823997: done 1846 episodes, mean reward 16.671, speed 59.18 f/s\n",
      "827997: done 1855 episodes, mean reward 16.965, speed 61.61 f/s\n",
      "831997: done 1864 episodes, mean reward 16.972, speed 62.41 f/s\n",
      "835997: done 1873 episodes, mean reward 16.525, speed 59.20 f/s\n",
      "839997: done 1882 episodes, mean reward 16.483, speed 59.24 f/s\n",
      "843997: done 1891 episodes, mean reward 16.353, speed 58.64 f/s\n",
      "847997: done 1900 episodes, mean reward 16.367, speed 49.55 f/s\n",
      "851997: done 1909 episodes, mean reward 16.375, speed 37.66 f/s\n",
      "855997: done 1918 episodes, mean reward 16.576, speed 52.54 f/s\n",
      "859997: done 1927 episodes, mean reward 16.347, speed 59.13 f/s\n",
      "863997: done 1936 episodes, mean reward 16.301, speed 62.70 f/s\n",
      "867997: done 1945 episodes, mean reward 16.128, speed 70.49 f/s\n",
      "871997: done 1954 episodes, mean reward 15.905, speed 49.03 f/s\n",
      "875997: done 1963 episodes, mean reward 15.844, speed 38.90 f/s\n",
      "879997: done 1972 episodes, mean reward 15.873, speed 44.89 f/s\n",
      "883997: done 1981 episodes, mean reward 15.437, speed 45.59 f/s\n",
      "887997: done 1990 episodes, mean reward 15.493, speed 44.73 f/s\n",
      "891997: done 1999 episodes, mean reward 15.564, speed 62.85 f/s\n",
      "899997: done 2017 episodes, mean reward 14.947, speed 161.60 f/s\n",
      "907997: done 2035 episodes, mean reward 14.718, speed 151.55 f/s\n",
      "915997: done 2053 episodes, mean reward 14.827, speed 149.16 f/s\n",
      "923997: done 2071 episodes, mean reward 15.237, speed 145.09 f/s\n",
      "927997: done 2080 episodes, mean reward 15.482, speed 126.22 f/s\n",
      "931997: done 2089 episodes, mean reward 15.478, speed 120.34 f/s\n",
      "935997: done 2098 episodes, mean reward 15.697, speed 124.38 f/s\n",
      "939997: done 2107 episodes, mean reward 15.937, speed 121.39 f/s\n",
      "943997: done 2116 episodes, mean reward 16.144, speed 126.41 f/s\n",
      "947997: done 2125 episodes, mean reward 16.383, speed 131.80 f/s\n",
      "951997: done 2134 episodes, mean reward 16.689, speed 102.69 f/s\n",
      "955997: done 2143 episodes, mean reward 17.035, speed 81.83 f/s\n",
      "959997: done 2152 episodes, mean reward 16.804, speed 53.75 f/s\n",
      "963997: done 2161 episodes, mean reward 16.706, speed 32.85 f/s\n",
      "967997: done 2170 episodes, mean reward 16.750, speed 35.76 f/s\n",
      "971997: done 2179 episodes, mean reward 16.789, speed 39.54 f/s\n",
      "975997: done 2188 episodes, mean reward 16.736, speed 35.72 f/s\n",
      "979997: done 2197 episodes, mean reward 16.845, speed 37.19 f/s\n",
      "983997: done 2206 episodes, mean reward 17.073, speed 35.86 f/s\n",
      "987997: done 2215 episodes, mean reward 17.218, speed 35.12 f/s\n",
      "991997: done 2224 episodes, mean reward 17.122, speed 34.84 f/s\n",
      "995997: done 2233 episodes, mean reward 17.163, speed 34.59 f/s\n",
      "999997: done 2242 episodes, mean reward 16.886, speed 33.35 f/s\n",
      "1003997: done 2251 episodes, mean reward 16.860, speed 34.07 f/s\n",
      "1007997: done 2260 episodes, mean reward 16.797, speed 34.26 f/s\n",
      "1011997: done 2269 episodes, mean reward 16.637, speed 40.02 f/s\n",
      "1015997: done 2278 episodes, mean reward 16.644, speed 40.12 f/s\n",
      "1019997: done 2287 episodes, mean reward 16.675, speed 36.20 f/s\n",
      "1023997: done 2296 episodes, mean reward 16.563, speed 39.70 f/s\n",
      "1027997: done 2305 episodes, mean reward 16.512, speed 78.50 f/s\n",
      "1035997: done 2323 episodes, mean reward 15.998, speed 144.24 f/s\n",
      "1039997: done 2332 episodes, mean reward 15.738, speed 131.85 f/s\n",
      "1047997: done 2350 episodes, mean reward 15.891, speed 133.84 f/s\n",
      "1051997: done 2359 episodes, mean reward 15.858, speed 129.15 f/s\n",
      "1055997: done 2368 episodes, mean reward 15.928, speed 130.87 f/s\n",
      "1059997: done 2377 episodes, mean reward 16.107, speed 130.19 f/s\n",
      "1063997: done 2386 episodes, mean reward 15.997, speed 130.37 f/s\n",
      "1067997: done 2395 episodes, mean reward 15.999, speed 127.78 f/s\n",
      "1071997: done 2404 episodes, mean reward 15.897, speed 126.06 f/s\n",
      "1075997: done 2413 episodes, mean reward 16.169, speed 129.31 f/s\n",
      "1079997: done 2422 episodes, mean reward 16.006, speed 128.30 f/s\n",
      "1083997: done 2431 episodes, mean reward 16.255, speed 114.82 f/s\n",
      "1087997: done 2440 episodes, mean reward 16.173, speed 106.95 f/s\n",
      "1091997: done 2449 episodes, mean reward 16.065, speed 99.82 f/s\n",
      "1095997: done 2458 episodes, mean reward 16.342, speed 89.76 f/s\n",
      "1099997: done 2467 episodes, mean reward 16.546, speed 78.67 f/s\n",
      "1103997: done 2476 episodes, mean reward 16.038, speed 77.53 f/s\n",
      "1107997: done 2485 episodes, mean reward 16.110, speed 76.01 f/s\n",
      "1111997: done 2494 episodes, mean reward 16.119, speed 76.58 f/s\n",
      "1115997: done 2503 episodes, mean reward 16.208, speed 76.38 f/s\n",
      "1119997: done 2512 episodes, mean reward 16.009, speed 77.43 f/s\n",
      "1123997: done 2521 episodes, mean reward 16.032, speed 83.93 f/s\n",
      "1127997: done 2530 episodes, mean reward 15.978, speed 76.25 f/s\n",
      "1131997: done 2539 episodes, mean reward 15.900, speed 76.52 f/s\n",
      "1135997: done 2548 episodes, mean reward 16.079, speed 81.22 f/s\n",
      "1139997: done 2557 episodes, mean reward 15.825, speed 80.41 f/s\n",
      "1143997: done 2566 episodes, mean reward 15.472, speed 79.10 f/s\n",
      "1147997: done 2575 episodes, mean reward 15.780, speed 77.95 f/s\n",
      "1151997: done 2584 episodes, mean reward 15.588, speed 84.19 f/s\n",
      "1155997: done 2593 episodes, mean reward 15.688, speed 84.05 f/s\n",
      "1159997: done 2602 episodes, mean reward 15.711, speed 81.32 f/s\n",
      "1163997: done 2611 episodes, mean reward 15.752, speed 86.11 f/s\n",
      "1167997: done 2620 episodes, mean reward 15.699, speed 88.63 f/s\n",
      "1171997: done 2629 episodes, mean reward 15.639, speed 85.20 f/s\n",
      "1175997: done 2638 episodes, mean reward 15.565, speed 83.90 f/s\n",
      "1179997: done 2647 episodes, mean reward 15.419, speed 83.57 f/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1183997: done 2656 episodes, mean reward 15.762, speed 89.91 f/s\n",
      "1187997: done 2665 episodes, mean reward 15.591, speed 85.19 f/s\n",
      "1191997: done 2674 episodes, mean reward 15.635, speed 83.72 f/s\n",
      "1195997: done 2683 episodes, mean reward 15.870, speed 82.90 f/s\n",
      "1199997: done 2692 episodes, mean reward 15.985, speed 80.01 f/s\n",
      "1203997: done 2701 episodes, mean reward 15.987, speed 80.18 f/s\n",
      "1207997: done 2710 episodes, mean reward 16.270, speed 78.35 f/s\n",
      "1211997: done 2719 episodes, mean reward 16.585, speed 79.30 f/s\n",
      "1215997: done 2728 episodes, mean reward 16.610, speed 80.81 f/s\n",
      "1219997: done 2737 episodes, mean reward 16.594, speed 75.47 f/s\n",
      "1223997: done 2746 episodes, mean reward 16.842, speed 73.30 f/s\n",
      "1227997: done 2755 episodes, mean reward 16.862, speed 78.16 f/s\n",
      "1231997: done 2764 episodes, mean reward 16.983, speed 80.85 f/s\n",
      "1235997: done 2773 episodes, mean reward 16.642, speed 78.11 f/s\n",
      "1243997: done 2791 episodes, mean reward 16.255, speed 161.48 f/s\n",
      "1251997: done 2809 episodes, mean reward 16.292, speed 154.73 f/s\n",
      "1259997: done 2827 episodes, mean reward 16.058, speed 143.56 f/s\n",
      "1267997: done 2845 episodes, mean reward 16.456, speed 141.74 f/s\n",
      "1275997: done 2863 episodes, mean reward 16.137, speed 141.38 f/s\n",
      "1283997: done 2881 episodes, mean reward 16.447, speed 141.52 f/s\n",
      "1291997: done 2899 episodes, mean reward 16.512, speed 143.55 f/s\n",
      "1299997: done 2917 episodes, mean reward 15.832, speed 128.09 f/s\n",
      "1303997: done 2926 episodes, mean reward 16.005, speed 109.54 f/s\n",
      "1307997: done 2935 episodes, mean reward 15.827, speed 101.75 f/s\n",
      "1311997: done 2944 episodes, mean reward 15.778, speed 88.55 f/s\n",
      "1315997: done 2953 episodes, mean reward 15.845, speed 78.45 f/s\n",
      "1319997: done 2962 episodes, mean reward 15.932, speed 68.88 f/s\n",
      "1323997: done 2971 episodes, mean reward 15.911, speed 59.67 f/s\n",
      "1327997: done 2980 episodes, mean reward 16.201, speed 74.37 f/s\n",
      "1331997: done 2989 episodes, mean reward 16.241, speed 76.46 f/s\n",
      "1335997: done 2998 episodes, mean reward 16.376, speed 73.94 f/s\n",
      "1339997: done 3007 episodes, mean reward 16.675, speed 71.86 f/s\n",
      "1343997: done 3016 episodes, mean reward 16.772, speed 56.54 f/s\n",
      "1347997: done 3025 episodes, mean reward 16.905, speed 39.06 f/s\n",
      "1351997: done 3034 episodes, mean reward 16.647, speed 48.69 f/s\n",
      "1355997: done 3043 episodes, mean reward 16.589, speed 34.88 f/s\n",
      "1359997: done 3052 episodes, mean reward 16.663, speed 47.70 f/s\n",
      "1363997: done 3061 episodes, mean reward 16.446, speed 55.51 f/s\n",
      "1367997: done 3070 episodes, mean reward 16.160, speed 47.55 f/s\n",
      "1371997: done 3079 episodes, mean reward 15.892, speed 52.32 f/s\n",
      "1375997: done 3088 episodes, mean reward 15.899, speed 45.43 f/s\n",
      "1379997: done 3097 episodes, mean reward 15.799, speed 53.14 f/s\n",
      "1383997: done 3106 episodes, mean reward 15.442, speed 61.41 f/s\n",
      "1387997: done 3115 episodes, mean reward 15.400, speed 79.27 f/s\n",
      "1391997: done 3124 episodes, mean reward 15.189, speed 79.51 f/s\n",
      "1395997: done 3133 episodes, mean reward 15.441, speed 76.23 f/s\n",
      "1399997: done 3142 episodes, mean reward 15.478, speed 77.57 f/s\n",
      "1403997: done 3151 episodes, mean reward 15.155, speed 73.54 f/s\n",
      "1407997: done 3160 episodes, mean reward 15.098, speed 76.05 f/s\n",
      "1411997: done 3169 episodes, mean reward 15.324, speed 77.85 f/s\n",
      "1415997: done 3178 episodes, mean reward 15.494, speed 76.14 f/s\n",
      "1419997: done 3187 episodes, mean reward 15.622, speed 76.05 f/s\n",
      "1423997: done 3196 episodes, mean reward 15.495, speed 122.52 f/s\n",
      "1431997: done 3214 episodes, mean reward 15.622, speed 164.04 f/s\n",
      "1439997: done 3232 episodes, mean reward 15.643, speed 148.49 f/s\n",
      "1447997: done 3250 episodes, mean reward 15.700, speed 150.71 f/s\n",
      "1455997: done 3268 episodes, mean reward 16.143, speed 146.77 f/s\n",
      "1463997: done 3286 episodes, mean reward 16.372, speed 149.31 f/s\n",
      "1471997: done 3304 episodes, mean reward 16.203, speed 141.21 f/s\n",
      "1479997: done 3322 episodes, mean reward 16.281, speed 145.67 f/s\n",
      "1483997: done 3331 episodes, mean reward 16.401, speed 118.77 f/s\n",
      "1487997: done 3340 episodes, mean reward 16.073, speed 107.42 f/s\n",
      "1491997: done 3349 episodes, mean reward 16.077, speed 99.43 f/s\n",
      "1495997: done 3358 episodes, mean reward 15.759, speed 83.02 f/s\n",
      "1499997: done 3367 episodes, mean reward 15.419, speed 69.45 f/s\n",
      "1503997: done 3376 episodes, mean reward 15.187, speed 66.92 f/s\n",
      "1507997: done 3385 episodes, mean reward 15.089, speed 58.98 f/s\n",
      "1511997: done 3394 episodes, mean reward 14.805, speed 44.11 f/s\n",
      "1515997: done 3403 episodes, mean reward 14.754, speed 59.25 f/s\n",
      "1519997: done 3412 episodes, mean reward 14.950, speed 84.47 f/s\n",
      "1523997: done 3421 episodes, mean reward 14.846, speed 87.41 f/s\n",
      "1527997: done 3430 episodes, mean reward 14.438, speed 83.06 f/s\n",
      "1531997: done 3439 episodes, mean reward 14.350, speed 79.42 f/s\n",
      "1535997: done 3448 episodes, mean reward 14.335, speed 82.96 f/s\n",
      "1539997: done 3457 episodes, mean reward 14.856, speed 82.85 f/s\n",
      "1543997: done 3466 episodes, mean reward 14.901, speed 82.48 f/s\n",
      "1547997: done 3475 episodes, mean reward 14.989, speed 81.27 f/s\n",
      "1551997: done 3484 episodes, mean reward 14.966, speed 79.08 f/s\n",
      "1555997: done 3493 episodes, mean reward 15.263, speed 77.93 f/s\n",
      "1559997: done 3502 episodes, mean reward 15.177, speed 83.39 f/s\n",
      "1563997: done 3511 episodes, mean reward 14.928, speed 84.16 f/s\n",
      "1567997: done 3520 episodes, mean reward 14.915, speed 83.20 f/s\n",
      "1571997: done 3529 episodes, mean reward 14.954, speed 79.56 f/s\n",
      "1575997: done 3538 episodes, mean reward 15.190, speed 83.26 f/s\n",
      "1579997: done 3547 episodes, mean reward 15.499, speed 83.79 f/s\n",
      "1583997: done 3556 episodes, mean reward 15.580, speed 79.45 f/s\n",
      "1587997: done 3565 episodes, mean reward 15.540, speed 79.30 f/s\n",
      "1591997: done 3574 episodes, mean reward 15.632, speed 83.06 f/s\n",
      "1595997: done 3583 episodes, mean reward 16.108, speed 88.95 f/s\n",
      "1599997: done 3592 episodes, mean reward 16.047, speed 85.80 f/s\n",
      "1603997: done 3601 episodes, mean reward 16.389, speed 83.86 f/s\n",
      "1607997: done 3610 episodes, mean reward 16.269, speed 83.03 f/s\n",
      "1611997: done 3619 episodes, mean reward 16.464, speed 89.67 f/s\n",
      "1615997: done 3628 episodes, mean reward 16.731, speed 84.86 f/s\n",
      "1619997: done 3637 episodes, mean reward 16.666, speed 84.31 f/s\n",
      "1623997: done 3646 episodes, mean reward 16.611, speed 84.38 f/s\n",
      "1627997: done 3655 episodes, mean reward 16.485, speed 82.86 f/s\n",
      "1631997: done 3664 episodes, mean reward 16.779, speed 87.52 f/s\n",
      "1635997: done 3673 episodes, mean reward 16.415, speed 108.99 f/s\n",
      "1643997: done 3691 episodes, mean reward 16.265, speed 166.46 f/s\n",
      "1651997: done 3709 episodes, mean reward 15.584, speed 158.37 f/s\n",
      "1659997: done 3727 episodes, mean reward 15.344, speed 153.99 f/s\n",
      "1667997: done 3745 episodes, mean reward 15.142, speed 152.57 f/s\n",
      "1675997: done 3763 episodes, mean reward 15.173, speed 148.27 f/s\n",
      "1683997: done 3781 episodes, mean reward 15.020, speed 149.15 f/s\n",
      "1691997: done 3799 episodes, mean reward 15.248, speed 147.75 f/s\n",
      "1699997: done 3817 episodes, mean reward 15.208, speed 139.16 f/s\n",
      "1703997: done 3826 episodes, mean reward 15.389, speed 115.49 f/s\n",
      "1707997: done 3835 episodes, mean reward 15.015, speed 110.00 f/s\n",
      "1711997: done 3844 episodes, mean reward 15.106, speed 98.58 f/s\n",
      "1715997: done 3853 episodes, mean reward 14.915, speed 85.95 f/s\n",
      "1719997: done 3862 episodes, mean reward 14.585, speed 74.81 f/s\n",
      "1723997: done 3871 episodes, mean reward 14.483, speed 77.93 f/s\n",
      "1727997: done 3880 episodes, mean reward 14.417, speed 77.87 f/s\n",
      "1731997: done 3889 episodes, mean reward 14.481, speed 75.51 f/s\n",
      "1735997: done 3898 episodes, mean reward 14.428, speed 77.05 f/s\n",
      "1739997: done 3907 episodes, mean reward 14.357, speed 74.65 f/s\n",
      "1743997: done 3916 episodes, mean reward 14.484, speed 72.95 f/s\n",
      "1747997: done 3925 episodes, mean reward 14.424, speed 79.69 f/s\n",
      "1751997: done 3934 episodes, mean reward 14.596, speed 79.43 f/s\n",
      "1755997: done 3943 episodes, mean reward 14.833, speed 75.67 f/s\n",
      "1759997: done 3952 episodes, mean reward 14.956, speed 72.63 f/s\n",
      "1763997: done 3961 episodes, mean reward 15.481, speed 81.67 f/s\n",
      "1767997: done 3970 episodes, mean reward 15.639, speed 79.87 f/s\n",
      "1771997: done 3979 episodes, mean reward 16.057, speed 76.73 f/s\n",
      "1775997: done 3988 episodes, mean reward 16.014, speed 76.32 f/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1779997: done 3997 episodes, mean reward 16.200, speed 72.90 f/s\n",
      "1783997: done 4006 episodes, mean reward 16.519, speed 76.83 f/s\n",
      "1787997: done 4015 episodes, mean reward 16.610, speed 78.90 f/s\n",
      "1791997: done 4024 episodes, mean reward 16.421, speed 77.49 f/s\n",
      "1795997: done 4033 episodes, mean reward 16.460, speed 73.45 f/s\n",
      "1799997: done 4042 episodes, mean reward 16.012, speed 76.28 f/s\n",
      "1803997: done 4051 episodes, mean reward 15.973, speed 80.58 f/s\n",
      "1807997: done 4060 episodes, mean reward 15.817, speed 77.32 f/s\n",
      "1811997: done 4069 episodes, mean reward 16.129, speed 73.53 f/s\n",
      "1815997: done 4078 episodes, mean reward 16.067, speed 73.76 f/s\n",
      "1819997: done 4087 episodes, mean reward 16.257, speed 72.16 f/s\n",
      "1823997: done 4096 episodes, mean reward 16.191, speed 74.99 f/s\n",
      "1827997: done 4105 episodes, mean reward 16.133, speed 77.88 f/s\n",
      "1831997: done 4114 episodes, mean reward 15.949, speed 76.58 f/s\n",
      "1835997: done 4123 episodes, mean reward 16.375, speed 75.56 f/s\n",
      "1839997: done 4132 episodes, mean reward 16.576, speed 79.53 f/s\n",
      "1843997: done 4141 episodes, mean reward 16.814, speed 80.50 f/s\n",
      "1847997: done 4150 episodes, mean reward 16.747, speed 79.91 f/s\n",
      "1851997: done 4159 episodes, mean reward 16.946, speed 80.23 f/s\n",
      "1859997: done 4177 episodes, mean reward 16.713, speed 161.31 f/s\n",
      "1867997: done 4195 episodes, mean reward 16.839, speed 148.58 f/s\n",
      "1875997: done 4213 episodes, mean reward 17.165, speed 141.62 f/s\n",
      "1883997: done 4231 episodes, mean reward 16.997, speed 144.25 f/s\n",
      "1891997: done 4249 episodes, mean reward 17.587, speed 140.38 f/s\n",
      "1899997: done 4267 episodes, mean reward 18.233, speed 146.56 f/s\n",
      "1907997: done 4285 episodes, mean reward 18.426, speed 139.42 f/s\n",
      "1915997: done 4303 episodes, mean reward 18.156, speed 135.80 f/s\n",
      "1919997: done 4312 episodes, mean reward 18.162, speed 109.39 f/s\n",
      "1923997: done 4321 episodes, mean reward 18.450, speed 105.49 f/s\n",
      "1927997: done 4330 episodes, mean reward 18.430, speed 97.18 f/s\n",
      "1931997: done 4339 episodes, mean reward 18.572, speed 86.53 f/s\n",
      "1935997: done 4348 episodes, mean reward 18.342, speed 78.91 f/s\n",
      "1939997: done 4357 episodes, mean reward 18.129, speed 80.03 f/s\n",
      "1943997: done 4366 episodes, mean reward 17.696, speed 74.58 f/s\n",
      "1947997: done 4375 episodes, mean reward 17.905, speed 72.87 f/s\n",
      "1951997: done 4384 episodes, mean reward 17.821, speed 71.82 f/s\n",
      "1955997: done 4393 episodes, mean reward 17.923, speed 71.38 f/s\n",
      "1959997: done 4402 episodes, mean reward 18.408, speed 79.24 f/s\n",
      "1963997: done 4411 episodes, mean reward 18.342, speed 80.67 f/s\n",
      "1967997: done 4420 episodes, mean reward 18.622, speed 76.41 f/s\n",
      "1971997: done 4429 episodes, mean reward 18.606, speed 75.93 f/s\n",
      "1975997: done 4438 episodes, mean reward 18.494, speed 75.97 f/s\n",
      "1979997: done 4447 episodes, mean reward 18.338, speed 72.83 f/s\n",
      "1983997: done 4456 episodes, mean reward 18.516, speed 52.12 f/s\n",
      "1987997: done 4465 episodes, mean reward 18.498, speed 63.68 f/s\n",
      "1991997: done 4474 episodes, mean reward 18.551, speed 76.02 f/s\n",
      "1995997: done 4483 episodes, mean reward 18.707, speed 70.43 f/s\n",
      "1999997: done 4492 episodes, mean reward 18.659, speed 63.82 f/s\n",
      "2003997: done 4501 episodes, mean reward 18.252, speed 59.32 f/s\n",
      "2007997: done 4510 episodes, mean reward 18.418, speed 67.34 f/s\n",
      "2011997: done 4519 episodes, mean reward 18.091, speed 63.24 f/s\n",
      "2015997: done 4528 episodes, mean reward 18.158, speed 57.38 f/s\n",
      "2019997: done 4537 episodes, mean reward 18.480, speed 56.34 f/s\n",
      "2023997: done 4546 episodes, mean reward 18.451, speed 58.41 f/s\n",
      "2027997: done 4555 episodes, mean reward 18.224, speed 62.77 f/s\n",
      "2031997: done 4564 episodes, mean reward 18.274, speed 60.66 f/s\n",
      "2035997: done 4573 episodes, mean reward 18.473, speed 54.90 f/s\n",
      "2039997: done 4582 episodes, mean reward 18.451, speed 66.77 f/s\n",
      "2043997: done 4591 episodes, mean reward 18.439, speed 66.58 f/s\n",
      "2047997: done 4600 episodes, mean reward 18.274, speed 56.92 f/s\n",
      "2051997: done 4609 episodes, mean reward 17.794, speed 67.66 f/s\n",
      "2059997: done 4627 episodes, mean reward 18.021, speed 156.83 f/s\n",
      "2067997: done 4645 episodes, mean reward 17.534, speed 143.56 f/s\n",
      "2075997: done 4663 episodes, mean reward 17.693, speed 140.78 f/s\n",
      "2083997: done 4681 episodes, mean reward 17.119, speed 137.37 f/s\n",
      "2091997: done 4699 episodes, mean reward 17.458, speed 135.67 f/s\n",
      "2099997: done 4717 episodes, mean reward 17.438, speed 132.91 f/s\n",
      "2107997: done 4735 episodes, mean reward 17.400, speed 139.78 f/s\n",
      "2111997: done 4744 episodes, mean reward 17.491, speed 113.14 f/s\n",
      "2115997: done 4753 episodes, mean reward 17.270, speed 101.09 f/s\n",
      "2119997: done 4762 episodes, mean reward 17.361, speed 89.93 f/s\n",
      "2123997: done 4771 episodes, mean reward 17.497, speed 78.18 f/s\n",
      "2127997: done 4780 episodes, mean reward 17.287, speed 68.15 f/s\n",
      "2131997: done 4789 episodes, mean reward 17.607, speed 60.89 f/s\n",
      "2135997: done 4798 episodes, mean reward 17.472, speed 60.65 f/s\n",
      "2139997: done 4807 episodes, mean reward 17.912, speed 66.21 f/s\n",
      "2143997: done 4816 episodes, mean reward 17.851, speed 65.38 f/s\n",
      "2147997: done 4825 episodes, mean reward 17.681, speed 69.99 f/s\n",
      "2151997: done 4834 episodes, mean reward 17.497, speed 73.93 f/s\n",
      "2155997: done 4843 episodes, mean reward 16.977, speed 67.87 f/s\n",
      "2159997: done 4852 episodes, mean reward 17.218, speed 64.88 f/s\n",
      "2163997: done 4861 episodes, mean reward 17.460, speed 63.70 f/s\n",
      "2167997: done 4870 episodes, mean reward 17.497, speed 65.53 f/s\n",
      "2171997: done 4879 episodes, mean reward 17.897, speed 72.93 f/s\n",
      "2175997: done 4888 episodes, mean reward 17.630, speed 72.00 f/s\n",
      "2179997: done 4897 episodes, mean reward 17.704, speed 69.88 f/s\n",
      "2183997: done 4906 episodes, mean reward 17.400, speed 64.66 f/s\n",
      "2187997: done 4915 episodes, mean reward 17.524, speed 64.17 f/s\n",
      "2191997: done 4924 episodes, mean reward 17.737, speed 71.71 f/s\n",
      "2195997: done 4933 episodes, mean reward 18.183, speed 70.88 f/s\n",
      "2199997: done 4942 episodes, mean reward 18.546, speed 65.55 f/s\n",
      "2203997: done 4951 episodes, mean reward 18.900, speed 65.70 f/s\n",
      "2207997: done 4960 episodes, mean reward 19.130, speed 71.37 f/s\n",
      "2211997: done 4969 episodes, mean reward 19.064, speed 72.21 f/s\n",
      "2215997: done 4978 episodes, mean reward 18.782, speed 75.74 f/s\n",
      "2219997: done 4987 episodes, mean reward 19.206, speed 69.75 f/s\n",
      "2223997: done 4996 episodes, mean reward 19.099, speed 67.98 f/s\n",
      "2227997: done 5005 episodes, mean reward 19.338, speed 71.11 f/s\n",
      "2231997: done 5014 episodes, mean reward 18.743, speed 69.69 f/s\n",
      "2235997: done 5023 episodes, mean reward 18.579, speed 66.82 f/s\n",
      "2239997: done 5032 episodes, mean reward 18.334, speed 73.07 f/s\n",
      "2243997: done 5041 episodes, mean reward 18.213, speed 83.22 f/s\n",
      "2251997: done 5059 episodes, mean reward 17.512, speed 163.92 f/s\n",
      "2259997: done 5077 episodes, mean reward 17.806, speed 152.88 f/s\n",
      "2267997: done 5095 episodes, mean reward 17.830, speed 152.54 f/s\n",
      "2275997: done 5113 episodes, mean reward 18.526, speed 147.84 f/s\n",
      "2283997: done 5131 episodes, mean reward 18.669, speed 146.74 f/s\n",
      "2291997: done 5149 episodes, mean reward 18.977, speed 147.99 f/s\n",
      "2299997: done 5167 episodes, mean reward 19.462, speed 145.35 f/s\n",
      "2307997: done 5185 episodes, mean reward 19.293, speed 144.22 f/s\n",
      "2311997: done 5194 episodes, mean reward 19.254, speed 117.37 f/s\n",
      "2315997: done 5203 episodes, mean reward 19.669, speed 108.12 f/s\n",
      "2319997: done 5212 episodes, mean reward 19.571, speed 100.44 f/s\n",
      "2323997: done 5221 episodes, mean reward 19.353, speed 89.73 f/s\n",
      "2327997: done 5230 episodes, mean reward 19.835, speed 81.94 f/s\n",
      "2331997: done 5239 episodes, mean reward 19.320, speed 78.14 f/s\n",
      "2335997: done 5248 episodes, mean reward 19.882, speed 71.26 f/s\n",
      "2339997: done 5257 episodes, mean reward 20.154, speed 65.63 f/s\n",
      "2343997: done 5266 episodes, mean reward 20.124, speed 69.35 f/s\n",
      "2347997: done 5275 episodes, mean reward 19.838, speed 66.50 f/s\n",
      "2351997: done 5284 episodes, mean reward 19.975, speed 50.68 f/s\n",
      "2355997: done 5293 episodes, mean reward 20.276, speed 56.23 f/s\n",
      "2359997: done 5302 episodes, mean reward 20.499, speed 55.34 f/s\n",
      "2363997: done 5311 episodes, mean reward 20.490, speed 78.27 f/s\n",
      "2367997: done 5320 episodes, mean reward 20.563, speed 70.18 f/s\n",
      "2371997: done 5329 episodes, mean reward 20.371, speed 77.27 f/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2375997: done 5338 episodes, mean reward 20.508, speed 64.63 f/s\n",
      "2379997: done 5347 episodes, mean reward 20.209, speed 50.93 f/s\n",
      "2383997: done 5356 episodes, mean reward 19.964, speed 72.35 f/s\n",
      "2387997: done 5365 episodes, mean reward 20.361, speed 73.71 f/s\n",
      "2391997: done 5374 episodes, mean reward 19.856, speed 71.85 f/s\n",
      "2395997: done 5383 episodes, mean reward 19.964, speed 72.04 f/s\n",
      "2399997: done 5392 episodes, mean reward 19.818, speed 74.29 f/s\n",
      "2403997: done 5401 episodes, mean reward 19.734, speed 71.38 f/s\n",
      "2407997: done 5410 episodes, mean reward 19.457, speed 73.49 f/s\n",
      "2411997: done 5419 episodes, mean reward 19.232, speed 70.41 f/s\n",
      "2415997: done 5428 episodes, mean reward 19.588, speed 72.11 f/s\n",
      "2419997: done 5437 episodes, mean reward 19.671, speed 77.35 f/s\n",
      "2423997: done 5446 episodes, mean reward 19.977, speed 72.91 f/s\n",
      "2427997: done 5455 episodes, mean reward 20.259, speed 69.65 f/s\n",
      "2431997: done 5464 episodes, mean reward 19.952, speed 75.98 f/s\n",
      "2435997: done 5473 episodes, mean reward 20.153, speed 76.66 f/s\n",
      "2439997: done 5482 episodes, mean reward 20.486, speed 79.13 f/s\n",
      "2443997: done 5491 episodes, mean reward 20.277, speed 78.88 f/s\n",
      "2447997: done 5500 episodes, mean reward 20.196, speed 119.76 f/s\n",
      "2455997: done 5518 episodes, mean reward 19.821, speed 166.36 f/s\n",
      "2463997: done 5536 episodes, mean reward 19.506, speed 150.40 f/s\n",
      "2471997: done 5554 episodes, mean reward 19.084, speed 151.18 f/s\n",
      "2479997: done 5572 episodes, mean reward 18.906, speed 145.40 f/s\n",
      "2487997: done 5590 episodes, mean reward 18.840, speed 146.48 f/s\n",
      "2495997: done 5608 episodes, mean reward 18.979, speed 143.96 f/s\n",
      "2503997: done 5626 episodes, mean reward 19.380, speed 130.88 f/s\n",
      "2507997: done 5635 episodes, mean reward 19.530, speed 132.10 f/s\n",
      "2511997: done 5644 episodes, mean reward 19.505, speed 107.25 f/s\n",
      "2515997: done 5653 episodes, mean reward 19.486, speed 88.06 f/s\n",
      "2519997: done 5662 episodes, mean reward 19.569, speed 85.14 f/s\n",
      "2523997: done 5671 episodes, mean reward 19.685, speed 73.73 f/s\n",
      "2527997: done 5680 episodes, mean reward 19.704, speed 63.36 f/s\n",
      "2531997: done 5689 episodes, mean reward 19.525, speed 70.58 f/s\n",
      "2535997: done 5698 episodes, mean reward 19.515, speed 77.36 f/s\n",
      "2539997: done 5707 episodes, mean reward 19.572, speed 63.07 f/s\n",
      "2543997: done 5716 episodes, mean reward 19.797, speed 62.33 f/s\n",
      "2547997: done 5725 episodes, mean reward 19.750, speed 75.11 f/s\n",
      "2551997: done 5734 episodes, mean reward 19.793, speed 72.53 f/s\n",
      "2555997: done 5743 episodes, mean reward 19.637, speed 67.10 f/s\n",
      "2559997: done 5752 episodes, mean reward 19.787, speed 72.90 f/s\n",
      "2563997: done 5761 episodes, mean reward 19.976, speed 75.63 f/s\n",
      "2567997: done 5770 episodes, mean reward 19.927, speed 69.10 f/s\n",
      "2571997: done 5779 episodes, mean reward 20.002, speed 69.12 f/s\n",
      "2575997: done 5788 episodes, mean reward 20.063, speed 71.38 f/s\n",
      "2579997: done 5797 episodes, mean reward 20.280, speed 70.41 f/s\n",
      "2583997: done 5806 episodes, mean reward 20.065, speed 65.86 f/s\n",
      "2587997: done 5815 episodes, mean reward 19.676, speed 70.16 f/s\n",
      "2591997: done 5824 episodes, mean reward 19.281, speed 67.81 f/s\n",
      "2595997: done 5833 episodes, mean reward 19.112, speed 64.98 f/s\n",
      "2599997: done 5842 episodes, mean reward 19.160, speed 65.45 f/s\n",
      "2603997: done 5851 episodes, mean reward 18.331, speed 65.97 f/s\n",
      "2607997: done 5860 episodes, mean reward 18.093, speed 71.43 f/s\n",
      "2611997: done 5869 episodes, mean reward 18.010, speed 66.82 f/s\n",
      "2615997: done 5878 episodes, mean reward 17.835, speed 66.04 f/s\n",
      "2619997: done 5887 episodes, mean reward 18.079, speed 67.51 f/s\n",
      "2623997: done 5896 episodes, mean reward 18.241, speed 70.91 f/s\n",
      "2627997: done 5905 episodes, mean reward 18.212, speed 68.52 f/s\n",
      "2631997: done 5914 episodes, mean reward 18.230, speed 72.43 f/s\n",
      "2635997: done 5923 episodes, mean reward 18.553, speed 72.14 f/s\n",
      "2639997: done 5932 episodes, mean reward 18.530, speed 73.35 f/s\n",
      "2643997: done 5941 episodes, mean reward 18.460, speed 75.36 f/s\n",
      "2647997: done 5950 episodes, mean reward 19.283, speed 72.87 f/s\n",
      "2651997: done 5959 episodes, mean reward 19.556, speed 111.26 f/s\n",
      "2659997: done 5977 episodes, mean reward 19.600, speed 163.60 f/s\n",
      "2667997: done 5995 episodes, mean reward 19.288, speed 150.74 f/s\n",
      "2675997: done 6013 episodes, mean reward 19.326, speed 146.34 f/s\n",
      "2683997: done 6031 episodes, mean reward 19.470, speed 147.07 f/s\n",
      "2691997: done 6049 episodes, mean reward 19.810, speed 143.59 f/s\n",
      "2699997: done 6067 episodes, mean reward 19.765, speed 144.94 f/s\n",
      "2707997: done 6085 episodes, mean reward 18.956, speed 140.86 f/s\n",
      "2711997: done 6094 episodes, mean reward 19.301, speed 123.76 f/s\n",
      "2715997: done 6103 episodes, mean reward 19.499, speed 111.14 f/s\n",
      "2719997: done 6112 episodes, mean reward 19.456, speed 100.02 f/s\n",
      "2723997: done 6121 episodes, mean reward 19.279, speed 86.71 f/s\n",
      "2727997: done 6130 episodes, mean reward 19.116, speed 75.13 f/s\n",
      "2731997: done 6139 episodes, mean reward 18.981, speed 71.49 f/s\n",
      "2735997: done 6148 episodes, mean reward 18.699, speed 74.66 f/s\n",
      "2739997: done 6157 episodes, mean reward 18.938, speed 72.13 f/s\n",
      "2743997: done 6166 episodes, mean reward 19.123, speed 65.77 f/s\n",
      "2747997: done 6175 episodes, mean reward 19.322, speed 65.22 f/s\n",
      "2751997: done 6184 episodes, mean reward 19.757, speed 71.86 f/s\n",
      "2755997: done 6193 episodes, mean reward 19.519, speed 76.01 f/s\n",
      "2759997: done 6202 episodes, mean reward 19.957, speed 72.93 f/s\n",
      "2763997: done 6211 episodes, mean reward 19.928, speed 69.70 f/s\n",
      "2767997: done 6220 episodes, mean reward 20.076, speed 69.43 f/s\n",
      "2771997: done 6229 episodes, mean reward 20.742, speed 69.21 f/s\n",
      "2775997: done 6238 episodes, mean reward 21.157, speed 66.85 f/s\n",
      "2779997: done 6247 episodes, mean reward 20.902, speed 65.38 f/s\n",
      "2783997: done 6256 episodes, mean reward 20.670, speed 69.75 f/s\n",
      "2787997: done 6265 episodes, mean reward 20.212, speed 83.09 f/s\n",
      "2791997: done 6274 episodes, mean reward 20.541, speed 82.83 f/s\n",
      "2795997: done 6283 episodes, mean reward 20.559, speed 79.99 f/s\n",
      "2799997: done 6292 episodes, mean reward 20.420, speed 79.58 f/s\n",
      "2803997: done 6301 episodes, mean reward 20.362, speed 83.13 f/s\n",
      "2807997: done 6310 episodes, mean reward 20.221, speed 83.98 f/s\n",
      "2811997: done 6319 episodes, mean reward 20.346, speed 79.99 f/s\n",
      "2815997: done 6328 episodes, mean reward 20.051, speed 80.30 f/s\n",
      "2819997: done 6337 episodes, mean reward 20.179, speed 82.26 f/s\n",
      "2823997: done 6346 episodes, mean reward 20.052, speed 81.79 f/s\n",
      "2827997: done 6355 episodes, mean reward 20.894, speed 78.86 f/s\n",
      "2831997: done 6364 episodes, mean reward 21.223, speed 80.43 f/s\n",
      "2835997: done 6373 episodes, mean reward 20.912, speed 82.43 f/s\n",
      "2839997: done 6382 episodes, mean reward 21.183, speed 78.86 f/s\n",
      "2843997: done 6391 episodes, mean reward 20.930, speed 82.44 f/s\n",
      "2847997: done 6400 episodes, mean reward 21.133, speed 83.14 f/s\n",
      "2851997: done 6409 episodes, mean reward 21.370, speed 84.34 f/s\n",
      "2859997: done 6427 episodes, mean reward 21.030, speed 164.16 f/s\n",
      "2867997: done 6445 episodes, mean reward 21.377, speed 156.43 f/s\n",
      "2875997: done 6463 episodes, mean reward 21.064, speed 152.23 f/s\n",
      "2883997: done 6481 episodes, mean reward 21.415, speed 148.34 f/s\n",
      "2891997: done 6499 episodes, mean reward 21.057, speed 142.90 f/s\n",
      "2899997: done 6517 episodes, mean reward 20.725, speed 144.68 f/s\n",
      "2907997: done 6535 episodes, mean reward 21.246, speed 144.14 f/s\n",
      "2915997: done 6553 episodes, mean reward 21.447, speed 129.61 f/s\n",
      "2919997: done 6562 episodes, mean reward 21.140, speed 111.51 f/s\n",
      "2923997: done 6571 episodes, mean reward 21.225, speed 102.30 f/s\n",
      "2927997: done 6580 episodes, mean reward 20.687, speed 90.56 f/s\n",
      "2931997: done 6589 episodes, mean reward 20.852, speed 84.12 f/s\n",
      "2935997: done 6598 episodes, mean reward 21.121, speed 79.07 f/s\n",
      "2939997: done 6607 episodes, mean reward 21.157, speed 77.96 f/s\n",
      "2943997: done 6616 episodes, mean reward 21.740, speed 75.79 f/s\n",
      "2947997: done 6625 episodes, mean reward 21.590, speed 73.63 f/s\n",
      "2951997: done 6634 episodes, mean reward 21.725, speed 79.64 f/s\n",
      "2955997: done 6643 episodes, mean reward 21.108, speed 79.24 f/s\n",
      "2959997: done 6652 episodes, mean reward 21.004, speed 76.62 f/s\n",
      "2963997: done 6661 episodes, mean reward 21.149, speed 75.81 f/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2967997: done 6670 episodes, mean reward 21.333, speed 76.22 f/s\n",
      "2971997: done 6679 episodes, mean reward 21.858, speed 79.00 f/s\n",
      "2975997: done 6688 episodes, mean reward 21.809, speed 81.18 f/s\n",
      "2979997: done 6697 episodes, mean reward 21.492, speed 78.04 f/s\n",
      "2983997: done 6706 episodes, mean reward 21.734, speed 77.82 f/s\n",
      "2987997: done 6715 episodes, mean reward 21.250, speed 82.50 f/s\n",
      "2991997: done 6724 episodes, mean reward 21.256, speed 80.00 f/s\n",
      "2995997: done 6733 episodes, mean reward 21.142, speed 77.15 f/s\n",
      "2999997: done 6742 episodes, mean reward 21.034, speed 79.31 f/s\n",
      "3003997: done 6751 episodes, mean reward 21.607, speed 80.88 f/s\n",
      "3007997: done 6760 episodes, mean reward 21.668, speed 77.99 f/s\n",
      "3011997: done 6769 episodes, mean reward 21.896, speed 81.16 f/s\n",
      "3015997: done 6778 episodes, mean reward 21.714, speed 81.02 f/s\n",
      "3019997: done 6787 episodes, mean reward 21.869, speed 77.26 f/s\n",
      "3023997: done 6796 episodes, mean reward 22.029, speed 82.28 f/s\n",
      "3027997: done 6805 episodes, mean reward 21.906, speed 78.28 f/s\n",
      "3031997: done 6814 episodes, mean reward 21.933, speed 78.05 f/s\n",
      "3035997: done 6823 episodes, mean reward 21.792, speed 82.81 f/s\n",
      "3039997: done 6832 episodes, mean reward 21.971, speed 78.50 f/s\n",
      "3043997: done 6841 episodes, mean reward 21.951, speed 78.30 f/s\n",
      "3047997: done 6850 episodes, mean reward 21.781, speed 76.58 f/s\n",
      "3051997: done 6859 episodes, mean reward 21.878, speed 80.22 f/s\n",
      "3055997: done 6868 episodes, mean reward 21.505, speed 80.82 f/s\n",
      "3059997: done 6877 episodes, mean reward 21.376, speed 77.19 f/s\n",
      "3063997: done 6886 episodes, mean reward 21.308, speed 77.65 f/s\n",
      "3067997: done 6895 episodes, mean reward 21.001, speed 115.66 f/s\n",
      "3075997: done 6913 episodes, mean reward 21.565, speed 163.28 f/s\n",
      "3083997: done 6931 episodes, mean reward 22.003, speed 151.56 f/s\n",
      "3091997: done 6949 episodes, mean reward 21.582, speed 150.06 f/s\n",
      "3099997: done 6967 episodes, mean reward 21.477, speed 148.20 f/s\n",
      "3107997: done 6985 episodes, mean reward 21.981, speed 147.80 f/s\n",
      "3115997: done 7003 episodes, mean reward 21.870, speed 145.29 f/s\n",
      "3123997: done 7021 episodes, mean reward 21.222, speed 142.51 f/s\n",
      "3131997: done 7039 episodes, mean reward 20.964, speed 142.83 f/s\n",
      "3135997: done 7048 episodes, mean reward 20.971, speed 119.97 f/s\n",
      "3139997: done 7057 episodes, mean reward 21.231, speed 109.54 f/s\n",
      "3143997: done 7066 episodes, mean reward 21.523, speed 103.23 f/s\n",
      "3147997: done 7075 episodes, mean reward 21.490, speed 94.18 f/s\n",
      "3151997: done 7084 episodes, mean reward 21.212, speed 85.63 f/s\n",
      "3155997: done 7093 episodes, mean reward 20.999, speed 82.50 f/s\n",
      "3159997: done 7102 episodes, mean reward 21.072, speed 79.28 f/s\n",
      "3163997: done 7111 episodes, mean reward 21.264, speed 78.39 f/s\n",
      "3167997: done 7120 episodes, mean reward 21.260, speed 81.84 f/s\n",
      "3171997: done 7129 episodes, mean reward 22.022, speed 80.11 f/s\n",
      "3175997: done 7138 episodes, mean reward 21.695, speed 82.37 f/s\n",
      "3179997: done 7147 episodes, mean reward 21.538, speed 80.60 f/s\n",
      "3183997: done 7156 episodes, mean reward 21.482, speed 82.39 f/s\n",
      "3187997: done 7165 episodes, mean reward 21.610, speed 81.16 f/s\n",
      "3191997: done 7174 episodes, mean reward 21.151, speed 81.34 f/s\n",
      "3195997: done 7183 episodes, mean reward 21.255, speed 81.90 f/s\n",
      "3199997: done 7192 episodes, mean reward 21.073, speed 77.40 f/s\n",
      "3203997: done 7201 episodes, mean reward 21.064, speed 74.04 f/s\n",
      "3207997: done 7210 episodes, mean reward 21.189, speed 72.96 f/s\n",
      "3211997: done 7219 episodes, mean reward 21.362, speed 74.53 f/s\n",
      "3215997: done 7228 episodes, mean reward 21.057, speed 80.98 f/s\n",
      "3219997: done 7237 episodes, mean reward 21.525, speed 77.24 f/s\n",
      "3223997: done 7246 episodes, mean reward 22.105, speed 74.25 f/s\n",
      "3227997: done 7255 episodes, mean reward 21.663, speed 75.35 f/s\n",
      "3231997: done 7264 episodes, mean reward 21.581, speed 76.63 f/s\n",
      "3235997: done 7273 episodes, mean reward 21.760, speed 75.61 f/s\n",
      "3239997: done 7282 episodes, mean reward 21.924, speed 76.00 f/s\n",
      "3243997: done 7291 episodes, mean reward 22.118, speed 76.75 f/s\n",
      "3247997: done 7300 episodes, mean reward 22.194, speed 71.60 f/s\n",
      "3251997: done 7309 episodes, mean reward 22.609, speed 81.24 f/s\n",
      "3255997: done 7318 episodes, mean reward 22.446, speed 78.12 f/s\n",
      "3259997: done 7327 episodes, mean reward 22.540, speed 71.89 f/s\n",
      "3263997: done 7336 episodes, mean reward 22.292, speed 71.93 f/s\n",
      "3267997: done 7345 episodes, mean reward 21.770, speed 76.43 f/s\n",
      "3271997: done 7354 episodes, mean reward 22.270, speed 75.86 f/s\n",
      "3275997: done 7363 episodes, mean reward 22.240, speed 74.49 f/s\n",
      "3279997: done 7372 episodes, mean reward 22.575, speed 71.98 f/s\n",
      "3283997: done 7381 episodes, mean reward 22.403, speed 72.66 f/s\n",
      "3287997: done 7390 episodes, mean reward 22.593, speed 74.04 f/s\n",
      "3291997: done 7399 episodes, mean reward 22.620, speed 126.30 f/s\n",
      "3299997: done 7417 episodes, mean reward 22.299, speed 161.10 f/s\n",
      "3307997: done 7435 episodes, mean reward 22.599, speed 149.75 f/s\n",
      "3315997: done 7453 episodes, mean reward 22.602, speed 149.40 f/s\n",
      "3323997: done 7471 episodes, mean reward 22.107, speed 150.22 f/s\n",
      "3331997: done 7489 episodes, mean reward 22.095, speed 147.52 f/s\n",
      "3339997: done 7507 episodes, mean reward 22.032, speed 148.55 f/s\n",
      "3347997: done 7525 episodes, mean reward 22.123, speed 143.11 f/s\n",
      "3351997: done 7534 episodes, mean reward 22.332, speed 130.10 f/s\n",
      "3355997: done 7543 episodes, mean reward 22.541, speed 113.15 f/s\n",
      "3359997: done 7552 episodes, mean reward 22.310, speed 102.24 f/s\n",
      "3363997: done 7561 episodes, mean reward 22.486, speed 93.02 f/s\n",
      "3367997: done 7570 episodes, mean reward 22.531, speed 85.69 f/s\n",
      "3371997: done 7579 episodes, mean reward 22.054, speed 78.29 f/s\n",
      "3375997: done 7588 episodes, mean reward 21.843, speed 73.20 f/s\n",
      "3379997: done 7597 episodes, mean reward 21.438, speed 76.45 f/s\n",
      "3383997: done 7606 episodes, mean reward 21.745, speed 82.39 f/s\n",
      "3387997: done 7615 episodes, mean reward 21.453, speed 78.07 f/s\n",
      "3391997: done 7624 episodes, mean reward 21.251, speed 76.78 f/s\n",
      "3395997: done 7633 episodes, mean reward 21.034, speed 81.79 f/s\n",
      "3399997: done 7642 episodes, mean reward 21.012, speed 77.15 f/s\n",
      "3403997: done 7651 episodes, mean reward 21.250, speed 78.04 f/s\n",
      "3407997: done 7660 episodes, mean reward 21.077, speed 85.73 f/s\n",
      "3411997: done 7669 episodes, mean reward 21.353, speed 81.49 f/s\n",
      "3415997: done 7678 episodes, mean reward 21.614, speed 72.40 f/s\n",
      "3419997: done 7687 episodes, mean reward 22.088, speed 81.06 f/s\n",
      "3423997: done 7696 episodes, mean reward 22.016, speed 82.53 f/s\n",
      "3427997: done 7705 episodes, mean reward 22.187, speed 80.34 f/s\n",
      "3431997: done 7714 episodes, mean reward 22.367, speed 73.64 f/s\n",
      "3435997: done 7723 episodes, mean reward 22.605, speed 71.06 f/s\n",
      "3439997: done 7732 episodes, mean reward 22.923, speed 80.31 f/s\n",
      "3443997: done 7741 episodes, mean reward 22.757, speed 80.97 f/s\n",
      "3447997: done 7750 episodes, mean reward 22.850, speed 76.77 f/s\n",
      "3451997: done 7759 episodes, mean reward 22.845, speed 73.29 f/s\n",
      "3455997: done 7768 episodes, mean reward 22.318, speed 78.42 f/s\n",
      "3459997: done 7777 episodes, mean reward 22.317, speed 76.26 f/s\n",
      "3463997: done 7786 episodes, mean reward 22.268, speed 72.27 f/s\n",
      "3467997: done 7795 episodes, mean reward 22.654, speed 78.25 f/s\n",
      "3471997: done 7804 episodes, mean reward 22.706, speed 75.15 f/s\n",
      "3475997: done 7813 episodes, mean reward 22.385, speed 73.51 f/s\n",
      "3479997: done 7822 episodes, mean reward 22.174, speed 76.07 f/s\n",
      "3483997: done 7831 episodes, mean reward 21.974, speed 80.16 f/s\n",
      "3487997: done 7840 episodes, mean reward 22.031, speed 68.33 f/s\n",
      "3491997: done 7849 episodes, mean reward 22.157, speed 74.14 f/s\n",
      "3495997: done 7858 episodes, mean reward 22.173, speed 80.72 f/s\n",
      "3499997: done 7867 episodes, mean reward 22.550, speed 78.41 f/s\n",
      "3503997: done 7876 episodes, mean reward 22.493, speed 73.63 f/s\n",
      "3511997: done 7894 episodes, mean reward 22.311, speed 153.17 f/s\n",
      "3519997: done 7912 episodes, mean reward 22.391, speed 151.35 f/s\n",
      "3527997: done 7930 episodes, mean reward 22.449, speed 146.30 f/s\n",
      "3535997: done 7948 episodes, mean reward 22.085, speed 146.90 f/s\n",
      "3543997: done 7966 episodes, mean reward 22.216, speed 146.06 f/s\n",
      "3551997: done 7984 episodes, mean reward 22.083, speed 144.11 f/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3559997: done 8002 episodes, mean reward 22.088, speed 143.14 f/s\n",
      "3567997: done 8020 episodes, mean reward 22.227, speed 140.86 f/s\n",
      "3575997: done 8038 episodes, mean reward 22.377, speed 126.00 f/s\n",
      "3579997: done 8047 episodes, mean reward 22.592, speed 106.47 f/s\n",
      "3583997: done 8056 episodes, mean reward 22.104, speed 102.02 f/s\n",
      "3587997: done 8065 episodes, mean reward 22.439, speed 89.51 f/s\n",
      "3591997: done 8074 episodes, mean reward 22.620, speed 81.72 f/s\n",
      "3595997: done 8083 episodes, mean reward 22.683, speed 78.86 f/s\n",
      "3599997: done 8092 episodes, mean reward 22.457, speed 76.51 f/s\n",
      "3603997: done 8101 episodes, mean reward 22.325, speed 80.39 f/s\n",
      "3607997: done 8110 episodes, mean reward 21.860, speed 79.03 f/s\n",
      "3611997: done 8119 episodes, mean reward 21.868, speed 77.09 f/s\n",
      "3615997: done 8128 episodes, mean reward 21.912, speed 74.78 f/s\n",
      "3619997: done 8137 episodes, mean reward 22.141, speed 80.41 f/s\n",
      "3623997: done 8146 episodes, mean reward 21.916, speed 82.10 f/s\n",
      "3627997: done 8155 episodes, mean reward 21.980, speed 84.39 f/s\n",
      "3631997: done 8164 episodes, mean reward 21.839, speed 77.24 f/s\n",
      "3635997: done 8173 episodes, mean reward 21.802, speed 74.68 f/s\n",
      "3639997: done 8182 episodes, mean reward 21.858, speed 78.90 f/s\n",
      "3643997: done 8191 episodes, mean reward 21.809, speed 80.67 f/s\n",
      "3647997: done 8200 episodes, mean reward 21.471, speed 77.48 f/s\n",
      "3651997: done 8209 episodes, mean reward 21.431, speed 75.81 f/s\n",
      "3655997: done 8218 episodes, mean reward 21.585, speed 74.88 f/s\n",
      "3659997: done 8227 episodes, mean reward 21.730, speed 75.80 f/s\n",
      "3663997: done 8236 episodes, mean reward 21.817, speed 81.41 f/s\n",
      "3667997: done 8245 episodes, mean reward 22.028, speed 76.10 f/s\n",
      "3671997: done 8254 episodes, mean reward 21.854, speed 75.38 f/s\n",
      "3675997: done 8263 episodes, mean reward 22.113, speed 73.91 f/s\n",
      "3679997: done 8272 episodes, mean reward 21.934, speed 74.04 f/s\n"
     ]
    }
   ],
   "source": [
    "frame_idx = 0\n",
    "best_reward = None\n",
    "stop_score = 30\n",
    "\n",
    "with ptan.common.utils.RewardTracker(writer,min_ts_diff=30) as tracker:\n",
    "    with ptan.common.utils.TBMeanTracker(writer, batch_size=10) as tb_tracker:\n",
    "        while True:\n",
    "            \n",
    "            frame_idx += 1\n",
    "            buffer.populate(config.STEPS)\n",
    "            \n",
    "            rewards_steps = exp_source.pop_rewards_steps()\n",
    "            if rewards_steps:\n",
    "                rewards, steps = zip(*rewards_steps)\n",
    "                tb_tracker.track(\"episode_steps\", steps[0], frame_idx)\n",
    "                mean_reward = tracker.reward(rewards[0], frame_idx)\n",
    "                \n",
    "                if mean_reward and mean_reward > stop_score:\n",
    "                    print('Solved!')\n",
    "                    break\n",
    "                \n",
    "            if len(buffer) < 10000:\n",
    "                continue\n",
    "                \n",
    "            batch = buffer.sample(config.BATCH_SIZE)\n",
    "            states_v, actions_v, rewards_v, dones_mask, last_states_v = unpack_batch(batch, config.device)\n",
    "            \n",
    "            #Critic Training\n",
    "            crt_opt.zero_grad()\n",
    "            q_v = critic_net(states_v, actions_v)\n",
    "            last_act_v = actor_target.target_model(last_states_v)\n",
    "            q_last_v = critic_target.target_model(last_states_v, last_act_v)\n",
    "            q_last_v[dones_mask] = 0.0\n",
    "            q_ref_v = rewards_v.unsqueeze(dim=-1) + q_last_v * config.GAMMA\n",
    "            critic_loss_v = F.mse_loss(q_v, q_ref_v.detach())\n",
    "            critic_loss_v.backward()\n",
    "            crt_opt.step()\n",
    "            tb_tracker.track(\"loss_critic\", critic_loss_v, frame_idx)\n",
    "            tb_tracker.track(\"critic_ref\", q_ref_v.mean(), frame_idx)\n",
    "            \n",
    "            #Actor Training            \n",
    "            act_opt.zero_grad()\n",
    "            cur_actions_v = actor_net(states_v)\n",
    "            actor_loss_v = -critic_net(states_v, cur_actions_v)\n",
    "            actor_loss_v = actor_loss_v.mean()\n",
    "            actor_loss_v.backward()\n",
    "            act_opt.step()\n",
    "            tb_tracker.track(\"loss_actor\", actor_loss_v, frame_idx)\n",
    "\n",
    "            actor_target.alpha_sync(alpha=1 - config.TAU)\n",
    "            critic_target.alpha_sync(alpha=1 - config.TAU)\n",
    "            \n",
    "            \n",
    "                \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np.asanyarray(critic_losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.asanyarray(critic_losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_score_line = [s for s in log_data if \"max_score: \" in s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_scores = [float(s.strip().split()[-1]) for s in max_score_line]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(max_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_info = env.reset()[brain_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_info.previous_vector_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(env_info.vector_observations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.TAU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drlnd",
   "language": "python",
   "name": "drlnd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
